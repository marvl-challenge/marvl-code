WARNING:tensorflow:From /home/projects/ku_00062/envs/marvl/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/marvl/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/marvl/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.

05/05/2021 19:13:56 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False
05/05/2021 19:13:57 - INFO - volta.task_utils -   Loading NLVR2zh Dataset with batch size 32
05/05/2021 19:14:28 - INFO - volta.train_utils -   logging file at: /home/projects/ku_00062/logs/mlvr/ctrl_muniter_base/NLVR2zh_ctrl_muniter_base
05/05/2021 19:14:28 - INFO - volta.utils -   loading weights file /home/projects/ku_00062/checkpoints/mlvr/ctrl_muniter/conceptual_captions_wikipedia/ctrl_muniter_base/pytorch_model_9.bin
05/05/2021 19:14:34 - INFO - volta.utils -   
05/05/2021 19:14:34 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['bert.embeddings.image_token_type_embeddings.weight', 'clfs_dict.TASK12.logit_fc.0.weight', 'clfs_dict.TASK12.logit_fc.0.bias', 'clfs_dict.TASK12.logit_fc.2.weight', 'clfs_dict.TASK12.logit_fc.2.bias', 'clfs_dict.TASK12.logit_fc.3.weight', 'clfs_dict.TASK12.logit_fc.3.bias']
05/05/2021 19:14:34 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLTasks: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
05/05/2021 19:14:38 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/05/2021 19:14:41 - INFO - __main__ -   >> Parameters:
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |Name                                                       |Dtype            |Shape            |#Params     |Trainable|
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.word_embeddings.weight                     |torch.float32    |(119547, 768)    |91812096    |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.position_embeddings.weight                 |torch.float32    |(512, 768)       |393216      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.token_type_embeddings.weight               |torch.float32    |(2, 768)         |1536        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.LayerNorm.weight                           |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.LayerNorm.bias                             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)      |1572864     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.image_embeddings.bias                      |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.image_location_embeddings.weight           |torch.float32    |(768, 5)         |3840        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.image_location_embeddings.bias             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.image_layer_norm.weight                    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.image_layer_norm.bias                      |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.image_location_layer_norm.weight           |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.image_location_layer_norm.bias             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.v_LayerNorm.weight                         |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.embeddings.v_LayerNorm.bias                           |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.t_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.t_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.v_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432      |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |bert.v_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.0.weight                         |torch.float32    |(1536, 2048)     |3145728     |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.0.bias                           |torch.float32    |(1536,)          |1536        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.2.weight                         |torch.float32    |(1536,)          |1536        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.2.bias                           |torch.float32    |(1536,)          |1536        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.3.weight                         |torch.float32    |(2, 1536)        |3072        |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.3.bias                           |torch.float32    |(2,)             |2           |True    |
05/05/2021 19:14:41 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/05/2021 19:14:41 - INFO - __main__ -   >> # TrainableParams:       	183.57	M
05/05/2021 19:14:41 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
05/05/2021 19:14:41 - INFO - __main__ -   >> # TotalParams:           	183.57	M

Epoch:   0%|          | 0/20 [00:00<?, ?it/s]05/05/2021 19:16:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 40 Ep: 0.01 loss 0.199 score 0.246 lr 1.94444e-08 
05/05/2021 19:18:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 80 Ep: 0.03 loss 0.195 score 0.254 lr 5.64815e-08 
05/05/2021 19:19:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 120 Ep: 0.04 loss 0.198 score 0.244 lr 9.35185e-08 
05/05/2021 19:20:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 160 Ep: 0.06 loss 0.194 score 0.260 lr 1.30556e-07 
05/05/2021 19:22:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 200 Ep: 0.07 loss 0.188 score 0.246 lr 1.67593e-07 
05/05/2021 19:23:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 240 Ep: 0.09 loss 0.184 score 0.255 lr 2.0463e-07 
05/05/2021 19:24:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 280 Ep: 0.10 loss 0.187 score 0.250 lr 2.41667e-07 
05/05/2021 19:26:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 320 Ep: 0.12 loss 0.182 score 0.250 lr 2.78704e-07 
05/05/2021 19:27:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 360 Ep: 0.13 loss 0.183 score 0.248 lr 3.15741e-07 
05/05/2021 19:28:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 400 Ep: 0.15 loss 0.183 score 0.243 lr 3.52778e-07 
05/05/2021 19:29:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 440 Ep: 0.16 loss 0.181 score 0.246 lr 3.89815e-07 
05/05/2021 19:30:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 480 Ep: 0.18 loss 0.176 score 0.263 lr 4.26852e-07 
05/05/2021 19:31:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 520 Ep: 0.19 loss 0.178 score 0.257 lr 4.63889e-07 
05/05/2021 19:33:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 560 Ep: 0.21 loss 0.177 score 0.255 lr 5.00926e-07 
05/05/2021 19:34:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 600 Ep: 0.22 loss 0.176 score 0.259 lr 5.37963e-07 
05/05/2021 19:35:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 640 Ep: 0.24 loss 0.175 score 0.263 lr 5.75e-07 
05/05/2021 19:36:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 680 Ep: 0.25 loss 0.178 score 0.250 lr 6.12037e-07 
05/05/2021 19:37:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 720 Ep: 0.27 loss 0.177 score 0.252 lr 6.49074e-07 
05/05/2021 19:38:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 760 Ep: 0.28 loss 0.176 score 0.255 lr 6.86111e-07 
05/05/2021 19:39:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 800 Ep: 0.30 loss 0.179 score 0.247 lr 7.23148e-07 
05/05/2021 19:40:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 840 Ep: 0.31 loss 0.174 score 0.261 lr 7.60185e-07 
05/05/2021 19:41:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 880 Ep: 0.33 loss 0.177 score 0.254 lr 7.97222e-07 
05/05/2021 19:42:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 920 Ep: 0.34 loss 0.178 score 0.245 lr 8.34259e-07 
05/05/2021 19:43:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 960 Ep: 0.36 loss 0.177 score 0.252 lr 8.71296e-07 
05/05/2021 19:44:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 1000 Ep: 0.37 loss 0.175 score 0.252 lr 9.08333e-07 
05/05/2021 19:45:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 1040 Ep: 0.39 loss 0.177 score 0.252 lr 9.4537e-07 
05/05/2021 19:46:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 1080 Ep: 0.40 loss 0.177 score 0.251 lr 9.82407e-07 
05/05/2021 19:48:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 1120 Ep: 0.41 loss 0.177 score 0.241 lr 1.01944e-06 
05/05/2021 19:49:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 1160 Ep: 0.43 loss 0.175 score 0.248 lr 1.05648e-06 
05/05/2021 19:50:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 1200 Ep: 0.44 loss 0.177 score 0.244 lr 1.09352e-06 
05/05/2021 19:51:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 1240 Ep: 0.46 loss 0.175 score 0.252 lr 1.13056e-06 
05/05/2021 19:52:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 1280 Ep: 0.47 loss 0.175 score 0.256 lr 1.16759e-06 
05/05/2021 19:53:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 1320 Ep: 0.49 loss 0.176 score 0.248 lr 1.20463e-06 
05/05/2021 19:55:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 1360 Ep: 0.50 loss 0.176 score 0.248 lr 1.24167e-06 
05/05/2021 19:57:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 1400 Ep: 0.52 loss 0.175 score 0.250 lr 1.2787e-06 
05/05/2021 19:58:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 1440 Ep: 0.53 loss 0.173 score 0.271 lr 1.31574e-06 
05/05/2021 19:59:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 1480 Ep: 0.55 loss 0.176 score 0.255 lr 1.35278e-06 
05/05/2021 20:00:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 1520 Ep: 0.56 loss 0.174 score 0.251 lr 1.38981e-06 
05/05/2021 20:01:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 1560 Ep: 0.58 loss 0.175 score 0.255 lr 1.42685e-06 
05/05/2021 20:02:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 1600 Ep: 0.59 loss 0.176 score 0.261 lr 1.46389e-06 
05/05/2021 20:04:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 1640 Ep: 0.61 loss 0.177 score 0.248 lr 1.50093e-06 
05/05/2021 20:05:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 1680 Ep: 0.62 loss 0.176 score 0.255 lr 1.53796e-06 
05/05/2021 20:06:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 1720 Ep: 0.64 loss 0.174 score 0.252 lr 1.575e-06 
05/05/2021 20:07:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 1760 Ep: 0.65 loss 0.176 score 0.250 lr 1.61204e-06 
05/05/2021 20:09:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 1800 Ep: 0.67 loss 0.176 score 0.243 lr 1.64907e-06 
05/05/2021 20:10:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 1840 Ep: 0.68 loss 0.174 score 0.255 lr 1.68611e-06 
05/05/2021 20:11:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 1880 Ep: 0.70 loss 0.174 score 0.253 lr 1.72315e-06 
05/05/2021 20:12:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 1920 Ep: 0.71 loss 0.174 score 0.264 lr 1.76019e-06 
05/05/2021 20:13:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 1960 Ep: 0.73 loss 0.175 score 0.250 lr 1.79722e-06 
05/05/2021 20:14:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 2000 Ep: 0.74 loss 0.173 score 0.257 lr 1.83426e-06 
05/05/2021 20:15:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 2040 Ep: 0.76 loss 0.176 score 0.253 lr 1.8713e-06 
05/05/2021 20:16:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 2080 Ep: 0.77 loss 0.175 score 0.261 lr 1.90833e-06 
05/05/2021 20:17:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 2120 Ep: 0.79 loss 0.176 score 0.247 lr 1.94537e-06 
05/05/2021 20:18:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 2160 Ep: 0.80 loss 0.174 score 0.254 lr 1.98241e-06 
05/05/2021 20:19:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 2200 Ep: 0.81 loss 0.176 score 0.249 lr 2.01944e-06 
05/05/2021 20:20:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 2240 Ep: 0.83 loss 0.175 score 0.251 lr 2.05648e-06 
05/05/2021 20:21:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 2280 Ep: 0.84 loss 0.174 score 0.257 lr 2.09352e-06 
05/05/2021 20:23:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 2320 Ep: 0.86 loss 0.174 score 0.249 lr 2.13056e-06 
05/05/2021 20:24:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 2360 Ep: 0.87 loss 0.175 score 0.255 lr 2.16759e-06 
05/05/2021 20:25:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 2400 Ep: 0.89 loss 0.175 score 0.252 lr 2.20463e-06 
05/05/2021 20:26:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 2440 Ep: 0.90 loss 0.173 score 0.272 lr 2.24167e-06 
05/05/2021 20:27:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 2480 Ep: 0.92 loss 0.175 score 0.244 lr 2.2787e-06 
05/05/2021 20:29:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 2520 Ep: 0.93 loss 0.175 score 0.257 lr 2.31574e-06 
05/05/2021 20:30:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 2560 Ep: 0.95 loss 0.175 score 0.249 lr 2.35278e-06 
05/05/2021 20:31:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 2600 Ep: 0.96 loss 0.175 score 0.255 lr 2.38981e-06 
05/05/2021 20:32:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 2640 Ep: 0.98 loss 0.174 score 0.256 lr 2.42685e-06 
05/05/2021 20:33:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 2680 Ep: 0.99 loss 0.175 score 0.258 lr 2.46389e-06 
05/05/2021 20:33:50 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:   5%|         | 1/20 [1:19:16<25:06:05, 4756.08s/it]05/05/2021 20:49:34 - INFO - volta.train_utils -   Eval task TASK12 on iteration 2700 
05/05/2021 20:49:34 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 0.690 score 52.950 
05/05/2021 20:49:34 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/05/2021 20:50:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 2740 Ep: 1.01 loss 0.173 score 0.258 lr 2.51019e-06 
05/05/2021 20:50:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 2780 Ep: 1.03 loss 0.175 score 0.261 lr 2.55648e-06 
05/05/2021 20:52:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 2820 Ep: 1.04 loss 0.174 score 0.249 lr 2.59352e-06 
05/05/2021 20:53:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 2860 Ep: 1.06 loss 0.174 score 0.259 lr 2.63056e-06 
05/05/2021 20:54:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 2900 Ep: 1.07 loss 0.173 score 0.271 lr 2.66759e-06 
05/05/2021 20:55:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 2940 Ep: 1.09 loss 0.171 score 0.272 lr 2.70463e-06 
05/05/2021 20:56:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 2980 Ep: 1.10 loss 0.173 score 0.268 lr 2.74167e-06 
05/05/2021 20:57:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 3020 Ep: 1.12 loss 0.174 score 0.275 lr 2.7787e-06 
05/05/2021 20:58:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 3060 Ep: 1.13 loss 0.172 score 0.265 lr 2.81574e-06 
05/05/2021 20:59:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 3100 Ep: 1.15 loss 0.172 score 0.271 lr 2.85278e-06 
05/05/2021 21:00:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 3140 Ep: 1.16 loss 0.173 score 0.265 lr 2.88981e-06 
05/05/2021 21:01:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 3180 Ep: 1.18 loss 0.172 score 0.270 lr 2.92685e-06 
05/05/2021 21:02:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 3220 Ep: 1.19 loss 0.172 score 0.267 lr 2.96389e-06 
05/05/2021 21:03:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 3260 Ep: 1.21 loss 0.170 score 0.280 lr 3.00093e-06 
05/05/2021 21:04:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 3300 Ep: 1.22 loss 0.172 score 0.287 lr 3.03796e-06 
05/05/2021 21:05:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 3340 Ep: 1.24 loss 0.172 score 0.282 lr 3.075e-06 
05/05/2021 21:06:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 3380 Ep: 1.25 loss 0.170 score 0.282 lr 3.11204e-06 
05/05/2021 21:07:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 3420 Ep: 1.27 loss 0.171 score 0.269 lr 3.14907e-06 
05/05/2021 21:08:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 3460 Ep: 1.28 loss 0.170 score 0.288 lr 3.18611e-06 
05/05/2021 21:09:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 3500 Ep: 1.30 loss 0.173 score 0.275 lr 3.22315e-06 
05/05/2021 21:10:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 3540 Ep: 1.31 loss 0.172 score 0.272 lr 3.26019e-06 
05/05/2021 21:11:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 3580 Ep: 1.33 loss 0.170 score 0.282 lr 3.29722e-06 
05/05/2021 21:12:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 3620 Ep: 1.34 loss 0.172 score 0.289 lr 3.33426e-06 
05/05/2021 21:13:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 3660 Ep: 1.36 loss 0.167 score 0.286 lr 3.3713e-06 
05/05/2021 21:14:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 3700 Ep: 1.37 loss 0.169 score 0.285 lr 3.40833e-06 
05/05/2021 21:15:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 3740 Ep: 1.39 loss 0.171 score 0.283 lr 3.44537e-06 
05/05/2021 21:17:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 3780 Ep: 1.40 loss 0.168 score 0.293 lr 3.48241e-06 
05/05/2021 21:18:03 - INFO - volta.train_utils -   [NLVR2zh]: iter 3820 Ep: 1.41 loss 0.169 score 0.292 lr 3.51944e-06 
05/05/2021 21:19:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 3860 Ep: 1.43 loss 0.169 score 0.282 lr 3.55648e-06 
05/05/2021 21:20:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 3900 Ep: 1.44 loss 0.167 score 0.289 lr 3.59352e-06 
05/05/2021 21:21:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 3940 Ep: 1.46 loss 0.167 score 0.281 lr 3.63056e-06 
05/05/2021 21:22:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 3980 Ep: 1.47 loss 0.167 score 0.291 lr 3.66759e-06 
05/05/2021 21:23:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 4020 Ep: 1.49 loss 0.166 score 0.285 lr 3.70463e-06 
05/05/2021 21:24:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 4060 Ep: 1.50 loss 0.164 score 0.299 lr 3.74167e-06 
05/05/2021 21:25:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 4100 Ep: 1.52 loss 0.164 score 0.295 lr 3.7787e-06 
05/05/2021 21:26:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 4140 Ep: 1.53 loss 0.166 score 0.290 lr 3.81574e-06 
05/05/2021 21:27:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 4180 Ep: 1.55 loss 0.166 score 0.296 lr 3.85278e-06 
05/05/2021 21:28:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 4220 Ep: 1.56 loss 0.164 score 0.304 lr 3.88981e-06 
05/05/2021 21:29:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 4260 Ep: 1.58 loss 0.163 score 0.290 lr 3.92685e-06 
05/05/2021 21:30:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 4300 Ep: 1.59 loss 0.166 score 0.280 lr 3.96389e-06 
05/05/2021 21:31:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 4340 Ep: 1.61 loss 0.162 score 0.309 lr 4.00093e-06 
05/05/2021 21:32:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 4380 Ep: 1.62 loss 0.163 score 0.302 lr 4.03796e-06 
05/05/2021 21:33:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 4420 Ep: 1.64 loss 0.166 score 0.303 lr 4.075e-06 
05/05/2021 21:34:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 4460 Ep: 1.65 loss 0.166 score 0.291 lr 4.11204e-06 
05/05/2021 21:35:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 4500 Ep: 1.67 loss 0.166 score 0.298 lr 4.14907e-06 
05/05/2021 21:35:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 4540 Ep: 1.68 loss 0.166 score 0.304 lr 4.18611e-06 
05/05/2021 21:36:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 4580 Ep: 1.70 loss 0.161 score 0.310 lr 4.22315e-06 
05/05/2021 21:37:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 4620 Ep: 1.71 loss 0.163 score 0.310 lr 4.26019e-06 
05/05/2021 21:38:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 4660 Ep: 1.73 loss 0.164 score 0.296 lr 4.29722e-06 
05/05/2021 21:39:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 4700 Ep: 1.74 loss 0.159 score 0.300 lr 4.33426e-06 
05/05/2021 21:40:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 4740 Ep: 1.76 loss 0.162 score 0.316 lr 4.3713e-06 
05/05/2021 21:41:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 4780 Ep: 1.77 loss 0.162 score 0.295 lr 4.40833e-06 
05/05/2021 21:42:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 4820 Ep: 1.79 loss 0.160 score 0.295 lr 4.44537e-06 
05/05/2021 21:43:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 4860 Ep: 1.80 loss 0.153 score 0.312 lr 4.48241e-06 
05/05/2021 21:44:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 4900 Ep: 1.81 loss 0.161 score 0.305 lr 4.51944e-06 
05/05/2021 21:45:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 4940 Ep: 1.83 loss 0.163 score 0.305 lr 4.55648e-06 
05/05/2021 21:46:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 4980 Ep: 1.84 loss 0.165 score 0.298 lr 4.59352e-06 
05/05/2021 21:47:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 5020 Ep: 1.86 loss 0.164 score 0.305 lr 4.63056e-06 
05/05/2021 21:48:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 5060 Ep: 1.87 loss 0.160 score 0.309 lr 4.66759e-06 
05/05/2021 21:49:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 5100 Ep: 1.89 loss 0.156 score 0.308 lr 4.70463e-06 
05/05/2021 21:50:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 5140 Ep: 1.90 loss 0.166 score 0.300 lr 4.74167e-06 
05/05/2021 21:51:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 5180 Ep: 1.92 loss 0.163 score 0.302 lr 4.7787e-06 
05/05/2021 21:52:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 5220 Ep: 1.93 loss 0.159 score 0.310 lr 4.81574e-06 
05/05/2021 21:53:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 5260 Ep: 1.95 loss 0.161 score 0.304 lr 4.85278e-06 
05/05/2021 21:54:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 5300 Ep: 1.96 loss 0.158 score 0.312 lr 4.88981e-06 
05/05/2021 21:55:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 5340 Ep: 1.98 loss 0.160 score 0.313 lr 4.92685e-06 
05/05/2021 21:56:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 5380 Ep: 1.99 loss 0.167 score 0.286 lr 4.96389e-06 
05/05/2021 21:57:09 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  10%|         | 2/20 [2:42:34<24:08:38, 4828.78s/it]05/05/2021 22:15:37 - INFO - volta.train_utils -   Eval task TASK12 on iteration 5400 
05/05/2021 22:15:37 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 0.628 score 63.234 
05/05/2021 22:15:37 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/05/2021 22:16:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 5440 Ep: 2.01 loss 0.158 score 0.311 lr 4.99578e-06 
05/05/2021 22:16:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 5480 Ep: 2.03 loss 0.149 score 0.326 lr 4.99372e-06 
05/05/2021 22:17:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 5520 Ep: 2.04 loss 0.152 score 0.317 lr 4.98961e-06 
05/05/2021 22:18:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 5560 Ep: 2.06 loss 0.156 score 0.320 lr 4.98549e-06 
05/05/2021 22:19:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 5600 Ep: 2.07 loss 0.152 score 0.314 lr 4.98138e-06 
05/05/2021 22:20:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 5640 Ep: 2.09 loss 0.156 score 0.330 lr 4.97726e-06 
05/05/2021 22:21:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 5680 Ep: 2.10 loss 0.154 score 0.322 lr 4.97315e-06 
05/05/2021 22:22:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 5720 Ep: 2.12 loss 0.152 score 0.325 lr 4.96903e-06 
05/05/2021 22:23:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 5760 Ep: 2.13 loss 0.152 score 0.322 lr 4.96492e-06 
05/05/2021 22:24:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 5800 Ep: 2.15 loss 0.158 score 0.306 lr 4.9608e-06 
05/05/2021 22:25:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 5840 Ep: 2.16 loss 0.156 score 0.319 lr 4.95669e-06 
05/05/2021 22:26:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 5880 Ep: 2.18 loss 0.159 score 0.316 lr 4.95257e-06 
05/05/2021 22:27:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 5920 Ep: 2.19 loss 0.148 score 0.319 lr 4.94846e-06 
05/05/2021 22:28:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 5960 Ep: 2.21 loss 0.149 score 0.329 lr 4.94434e-06 
05/05/2021 22:29:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 6000 Ep: 2.22 loss 0.148 score 0.340 lr 4.94023e-06 
05/05/2021 22:30:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 6040 Ep: 2.24 loss 0.147 score 0.334 lr 4.93611e-06 
05/05/2021 22:31:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 6080 Ep: 2.25 loss 0.155 score 0.311 lr 4.932e-06 
05/05/2021 22:32:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 6120 Ep: 2.27 loss 0.150 score 0.336 lr 4.92788e-06 
05/05/2021 22:33:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 6160 Ep: 2.28 loss 0.155 score 0.327 lr 4.92377e-06 
05/05/2021 22:34:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 6200 Ep: 2.30 loss 0.148 score 0.323 lr 4.91965e-06 
05/05/2021 22:35:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 6240 Ep: 2.31 loss 0.150 score 0.320 lr 4.91553e-06 
05/05/2021 22:36:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 6280 Ep: 2.33 loss 0.157 score 0.309 lr 4.91142e-06 
05/05/2021 22:36:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 6320 Ep: 2.34 loss 0.148 score 0.332 lr 4.9073e-06 
05/05/2021 22:38:03 - INFO - volta.train_utils -   [NLVR2zh]: iter 6360 Ep: 2.36 loss 0.162 score 0.310 lr 4.90319e-06 
05/05/2021 22:38:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 6400 Ep: 2.37 loss 0.153 score 0.326 lr 4.89907e-06 
05/05/2021 22:39:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 6440 Ep: 2.39 loss 0.155 score 0.319 lr 4.89496e-06 
05/05/2021 22:40:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 6480 Ep: 2.40 loss 0.153 score 0.319 lr 4.89084e-06 
05/05/2021 22:41:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 6520 Ep: 2.41 loss 0.154 score 0.316 lr 4.88673e-06 
05/05/2021 22:42:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 6560 Ep: 2.43 loss 0.145 score 0.336 lr 4.88261e-06 
05/05/2021 22:44:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 6600 Ep: 2.44 loss 0.154 score 0.330 lr 4.8785e-06 
05/05/2021 22:45:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 6640 Ep: 2.46 loss 0.155 score 0.311 lr 4.87438e-06 
05/05/2021 22:46:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 6680 Ep: 2.47 loss 0.153 score 0.322 lr 4.87027e-06 
05/05/2021 22:47:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 6720 Ep: 2.49 loss 0.151 score 0.325 lr 4.86615e-06 
05/05/2021 22:48:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 6760 Ep: 2.50 loss 0.146 score 0.334 lr 4.86204e-06 
05/05/2021 22:49:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 6800 Ep: 2.52 loss 0.153 score 0.320 lr 4.85792e-06 
05/05/2021 22:50:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 6840 Ep: 2.53 loss 0.155 score 0.314 lr 4.85381e-06 
05/05/2021 22:50:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 6880 Ep: 2.55 loss 0.151 score 0.329 lr 4.84969e-06 
05/05/2021 22:52:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 6920 Ep: 2.56 loss 0.152 score 0.326 lr 4.84558e-06 
05/05/2021 22:52:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 6960 Ep: 2.58 loss 0.153 score 0.319 lr 4.84146e-06 
05/05/2021 22:53:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 7000 Ep: 2.59 loss 0.149 score 0.325 lr 4.83735e-06 
05/05/2021 22:54:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 7040 Ep: 2.61 loss 0.149 score 0.331 lr 4.83323e-06 
05/05/2021 22:55:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 7080 Ep: 2.62 loss 0.150 score 0.325 lr 4.82912e-06 
05/05/2021 22:56:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 7120 Ep: 2.64 loss 0.155 score 0.318 lr 4.825e-06 
05/05/2021 22:57:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 7160 Ep: 2.65 loss 0.148 score 0.330 lr 4.82088e-06 
05/05/2021 22:58:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 7200 Ep: 2.67 loss 0.154 score 0.321 lr 4.81677e-06 
05/05/2021 22:59:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 7240 Ep: 2.68 loss 0.148 score 0.317 lr 4.81265e-06 
05/05/2021 23:00:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 7280 Ep: 2.70 loss 0.155 score 0.316 lr 4.80854e-06 
05/05/2021 23:01:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 7320 Ep: 2.71 loss 0.146 score 0.337 lr 4.80442e-06 
05/05/2021 23:02:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 7360 Ep: 2.73 loss 0.145 score 0.333 lr 4.80031e-06 
05/05/2021 23:03:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 7400 Ep: 2.74 loss 0.150 score 0.329 lr 4.79619e-06 
05/05/2021 23:04:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 7440 Ep: 2.76 loss 0.153 score 0.327 lr 4.79208e-06 
05/05/2021 23:05:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 7480 Ep: 2.77 loss 0.142 score 0.338 lr 4.78796e-06 
05/05/2021 23:05:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 7520 Ep: 2.79 loss 0.145 score 0.334 lr 4.78385e-06 
05/05/2021 23:07:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 7560 Ep: 2.80 loss 0.149 score 0.335 lr 4.77973e-06 
05/05/2021 23:07:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 7600 Ep: 2.81 loss 0.156 score 0.330 lr 4.77562e-06 
05/05/2021 23:09:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 7640 Ep: 2.83 loss 0.152 score 0.318 lr 4.7715e-06 
05/05/2021 23:09:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 7680 Ep: 2.84 loss 0.148 score 0.330 lr 4.76739e-06 
05/05/2021 23:10:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 7720 Ep: 2.86 loss 0.152 score 0.336 lr 4.76327e-06 
05/05/2021 23:11:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 7760 Ep: 2.87 loss 0.148 score 0.321 lr 4.75916e-06 
05/05/2021 23:12:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 7800 Ep: 2.89 loss 0.146 score 0.321 lr 4.75504e-06 
05/05/2021 23:13:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 7840 Ep: 2.90 loss 0.150 score 0.332 lr 4.75093e-06 
05/05/2021 23:14:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 7880 Ep: 2.92 loss 0.153 score 0.329 lr 4.74681e-06 
05/05/2021 23:14:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 7920 Ep: 2.93 loss 0.153 score 0.336 lr 4.7427e-06 
05/05/2021 23:16:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 7960 Ep: 2.95 loss 0.150 score 0.339 lr 4.73858e-06 
05/05/2021 23:16:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 8000 Ep: 2.96 loss 0.142 score 0.332 lr 4.73447e-06 
05/05/2021 23:18:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 8040 Ep: 2.98 loss 0.138 score 0.348 lr 4.73035e-06 
05/05/2021 23:18:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 8080 Ep: 2.99 loss 0.147 score 0.346 lr 4.72623e-06 
05/05/2021 23:18:58 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  15%|        | 3/20 [4:04:23<22:54:57, 4852.80s/it]05/05/2021 23:35:29 - INFO - volta.train_utils -   Eval task TASK12 on iteration 8100 
05/05/2021 23:35:29 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 0.613 score 65.024 
05/05/2021 23:35:29 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/05/2021 23:36:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 8140 Ep: 3.01 loss 0.137 score 0.356 lr 4.72109e-06 
05/05/2021 23:36:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 8180 Ep: 3.03 loss 0.140 score 0.345 lr 4.71595e-06 
05/05/2021 23:37:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 8220 Ep: 3.04 loss 0.133 score 0.352 lr 4.71183e-06 
05/05/2021 23:38:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 8260 Ep: 3.06 loss 0.135 score 0.358 lr 4.70772e-06 
05/05/2021 23:39:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 8300 Ep: 3.07 loss 0.134 score 0.353 lr 4.7036e-06 
05/05/2021 23:40:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 8340 Ep: 3.09 loss 0.135 score 0.353 lr 4.69949e-06 
05/05/2021 23:41:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 8380 Ep: 3.10 loss 0.137 score 0.345 lr 4.69537e-06 
05/05/2021 23:41:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 8420 Ep: 3.12 loss 0.131 score 0.358 lr 4.69126e-06 
05/05/2021 23:42:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 8460 Ep: 3.13 loss 0.136 score 0.355 lr 4.68714e-06 
05/05/2021 23:43:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 8500 Ep: 3.15 loss 0.134 score 0.351 lr 4.68302e-06 
05/05/2021 23:44:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 8540 Ep: 3.16 loss 0.132 score 0.353 lr 4.67891e-06 
05/05/2021 23:45:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 8580 Ep: 3.18 loss 0.130 score 0.364 lr 4.67479e-06 
05/05/2021 23:47:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 8620 Ep: 3.19 loss 0.137 score 0.350 lr 4.67068e-06 
05/05/2021 23:48:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 8660 Ep: 3.21 loss 0.138 score 0.349 lr 4.66656e-06 
05/05/2021 23:49:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 8700 Ep: 3.22 loss 0.126 score 0.361 lr 4.66245e-06 
05/05/2021 23:50:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 8740 Ep: 3.24 loss 0.143 score 0.353 lr 4.65833e-06 
05/05/2021 23:51:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 8780 Ep: 3.25 loss 0.138 score 0.359 lr 4.65422e-06 
05/05/2021 23:52:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 8820 Ep: 3.27 loss 0.135 score 0.350 lr 4.6501e-06 
05/05/2021 23:53:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 8860 Ep: 3.28 loss 0.126 score 0.355 lr 4.64599e-06 
05/05/2021 23:54:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 8900 Ep: 3.30 loss 0.137 score 0.355 lr 4.64187e-06 
05/05/2021 23:55:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 8940 Ep: 3.31 loss 0.132 score 0.339 lr 4.63776e-06 
05/05/2021 23:56:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 8980 Ep: 3.33 loss 0.147 score 0.353 lr 4.63364e-06 
05/05/2021 23:57:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 9020 Ep: 3.34 loss 0.132 score 0.366 lr 4.62953e-06 
05/05/2021 23:58:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 9060 Ep: 3.36 loss 0.133 score 0.359 lr 4.62541e-06 
05/05/2021 23:59:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 9100 Ep: 3.37 loss 0.147 score 0.336 lr 4.6213e-06 
05/06/2021 00:00:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 9140 Ep: 3.39 loss 0.130 score 0.358 lr 4.61718e-06 
05/06/2021 00:01:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 9180 Ep: 3.40 loss 0.130 score 0.358 lr 4.61307e-06 
05/06/2021 00:02:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 9220 Ep: 3.41 loss 0.135 score 0.360 lr 4.60895e-06 
05/06/2021 00:03:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 9260 Ep: 3.43 loss 0.133 score 0.345 lr 4.60484e-06 
05/06/2021 00:04:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 9300 Ep: 3.44 loss 0.138 score 0.359 lr 4.60072e-06 
05/06/2021 00:05:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 9340 Ep: 3.46 loss 0.136 score 0.361 lr 4.5966e-06 
05/06/2021 00:06:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 9380 Ep: 3.47 loss 0.133 score 0.358 lr 4.59249e-06 
05/06/2021 00:07:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 9420 Ep: 3.49 loss 0.132 score 0.355 lr 4.58837e-06 
05/06/2021 00:08:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 9460 Ep: 3.50 loss 0.126 score 0.364 lr 4.58426e-06 
05/06/2021 00:09:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 9500 Ep: 3.52 loss 0.131 score 0.354 lr 4.58014e-06 
05/06/2021 00:09:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 9540 Ep: 3.53 loss 0.136 score 0.353 lr 4.57603e-06 
05/06/2021 00:10:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 9580 Ep: 3.55 loss 0.135 score 0.358 lr 4.57191e-06 
05/06/2021 00:11:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 9620 Ep: 3.56 loss 0.140 score 0.355 lr 4.5678e-06 
05/06/2021 00:12:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 9660 Ep: 3.58 loss 0.126 score 0.362 lr 4.56368e-06 
05/06/2021 00:13:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 9700 Ep: 3.59 loss 0.139 score 0.344 lr 4.55957e-06 
05/06/2021 00:14:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 9740 Ep: 3.61 loss 0.136 score 0.349 lr 4.55545e-06 
05/06/2021 00:14:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 9780 Ep: 3.62 loss 0.129 score 0.357 lr 4.55134e-06 
05/06/2021 00:15:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 9820 Ep: 3.64 loss 0.131 score 0.352 lr 4.54722e-06 
05/06/2021 00:16:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 9860 Ep: 3.65 loss 0.136 score 0.354 lr 4.54311e-06 
05/06/2021 00:17:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 9900 Ep: 3.67 loss 0.136 score 0.355 lr 4.53899e-06 
05/06/2021 00:18:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 9940 Ep: 3.68 loss 0.130 score 0.354 lr 4.53488e-06 
05/06/2021 00:19:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 9980 Ep: 3.70 loss 0.141 score 0.343 lr 4.53076e-06 
05/06/2021 00:20:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 10020 Ep: 3.71 loss 0.133 score 0.359 lr 4.52665e-06 
05/06/2021 00:21:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 10060 Ep: 3.73 loss 0.135 score 0.356 lr 4.52253e-06 
05/06/2021 00:22:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 10100 Ep: 3.74 loss 0.134 score 0.345 lr 4.51842e-06 
05/06/2021 00:22:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 10140 Ep: 3.76 loss 0.135 score 0.353 lr 4.5143e-06 
05/06/2021 00:23:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 10180 Ep: 3.77 loss 0.130 score 0.358 lr 4.51019e-06 
05/06/2021 00:24:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 10220 Ep: 3.79 loss 0.129 score 0.358 lr 4.50607e-06 
05/06/2021 00:25:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 10260 Ep: 3.80 loss 0.130 score 0.347 lr 4.50195e-06 
05/06/2021 00:26:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 10300 Ep: 3.81 loss 0.134 score 0.359 lr 4.49784e-06 
05/06/2021 00:27:03 - INFO - volta.train_utils -   [NLVR2zh]: iter 10340 Ep: 3.83 loss 0.130 score 0.349 lr 4.49372e-06 
05/06/2021 00:27:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 10380 Ep: 3.84 loss 0.131 score 0.355 lr 4.48961e-06 
05/06/2021 00:28:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 10420 Ep: 3.86 loss 0.139 score 0.359 lr 4.48549e-06 
05/06/2021 00:29:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 10460 Ep: 3.87 loss 0.132 score 0.360 lr 4.48138e-06 
05/06/2021 00:30:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 10500 Ep: 3.89 loss 0.129 score 0.368 lr 4.47726e-06 
05/06/2021 00:30:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 10540 Ep: 3.90 loss 0.131 score 0.351 lr 4.47315e-06 
05/06/2021 00:31:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 10580 Ep: 3.92 loss 0.133 score 0.352 lr 4.46903e-06 
05/06/2021 00:32:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 10620 Ep: 3.93 loss 0.138 score 0.353 lr 4.46492e-06 
05/06/2021 00:33:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 10660 Ep: 3.95 loss 0.135 score 0.353 lr 4.4608e-06 
05/06/2021 00:33:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 10700 Ep: 3.96 loss 0.135 score 0.353 lr 4.45669e-06 
05/06/2021 00:34:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 10740 Ep: 3.98 loss 0.129 score 0.368 lr 4.45257e-06 
05/06/2021 00:35:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 10780 Ep: 3.99 loss 0.140 score 0.350 lr 4.44846e-06 
05/06/2021 00:35:42 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  20%|        | 4/20 [5:21:07<21:14:12, 4778.26s/it]05/06/2021 00:52:22 - INFO - volta.train_utils -   Eval task TASK12 on iteration 10800 
05/06/2021 00:52:22 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 0.587 score 68.018 
05/06/2021 00:52:22 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/06/2021 00:52:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 10840 Ep: 4.01 loss 0.124 score 0.363 lr 4.44331e-06 
05/06/2021 00:53:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 10880 Ep: 4.03 loss 0.126 score 0.364 lr 4.43817e-06 
05/06/2021 00:54:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 10920 Ep: 4.04 loss 0.118 score 0.382 lr 4.43405e-06 
05/06/2021 00:54:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 10960 Ep: 4.06 loss 0.116 score 0.365 lr 4.42994e-06 
05/06/2021 00:55:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 11000 Ep: 4.07 loss 0.122 score 0.380 lr 4.42582e-06 
05/06/2021 00:56:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 11040 Ep: 4.09 loss 0.121 score 0.375 lr 4.42171e-06 
05/06/2021 00:56:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 11080 Ep: 4.10 loss 0.120 score 0.373 lr 4.41759e-06 
05/06/2021 00:57:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 11120 Ep: 4.12 loss 0.121 score 0.374 lr 4.41348e-06 
05/06/2021 00:58:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 11160 Ep: 4.13 loss 0.126 score 0.377 lr 4.40936e-06 
05/06/2021 00:58:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 11200 Ep: 4.15 loss 0.120 score 0.373 lr 4.40525e-06 
05/06/2021 00:59:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 11240 Ep: 4.16 loss 0.127 score 0.378 lr 4.40113e-06 
05/06/2021 01:00:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 11280 Ep: 4.18 loss 0.115 score 0.388 lr 4.39702e-06 
05/06/2021 01:00:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 11320 Ep: 4.19 loss 0.118 score 0.379 lr 4.3929e-06 
05/06/2021 01:01:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 11360 Ep: 4.21 loss 0.118 score 0.379 lr 4.38879e-06 
05/06/2021 01:02:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 11400 Ep: 4.22 loss 0.113 score 0.374 lr 4.38467e-06 
05/06/2021 01:02:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 11440 Ep: 4.24 loss 0.125 score 0.373 lr 4.38056e-06 
05/06/2021 01:03:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 11480 Ep: 4.25 loss 0.127 score 0.361 lr 4.37644e-06 
05/06/2021 01:04:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 11520 Ep: 4.27 loss 0.118 score 0.372 lr 4.37233e-06 
05/06/2021 01:05:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 11560 Ep: 4.28 loss 0.109 score 0.380 lr 4.36821e-06 
05/06/2021 01:05:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 11600 Ep: 4.30 loss 0.120 score 0.372 lr 4.36409e-06 
05/06/2021 01:06:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 11640 Ep: 4.31 loss 0.114 score 0.373 lr 4.35998e-06 
05/06/2021 01:07:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 11680 Ep: 4.33 loss 0.119 score 0.374 lr 4.35586e-06 
05/06/2021 01:07:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 11720 Ep: 4.34 loss 0.130 score 0.370 lr 4.35175e-06 
05/06/2021 01:08:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 11760 Ep: 4.36 loss 0.117 score 0.375 lr 4.34763e-06 
05/06/2021 01:09:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 11800 Ep: 4.37 loss 0.131 score 0.352 lr 4.34352e-06 
05/06/2021 01:10:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 11840 Ep: 4.39 loss 0.117 score 0.386 lr 4.3394e-06 
05/06/2021 01:10:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 11880 Ep: 4.40 loss 0.120 score 0.372 lr 4.33529e-06 
05/06/2021 01:11:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 11920 Ep: 4.41 loss 0.126 score 0.366 lr 4.33117e-06 
05/06/2021 01:12:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 11960 Ep: 4.43 loss 0.121 score 0.378 lr 4.32706e-06 
05/06/2021 01:13:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 12000 Ep: 4.44 loss 0.128 score 0.372 lr 4.32294e-06 
05/06/2021 01:14:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 12040 Ep: 4.46 loss 0.119 score 0.368 lr 4.31883e-06 
05/06/2021 01:14:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 12080 Ep: 4.47 loss 0.119 score 0.377 lr 4.31471e-06 
05/06/2021 01:15:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 12120 Ep: 4.49 loss 0.120 score 0.378 lr 4.3106e-06 
05/06/2021 01:16:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 12160 Ep: 4.50 loss 0.128 score 0.367 lr 4.30648e-06 
05/06/2021 01:17:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 12200 Ep: 4.52 loss 0.128 score 0.361 lr 4.30237e-06 
05/06/2021 01:18:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 12240 Ep: 4.53 loss 0.122 score 0.376 lr 4.29825e-06 
05/06/2021 01:18:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 12280 Ep: 4.55 loss 0.126 score 0.366 lr 4.29414e-06 
05/06/2021 01:19:48 - INFO - volta.train_utils -   [NLVR2zh]: iter 12320 Ep: 4.56 loss 0.115 score 0.375 lr 4.29002e-06 
05/06/2021 01:20:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 12360 Ep: 4.58 loss 0.120 score 0.370 lr 4.28591e-06 
05/06/2021 01:21:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 12400 Ep: 4.59 loss 0.121 score 0.381 lr 4.28179e-06 
05/06/2021 01:21:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 12440 Ep: 4.61 loss 0.119 score 0.370 lr 4.27767e-06 
05/06/2021 01:22:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 12480 Ep: 4.62 loss 0.118 score 0.375 lr 4.27356e-06 
05/06/2021 01:23:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 12520 Ep: 4.64 loss 0.126 score 0.357 lr 4.26944e-06 
05/06/2021 01:24:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 12560 Ep: 4.65 loss 0.117 score 0.369 lr 4.26533e-06 
05/06/2021 01:24:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 12600 Ep: 4.67 loss 0.107 score 0.380 lr 4.26121e-06 
05/06/2021 01:25:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 12640 Ep: 4.68 loss 0.131 score 0.365 lr 4.2571e-06 
05/06/2021 01:26:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 12680 Ep: 4.70 loss 0.118 score 0.375 lr 4.25298e-06 
05/06/2021 01:27:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 12720 Ep: 4.71 loss 0.125 score 0.376 lr 4.24887e-06 
05/06/2021 01:27:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 12760 Ep: 4.73 loss 0.121 score 0.377 lr 4.24475e-06 
05/06/2021 01:28:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 12800 Ep: 4.74 loss 0.116 score 0.371 lr 4.24064e-06 
05/06/2021 01:29:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 12840 Ep: 4.76 loss 0.123 score 0.372 lr 4.23652e-06 
05/06/2021 01:30:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 12880 Ep: 4.77 loss 0.125 score 0.370 lr 4.23241e-06 
05/06/2021 01:30:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 12920 Ep: 4.79 loss 0.126 score 0.374 lr 4.22829e-06 
05/06/2021 01:31:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 12960 Ep: 4.80 loss 0.113 score 0.372 lr 4.22418e-06 
05/06/2021 01:32:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 13000 Ep: 4.81 loss 0.120 score 0.379 lr 4.22006e-06 
05/06/2021 01:32:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 13040 Ep: 4.83 loss 0.116 score 0.365 lr 4.21595e-06 
05/06/2021 01:33:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 13080 Ep: 4.84 loss 0.121 score 0.380 lr 4.21183e-06 
05/06/2021 01:34:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 13120 Ep: 4.86 loss 0.119 score 0.371 lr 4.20772e-06 
05/06/2021 01:34:48 - INFO - volta.train_utils -   [NLVR2zh]: iter 13160 Ep: 4.87 loss 0.117 score 0.378 lr 4.2036e-06 
05/06/2021 01:35:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 13200 Ep: 4.89 loss 0.130 score 0.369 lr 4.19949e-06 
05/06/2021 01:36:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 13240 Ep: 4.90 loss 0.128 score 0.378 lr 4.19537e-06 
05/06/2021 01:36:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 13280 Ep: 4.92 loss 0.122 score 0.371 lr 4.19126e-06 
05/06/2021 01:37:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 13320 Ep: 4.93 loss 0.118 score 0.373 lr 4.18714e-06 
05/06/2021 01:38:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 13360 Ep: 4.95 loss 0.122 score 0.376 lr 4.18302e-06 
05/06/2021 01:39:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 13400 Ep: 4.96 loss 0.123 score 0.362 lr 4.17891e-06 
05/06/2021 01:40:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 13440 Ep: 4.98 loss 0.121 score 0.370 lr 4.17479e-06 
05/06/2021 01:40:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 13480 Ep: 4.99 loss 0.117 score 0.377 lr 4.17068e-06 
05/06/2021 01:40:55 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  25%|       | 5/20 [6:26:20<18:49:39, 4518.66s/it]05/06/2021 01:58:46 - INFO - volta.train_utils -   Eval task TASK12 on iteration 13500 
05/06/2021 01:58:46 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 0.624 score 68.018 
05/06/2021 01:59:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 13540 Ep: 5.01 loss 0.121 score 0.375 lr 4.16553e-06 
05/06/2021 01:59:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 13580 Ep: 5.03 loss 0.115 score 0.388 lr 4.16039e-06 
05/06/2021 02:00:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 13620 Ep: 5.04 loss 0.106 score 0.402 lr 4.15628e-06 
05/06/2021 02:00:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 13660 Ep: 5.06 loss 0.103 score 0.398 lr 4.15216e-06 
05/06/2021 02:01:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 13700 Ep: 5.07 loss 0.112 score 0.386 lr 4.14805e-06 
05/06/2021 02:02:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 13740 Ep: 5.09 loss 0.103 score 0.392 lr 4.14393e-06 
05/06/2021 02:02:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 13780 Ep: 5.10 loss 0.116 score 0.385 lr 4.13981e-06 
05/06/2021 02:03:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 13820 Ep: 5.12 loss 0.109 score 0.391 lr 4.1357e-06 
05/06/2021 02:03:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 13860 Ep: 5.13 loss 0.112 score 0.387 lr 4.13158e-06 
05/06/2021 02:04:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 13900 Ep: 5.15 loss 0.104 score 0.396 lr 4.12747e-06 
05/06/2021 02:04:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 13940 Ep: 5.16 loss 0.107 score 0.386 lr 4.12335e-06 
05/06/2021 02:05:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 13980 Ep: 5.18 loss 0.110 score 0.396 lr 4.11924e-06 
05/06/2021 02:06:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 14020 Ep: 5.19 loss 0.111 score 0.389 lr 4.11512e-06 
05/06/2021 02:06:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 14060 Ep: 5.21 loss 0.104 score 0.395 lr 4.11101e-06 
05/06/2021 02:07:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 14100 Ep: 5.22 loss 0.112 score 0.391 lr 4.10689e-06 
05/06/2021 02:08:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 14140 Ep: 5.24 loss 0.113 score 0.384 lr 4.10278e-06 
05/06/2021 02:08:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 14180 Ep: 5.25 loss 0.121 score 0.377 lr 4.09866e-06 
05/06/2021 02:09:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 14220 Ep: 5.27 loss 0.108 score 0.384 lr 4.09455e-06 
05/06/2021 02:10:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 14260 Ep: 5.28 loss 0.114 score 0.396 lr 4.09043e-06 
05/06/2021 02:11:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 14300 Ep: 5.30 loss 0.109 score 0.387 lr 4.08632e-06 
05/06/2021 02:12:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 14340 Ep: 5.31 loss 0.111 score 0.384 lr 4.0822e-06 
05/06/2021 02:12:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 14380 Ep: 5.33 loss 0.110 score 0.394 lr 4.07809e-06 
05/06/2021 02:13:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 14420 Ep: 5.34 loss 0.107 score 0.392 lr 4.07397e-06 
05/06/2021 02:14:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 14460 Ep: 5.36 loss 0.117 score 0.387 lr 4.06986e-06 
05/06/2021 02:15:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 14500 Ep: 5.37 loss 0.114 score 0.388 lr 4.06574e-06 
05/06/2021 02:15:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 14540 Ep: 5.39 loss 0.113 score 0.389 lr 4.06163e-06 
05/06/2021 02:16:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 14580 Ep: 5.40 loss 0.103 score 0.389 lr 4.05751e-06 
05/06/2021 02:17:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 14620 Ep: 5.41 loss 0.104 score 0.391 lr 4.0534e-06 
05/06/2021 02:18:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 14660 Ep: 5.43 loss 0.112 score 0.395 lr 4.04928e-06 
05/06/2021 02:18:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 14700 Ep: 5.44 loss 0.111 score 0.388 lr 4.04516e-06 
05/06/2021 02:19:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 14740 Ep: 5.46 loss 0.110 score 0.386 lr 4.04105e-06 
05/06/2021 02:20:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 14780 Ep: 5.47 loss 0.110 score 0.382 lr 4.03693e-06 
05/06/2021 02:21:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 14820 Ep: 5.49 loss 0.109 score 0.395 lr 4.03282e-06 
05/06/2021 02:21:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 14860 Ep: 5.50 loss 0.108 score 0.393 lr 4.0287e-06 
05/06/2021 02:22:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 14900 Ep: 5.52 loss 0.113 score 0.388 lr 4.02459e-06 
05/06/2021 02:23:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 14940 Ep: 5.53 loss 0.116 score 0.382 lr 4.02047e-06 
05/06/2021 02:24:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 14980 Ep: 5.55 loss 0.108 score 0.388 lr 4.01636e-06 
05/06/2021 02:24:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 15020 Ep: 5.56 loss 0.114 score 0.387 lr 4.01224e-06 
05/06/2021 02:25:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 15060 Ep: 5.58 loss 0.114 score 0.386 lr 4.00813e-06 
05/06/2021 02:26:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 15100 Ep: 5.59 loss 0.112 score 0.380 lr 4.00401e-06 
05/06/2021 02:26:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 15140 Ep: 5.61 loss 0.108 score 0.388 lr 3.9999e-06 
05/06/2021 02:27:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 15180 Ep: 5.62 loss 0.104 score 0.384 lr 3.99578e-06 
05/06/2021 02:28:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 15220 Ep: 5.64 loss 0.108 score 0.393 lr 3.99167e-06 
05/06/2021 02:28:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 15260 Ep: 5.65 loss 0.115 score 0.376 lr 3.98755e-06 
05/06/2021 02:29:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 15300 Ep: 5.67 loss 0.102 score 0.393 lr 3.98344e-06 
05/06/2021 02:30:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 15340 Ep: 5.68 loss 0.111 score 0.391 lr 3.97932e-06 
05/06/2021 02:30:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 15380 Ep: 5.70 loss 0.116 score 0.385 lr 3.97521e-06 
05/06/2021 02:31:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 15420 Ep: 5.71 loss 0.110 score 0.393 lr 3.97109e-06 
05/06/2021 02:32:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 15460 Ep: 5.73 loss 0.105 score 0.389 lr 3.96698e-06 
05/06/2021 02:33:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 15500 Ep: 5.74 loss 0.117 score 0.380 lr 3.96286e-06 
05/06/2021 02:34:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 15540 Ep: 5.76 loss 0.111 score 0.384 lr 3.95874e-06 
05/06/2021 02:35:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 15580 Ep: 5.77 loss 0.114 score 0.391 lr 3.95463e-06 
05/06/2021 02:35:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 15620 Ep: 5.79 loss 0.118 score 0.388 lr 3.95051e-06 
05/06/2021 02:36:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 15660 Ep: 5.80 loss 0.105 score 0.391 lr 3.9464e-06 
05/06/2021 02:37:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 15700 Ep: 5.81 loss 0.109 score 0.382 lr 3.94228e-06 
05/06/2021 02:38:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 15740 Ep: 5.83 loss 0.109 score 0.381 lr 3.93817e-06 
05/06/2021 02:38:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 15780 Ep: 5.84 loss 0.115 score 0.388 lr 3.93405e-06 
05/06/2021 02:39:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 15820 Ep: 5.86 loss 0.111 score 0.394 lr 3.92994e-06 
05/06/2021 02:40:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 15860 Ep: 5.87 loss 0.109 score 0.387 lr 3.92582e-06 
05/06/2021 02:40:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 15900 Ep: 5.89 loss 0.115 score 0.383 lr 3.92171e-06 
05/06/2021 02:41:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 15940 Ep: 5.90 loss 0.109 score 0.394 lr 3.91759e-06 
05/06/2021 02:42:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 15980 Ep: 5.92 loss 0.112 score 0.389 lr 3.91348e-06 
05/06/2021 02:43:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 16020 Ep: 5.93 loss 0.121 score 0.377 lr 3.90936e-06 
05/06/2021 02:44:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 16060 Ep: 5.95 loss 0.114 score 0.388 lr 3.90525e-06 
05/06/2021 02:44:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 16100 Ep: 5.96 loss 0.109 score 0.394 lr 3.90113e-06 
05/06/2021 02:45:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 16140 Ep: 5.98 loss 0.107 score 0.384 lr 3.89702e-06 
05/06/2021 02:46:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 16180 Ep: 5.99 loss 0.109 score 0.398 lr 3.8929e-06 
05/06/2021 02:46:27 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  30%|       | 6/20 [7:31:52<16:53:16, 4342.64s/it]05/06/2021 03:04:02 - INFO - volta.train_utils -   Eval task TASK12 on iteration 16200 
05/06/2021 03:04:02 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 0.662 score 69.364 
05/06/2021 03:04:02 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/06/2021 03:04:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 16240 Ep: 6.01 loss 0.095 score 0.401 lr 3.88776e-06 
05/06/2021 03:05:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 16280 Ep: 6.03 loss 0.098 score 0.404 lr 3.88261e-06 
05/06/2021 03:05:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 16320 Ep: 6.04 loss 0.094 score 0.399 lr 3.8785e-06 
05/06/2021 03:06:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 16360 Ep: 6.06 loss 0.102 score 0.397 lr 3.87438e-06 
05/06/2021 03:07:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 16400 Ep: 6.07 loss 0.098 score 0.408 lr 3.87027e-06 
05/06/2021 03:07:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 16440 Ep: 6.09 loss 0.113 score 0.400 lr 3.86615e-06 
05/06/2021 03:08:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 16480 Ep: 6.10 loss 0.096 score 0.409 lr 3.86204e-06 
05/06/2021 03:08:48 - INFO - volta.train_utils -   [NLVR2zh]: iter 16520 Ep: 6.12 loss 0.100 score 0.402 lr 3.85792e-06 
05/06/2021 03:09:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 16560 Ep: 6.13 loss 0.100 score 0.404 lr 3.85381e-06 
05/06/2021 03:09:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 16600 Ep: 6.15 loss 0.102 score 0.399 lr 3.84969e-06 
05/06/2021 03:10:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 16640 Ep: 6.16 loss 0.093 score 0.402 lr 3.84558e-06 
05/06/2021 03:11:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 16680 Ep: 6.18 loss 0.101 score 0.400 lr 3.84146e-06 
05/06/2021 03:11:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 16720 Ep: 6.19 loss 0.105 score 0.399 lr 3.83735e-06 
05/06/2021 03:12:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 16760 Ep: 6.21 loss 0.102 score 0.398 lr 3.83323e-06 
05/06/2021 03:13:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 16800 Ep: 6.22 loss 0.103 score 0.398 lr 3.82912e-06 
05/06/2021 03:14:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 16840 Ep: 6.24 loss 0.104 score 0.399 lr 3.825e-06 
05/06/2021 03:14:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 16880 Ep: 6.25 loss 0.100 score 0.406 lr 3.82088e-06 
05/06/2021 03:15:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 16920 Ep: 6.27 loss 0.099 score 0.404 lr 3.81677e-06 
05/06/2021 03:16:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 16960 Ep: 6.28 loss 0.095 score 0.404 lr 3.81265e-06 
05/06/2021 03:17:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 17000 Ep: 6.30 loss 0.091 score 0.400 lr 3.80854e-06 
05/06/2021 03:17:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 17040 Ep: 6.31 loss 0.093 score 0.388 lr 3.80442e-06 
05/06/2021 03:18:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 17080 Ep: 6.33 loss 0.096 score 0.406 lr 3.80031e-06 
05/06/2021 03:19:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 17120 Ep: 6.34 loss 0.102 score 0.409 lr 3.79619e-06 
05/06/2021 03:20:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 17160 Ep: 6.36 loss 0.097 score 0.410 lr 3.79208e-06 
05/06/2021 03:20:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 17200 Ep: 6.37 loss 0.095 score 0.411 lr 3.78796e-06 
05/06/2021 03:21:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 17240 Ep: 6.39 loss 0.094 score 0.408 lr 3.78385e-06 
05/06/2021 03:22:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 17280 Ep: 6.40 loss 0.095 score 0.398 lr 3.77973e-06 
05/06/2021 03:23:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 17320 Ep: 6.41 loss 0.097 score 0.401 lr 3.77562e-06 
05/06/2021 03:24:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 17360 Ep: 6.43 loss 0.100 score 0.399 lr 3.7715e-06 
05/06/2021 03:25:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 17400 Ep: 6.44 loss 0.103 score 0.406 lr 3.76739e-06 
05/06/2021 03:26:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 17440 Ep: 6.46 loss 0.094 score 0.402 lr 3.76327e-06 
05/06/2021 03:27:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 17480 Ep: 6.47 loss 0.097 score 0.398 lr 3.75916e-06 
05/06/2021 03:28:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 17520 Ep: 6.49 loss 0.086 score 0.399 lr 3.75504e-06 
05/06/2021 03:29:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 17560 Ep: 6.50 loss 0.085 score 0.402 lr 3.75093e-06 
05/06/2021 03:29:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 17600 Ep: 6.52 loss 0.096 score 0.397 lr 3.74681e-06 
05/06/2021 03:30:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 17640 Ep: 6.53 loss 0.100 score 0.394 lr 3.7427e-06 
05/06/2021 03:31:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 17680 Ep: 6.55 loss 0.103 score 0.400 lr 3.73858e-06 
05/06/2021 03:32:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 17720 Ep: 6.56 loss 0.109 score 0.386 lr 3.73447e-06 
05/06/2021 03:33:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 17760 Ep: 6.58 loss 0.099 score 0.398 lr 3.73035e-06 
05/06/2021 03:33:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 17800 Ep: 6.59 loss 0.099 score 0.390 lr 3.72623e-06 
05/06/2021 03:34:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 17840 Ep: 6.61 loss 0.107 score 0.395 lr 3.72212e-06 
05/06/2021 03:35:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 17880 Ep: 6.62 loss 0.098 score 0.401 lr 3.718e-06 
05/06/2021 03:36:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 17920 Ep: 6.64 loss 0.092 score 0.400 lr 3.71389e-06 
05/06/2021 03:37:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 17960 Ep: 6.65 loss 0.101 score 0.407 lr 3.70977e-06 
05/06/2021 03:38:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 18000 Ep: 6.67 loss 0.109 score 0.396 lr 3.70566e-06 
05/06/2021 03:38:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 18040 Ep: 6.68 loss 0.101 score 0.400 lr 3.70154e-06 
05/06/2021 03:39:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 18080 Ep: 6.70 loss 0.101 score 0.404 lr 3.69743e-06 
05/06/2021 03:40:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 18120 Ep: 6.71 loss 0.106 score 0.394 lr 3.69331e-06 
05/06/2021 03:41:03 - INFO - volta.train_utils -   [NLVR2zh]: iter 18160 Ep: 6.73 loss 0.099 score 0.404 lr 3.6892e-06 
05/06/2021 03:41:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 18200 Ep: 6.74 loss 0.108 score 0.391 lr 3.68508e-06 
05/06/2021 03:42:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 18240 Ep: 6.76 loss 0.097 score 0.404 lr 3.68097e-06 
05/06/2021 03:43:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 18280 Ep: 6.77 loss 0.107 score 0.404 lr 3.67685e-06 
05/06/2021 03:44:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 18320 Ep: 6.79 loss 0.097 score 0.407 lr 3.67274e-06 
05/06/2021 03:45:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 18360 Ep: 6.80 loss 0.106 score 0.389 lr 3.66862e-06 
05/06/2021 03:46:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 18400 Ep: 6.81 loss 0.100 score 0.402 lr 3.66451e-06 
05/06/2021 03:47:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 18440 Ep: 6.83 loss 0.094 score 0.397 lr 3.66039e-06 
05/06/2021 03:47:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 18480 Ep: 6.84 loss 0.103 score 0.402 lr 3.65628e-06 
05/06/2021 03:48:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 18520 Ep: 6.86 loss 0.091 score 0.404 lr 3.65216e-06 
05/06/2021 03:49:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 18560 Ep: 6.87 loss 0.089 score 0.404 lr 3.64805e-06 
05/06/2021 03:50:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 18600 Ep: 6.89 loss 0.100 score 0.405 lr 3.64393e-06 
05/06/2021 03:50:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 18640 Ep: 6.90 loss 0.108 score 0.394 lr 3.63981e-06 
05/06/2021 03:51:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 18680 Ep: 6.92 loss 0.102 score 0.393 lr 3.6357e-06 
05/06/2021 03:52:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 18720 Ep: 6.93 loss 0.099 score 0.405 lr 3.63158e-06 
05/06/2021 03:53:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 18760 Ep: 6.95 loss 0.102 score 0.396 lr 3.62747e-06 
05/06/2021 03:54:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 18800 Ep: 6.96 loss 0.095 score 0.398 lr 3.62335e-06 
05/06/2021 03:55:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 18840 Ep: 6.98 loss 0.102 score 0.402 lr 3.61924e-06 
05/06/2021 03:56:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 18880 Ep: 6.99 loss 0.107 score 0.404 lr 3.61512e-06 
05/06/2021 03:56:29 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  35%|      | 7/20 [8:41:56<15:31:53, 4301.03s/it]05/06/2021 04:16:35 - INFO - volta.train_utils -   Eval task TASK12 on iteration 18900 
05/06/2021 04:16:35 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 0.682 score 69.908 
05/06/2021 04:16:35 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/06/2021 04:17:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 18940 Ep: 7.01 loss 0.087 score 0.411 lr 3.60998e-06 
05/06/2021 04:17:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 18980 Ep: 7.03 loss 0.085 score 0.418 lr 3.60484e-06 
05/06/2021 04:18:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 19020 Ep: 7.04 loss 0.091 score 0.413 lr 3.60072e-06 
05/06/2021 04:19:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 19060 Ep: 7.06 loss 0.090 score 0.410 lr 3.5966e-06 
05/06/2021 04:20:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 19100 Ep: 7.07 loss 0.087 score 0.406 lr 3.59249e-06 
05/06/2021 04:21:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 19140 Ep: 7.09 loss 0.083 score 0.422 lr 3.58837e-06 
05/06/2021 04:22:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 19180 Ep: 7.10 loss 0.101 score 0.402 lr 3.58426e-06 
05/06/2021 04:23:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 19220 Ep: 7.12 loss 0.086 score 0.420 lr 3.58014e-06 
05/06/2021 04:23:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 19260 Ep: 7.13 loss 0.100 score 0.404 lr 3.57603e-06 
05/06/2021 04:24:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 19300 Ep: 7.15 loss 0.094 score 0.414 lr 3.57191e-06 
05/06/2021 04:25:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 19340 Ep: 7.16 loss 0.091 score 0.420 lr 3.5678e-06 
05/06/2021 04:26:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 19380 Ep: 7.18 loss 0.081 score 0.418 lr 3.56368e-06 
05/06/2021 04:27:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 19420 Ep: 7.19 loss 0.090 score 0.418 lr 3.55957e-06 
05/06/2021 04:28:48 - INFO - volta.train_utils -   [NLVR2zh]: iter 19460 Ep: 7.21 loss 0.075 score 0.415 lr 3.55545e-06 
05/06/2021 04:29:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 19500 Ep: 7.22 loss 0.090 score 0.412 lr 3.55134e-06 
05/06/2021 04:30:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 19540 Ep: 7.24 loss 0.096 score 0.408 lr 3.54722e-06 
05/06/2021 04:31:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 19580 Ep: 7.25 loss 0.085 score 0.418 lr 3.54311e-06 
05/06/2021 04:32:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 19620 Ep: 7.27 loss 0.096 score 0.412 lr 3.53899e-06 
05/06/2021 04:33:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 19660 Ep: 7.28 loss 0.093 score 0.414 lr 3.53488e-06 
05/06/2021 04:34:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 19700 Ep: 7.30 loss 0.084 score 0.415 lr 3.53076e-06 
05/06/2021 04:35:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 19740 Ep: 7.31 loss 0.097 score 0.410 lr 3.52665e-06 
05/06/2021 04:35:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 19780 Ep: 7.33 loss 0.081 score 0.417 lr 3.52253e-06 
05/06/2021 04:36:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 19820 Ep: 7.34 loss 0.096 score 0.411 lr 3.51842e-06 
05/06/2021 04:37:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 19860 Ep: 7.36 loss 0.091 score 0.414 lr 3.5143e-06 
05/06/2021 04:38:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 19900 Ep: 7.37 loss 0.100 score 0.403 lr 3.51019e-06 
05/06/2021 04:39:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 19940 Ep: 7.39 loss 0.092 score 0.415 lr 3.50607e-06 
05/06/2021 04:40:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 19980 Ep: 7.40 loss 0.090 score 0.407 lr 3.50195e-06 
05/06/2021 04:41:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 20020 Ep: 7.41 loss 0.087 score 0.416 lr 3.49784e-06 
05/06/2021 04:42:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 20060 Ep: 7.43 loss 0.081 score 0.422 lr 3.49372e-06 
05/06/2021 04:43:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 20100 Ep: 7.44 loss 0.093 score 0.410 lr 3.48961e-06 
05/06/2021 04:44:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 20140 Ep: 7.46 loss 0.092 score 0.414 lr 3.48549e-06 
05/06/2021 04:45:03 - INFO - volta.train_utils -   [NLVR2zh]: iter 20180 Ep: 7.47 loss 0.086 score 0.418 lr 3.48138e-06 
05/06/2021 04:45:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 20220 Ep: 7.49 loss 0.093 score 0.413 lr 3.47726e-06 
05/06/2021 04:46:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 20260 Ep: 7.50 loss 0.093 score 0.411 lr 3.47315e-06 
05/06/2021 04:47:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 20300 Ep: 7.52 loss 0.086 score 0.409 lr 3.46903e-06 
05/06/2021 04:48:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 20340 Ep: 7.53 loss 0.084 score 0.416 lr 3.46492e-06 
05/06/2021 04:48:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 20380 Ep: 7.55 loss 0.097 score 0.409 lr 3.4608e-06 
05/06/2021 04:49:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 20420 Ep: 7.56 loss 0.089 score 0.412 lr 3.45669e-06 
05/06/2021 04:50:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 20460 Ep: 7.58 loss 0.092 score 0.401 lr 3.45257e-06 
05/06/2021 04:51:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 20500 Ep: 7.59 loss 0.091 score 0.407 lr 3.44846e-06 
05/06/2021 04:51:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 20540 Ep: 7.61 loss 0.093 score 0.412 lr 3.44434e-06 
05/06/2021 04:52:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 20580 Ep: 7.62 loss 0.090 score 0.411 lr 3.44023e-06 
05/06/2021 04:53:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 20620 Ep: 7.64 loss 0.095 score 0.407 lr 3.43611e-06 
05/06/2021 04:54:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 20660 Ep: 7.65 loss 0.092 score 0.402 lr 3.432e-06 
05/06/2021 04:55:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 20700 Ep: 7.67 loss 0.096 score 0.414 lr 3.42788e-06 
05/06/2021 04:55:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 20740 Ep: 7.68 loss 0.096 score 0.405 lr 3.42377e-06 
05/06/2021 04:56:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 20780 Ep: 7.70 loss 0.095 score 0.409 lr 3.41965e-06 
05/06/2021 04:57:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 20820 Ep: 7.71 loss 0.089 score 0.418 lr 3.41553e-06 
05/06/2021 04:57:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 20860 Ep: 7.73 loss 0.092 score 0.410 lr 3.41142e-06 
05/06/2021 04:58:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 20900 Ep: 7.74 loss 0.098 score 0.405 lr 3.4073e-06 
05/06/2021 04:59:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 20940 Ep: 7.76 loss 0.098 score 0.404 lr 3.40319e-06 
05/06/2021 05:00:03 - INFO - volta.train_utils -   [NLVR2zh]: iter 20980 Ep: 7.77 loss 0.089 score 0.407 lr 3.39907e-06 
05/06/2021 05:00:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 21020 Ep: 7.79 loss 0.085 score 0.418 lr 3.39496e-06 
05/06/2021 05:01:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 21060 Ep: 7.80 loss 0.085 score 0.414 lr 3.39084e-06 
05/06/2021 05:02:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 21100 Ep: 7.81 loss 0.090 score 0.414 lr 3.38673e-06 
05/06/2021 05:03:03 - INFO - volta.train_utils -   [NLVR2zh]: iter 21140 Ep: 7.83 loss 0.094 score 0.408 lr 3.38261e-06 
05/06/2021 05:03:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 21180 Ep: 7.84 loss 0.093 score 0.409 lr 3.3785e-06 
05/06/2021 05:04:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 21220 Ep: 7.86 loss 0.091 score 0.407 lr 3.37438e-06 
05/06/2021 05:05:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 21260 Ep: 7.87 loss 0.091 score 0.414 lr 3.37027e-06 
05/06/2021 05:06:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 21300 Ep: 7.89 loss 0.096 score 0.406 lr 3.36615e-06 
05/06/2021 05:06:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 21340 Ep: 7.90 loss 0.099 score 0.406 lr 3.36204e-06 
05/06/2021 05:07:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 21380 Ep: 7.92 loss 0.092 score 0.411 lr 3.35792e-06 
05/06/2021 05:08:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 21420 Ep: 7.93 loss 0.102 score 0.400 lr 3.35381e-06 
05/06/2021 05:09:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 21460 Ep: 7.95 loss 0.095 score 0.411 lr 3.34969e-06 
05/06/2021 05:09:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 21500 Ep: 7.96 loss 0.084 score 0.418 lr 3.34558e-06 
05/06/2021 05:10:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 21540 Ep: 7.98 loss 0.096 score 0.404 lr 3.34146e-06 
05/06/2021 05:11:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 21580 Ep: 7.99 loss 0.101 score 0.416 lr 3.33735e-06 
05/06/2021 05:11:41 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  40%|      | 8/20 [9:57:07<14:32:47, 4363.95s/it]05/06/2021 05:33:13 - INFO - volta.train_utils -   Eval task TASK12 on iteration 21600 
05/06/2021 05:33:13 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 0.717 score 69.794 
05/06/2021 05:33:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 21640 Ep: 8.01 loss 0.079 score 0.421 lr 3.3322e-06 
05/06/2021 05:34:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 21680 Ep: 8.03 loss 0.073 score 0.432 lr 3.32706e-06 
05/06/2021 05:34:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 21720 Ep: 8.04 loss 0.082 score 0.426 lr 3.32294e-06 
05/06/2021 05:35:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 21760 Ep: 8.06 loss 0.082 score 0.423 lr 3.31883e-06 
05/06/2021 05:36:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 21800 Ep: 8.07 loss 0.072 score 0.432 lr 3.31471e-06 
05/06/2021 05:36:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 21840 Ep: 8.09 loss 0.078 score 0.424 lr 3.3106e-06 
05/06/2021 05:37:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 21880 Ep: 8.10 loss 0.079 score 0.430 lr 3.30648e-06 
05/06/2021 05:38:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 21920 Ep: 8.12 loss 0.081 score 0.419 lr 3.30237e-06 
05/06/2021 05:38:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 21960 Ep: 8.13 loss 0.082 score 0.416 lr 3.29825e-06 
05/06/2021 05:39:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 22000 Ep: 8.15 loss 0.073 score 0.421 lr 3.29414e-06 
05/06/2021 05:39:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 22040 Ep: 8.16 loss 0.085 score 0.422 lr 3.29002e-06 
05/06/2021 05:40:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 22080 Ep: 8.18 loss 0.083 score 0.417 lr 3.28591e-06 
05/06/2021 05:41:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 22120 Ep: 8.19 loss 0.078 score 0.420 lr 3.28179e-06 
05/06/2021 05:41:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 22160 Ep: 8.21 loss 0.089 score 0.418 lr 3.27767e-06 
05/06/2021 05:42:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 22200 Ep: 8.22 loss 0.080 score 0.418 lr 3.27356e-06 
05/06/2021 05:43:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 22240 Ep: 8.24 loss 0.077 score 0.422 lr 3.26944e-06 
05/06/2021 05:44:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 22280 Ep: 8.25 loss 0.081 score 0.423 lr 3.26533e-06 
05/06/2021 05:44:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 22320 Ep: 8.27 loss 0.077 score 0.432 lr 3.26121e-06 
05/06/2021 05:45:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 22360 Ep: 8.28 loss 0.087 score 0.429 lr 3.2571e-06 
05/06/2021 05:46:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 22400 Ep: 8.30 loss 0.083 score 0.421 lr 3.25298e-06 
05/06/2021 05:46:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 22440 Ep: 8.31 loss 0.082 score 0.425 lr 3.24887e-06 
05/06/2021 05:47:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 22480 Ep: 8.33 loss 0.083 score 0.428 lr 3.24475e-06 
05/06/2021 05:48:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 22520 Ep: 8.34 loss 0.079 score 0.426 lr 3.24064e-06 
05/06/2021 05:49:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 22560 Ep: 8.36 loss 0.089 score 0.424 lr 3.23652e-06 
05/06/2021 05:49:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 22600 Ep: 8.37 loss 0.082 score 0.426 lr 3.23241e-06 
05/06/2021 05:50:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 22640 Ep: 8.39 loss 0.087 score 0.420 lr 3.22829e-06 
05/06/2021 05:51:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 22680 Ep: 8.40 loss 0.076 score 0.422 lr 3.22418e-06 
05/06/2021 05:52:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 22720 Ep: 8.41 loss 0.088 score 0.419 lr 3.22006e-06 
05/06/2021 05:53:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 22760 Ep: 8.43 loss 0.084 score 0.420 lr 3.21595e-06 
05/06/2021 05:54:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 22800 Ep: 8.44 loss 0.083 score 0.424 lr 3.21183e-06 
05/06/2021 05:55:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 22840 Ep: 8.46 loss 0.083 score 0.413 lr 3.20772e-06 
05/06/2021 05:57:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 22880 Ep: 8.47 loss 0.072 score 0.427 lr 3.2036e-06 
05/06/2021 05:57:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 22920 Ep: 8.49 loss 0.091 score 0.419 lr 3.19949e-06 
05/06/2021 05:59:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 22960 Ep: 8.50 loss 0.080 score 0.420 lr 3.19537e-06 
05/06/2021 05:59:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 23000 Ep: 8.52 loss 0.089 score 0.422 lr 3.19126e-06 
05/06/2021 06:01:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 23040 Ep: 8.53 loss 0.073 score 0.425 lr 3.18714e-06 
05/06/2021 06:02:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 23080 Ep: 8.55 loss 0.077 score 0.426 lr 3.18302e-06 
05/06/2021 06:03:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 23120 Ep: 8.56 loss 0.078 score 0.420 lr 3.17891e-06 
05/06/2021 06:04:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 23160 Ep: 8.58 loss 0.077 score 0.427 lr 3.17479e-06 
05/06/2021 06:05:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 23200 Ep: 8.59 loss 0.082 score 0.413 lr 3.17068e-06 
05/06/2021 06:06:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 23240 Ep: 8.61 loss 0.081 score 0.425 lr 3.16656e-06 
05/06/2021 06:06:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 23280 Ep: 8.62 loss 0.079 score 0.418 lr 3.16245e-06 
05/06/2021 06:07:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 23320 Ep: 8.64 loss 0.087 score 0.413 lr 3.15833e-06 
05/06/2021 06:08:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 23360 Ep: 8.65 loss 0.090 score 0.420 lr 3.15422e-06 
05/06/2021 06:09:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 23400 Ep: 8.67 loss 0.085 score 0.427 lr 3.1501e-06 
05/06/2021 06:09:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 23440 Ep: 8.68 loss 0.081 score 0.416 lr 3.14599e-06 
05/06/2021 06:10:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 23480 Ep: 8.70 loss 0.079 score 0.420 lr 3.14187e-06 
05/06/2021 06:11:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 23520 Ep: 8.71 loss 0.081 score 0.424 lr 3.13776e-06 
05/06/2021 06:12:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 23560 Ep: 8.73 loss 0.081 score 0.420 lr 3.13364e-06 
05/06/2021 06:13:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 23600 Ep: 8.74 loss 0.090 score 0.423 lr 3.12953e-06 
05/06/2021 06:13:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 23640 Ep: 8.76 loss 0.085 score 0.416 lr 3.12541e-06 
05/06/2021 06:14:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 23680 Ep: 8.77 loss 0.087 score 0.418 lr 3.1213e-06 
05/06/2021 06:15:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 23720 Ep: 8.79 loss 0.074 score 0.420 lr 3.11718e-06 
05/06/2021 06:16:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 23760 Ep: 8.80 loss 0.081 score 0.419 lr 3.11307e-06 
05/06/2021 06:17:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 23800 Ep: 8.81 loss 0.088 score 0.420 lr 3.10895e-06 
05/06/2021 06:18:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 23840 Ep: 8.83 loss 0.083 score 0.418 lr 3.10484e-06 
05/06/2021 06:18:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 23880 Ep: 8.84 loss 0.078 score 0.424 lr 3.10072e-06 
05/06/2021 06:19:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 23920 Ep: 8.86 loss 0.090 score 0.413 lr 3.0966e-06 
05/06/2021 06:20:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 23960 Ep: 8.87 loss 0.077 score 0.413 lr 3.09249e-06 
05/06/2021 06:21:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 24000 Ep: 8.89 loss 0.080 score 0.425 lr 3.08837e-06 
05/06/2021 06:22:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 24040 Ep: 8.90 loss 0.090 score 0.417 lr 3.08426e-06 
05/06/2021 06:22:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 24080 Ep: 8.92 loss 0.083 score 0.419 lr 3.08014e-06 
05/06/2021 06:23:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 24120 Ep: 8.93 loss 0.077 score 0.421 lr 3.07603e-06 
05/06/2021 06:24:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 24160 Ep: 8.95 loss 0.079 score 0.428 lr 3.07191e-06 
05/06/2021 06:25:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 24200 Ep: 8.96 loss 0.083 score 0.421 lr 3.0678e-06 
05/06/2021 06:26:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 24240 Ep: 8.98 loss 0.082 score 0.422 lr 3.06368e-06 
05/06/2021 06:27:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 24280 Ep: 8.99 loss 0.085 score 0.421 lr 3.05957e-06 
05/06/2021 06:27:19 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  45%|     | 9/20 [11:12:46<13:29:42, 4416.63s/it]05/06/2021 06:49:13 - INFO - volta.train_utils -   Eval task TASK12 on iteration 24300 
05/06/2021 06:49:13 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 0.777 score 69.579 
05/06/2021 06:49:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 24340 Ep: 9.01 loss 0.069 score 0.435 lr 3.05442e-06 
05/06/2021 06:50:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 24380 Ep: 9.03 loss 0.081 score 0.430 lr 3.04928e-06 
05/06/2021 06:50:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 24420 Ep: 9.04 loss 0.076 score 0.433 lr 3.04516e-06 
05/06/2021 06:51:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 24460 Ep: 9.06 loss 0.072 score 0.438 lr 3.04105e-06 
05/06/2021 06:52:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 24500 Ep: 9.07 loss 0.076 score 0.429 lr 3.03693e-06 
05/06/2021 06:52:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 24540 Ep: 9.09 loss 0.070 score 0.430 lr 3.03282e-06 
05/06/2021 06:53:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 24580 Ep: 9.10 loss 0.073 score 0.432 lr 3.0287e-06 
05/06/2021 06:54:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 24620 Ep: 9.12 loss 0.063 score 0.443 lr 3.02459e-06 
05/06/2021 06:55:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 24660 Ep: 9.13 loss 0.072 score 0.428 lr 3.02047e-06 
05/06/2021 06:55:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 24700 Ep: 9.15 loss 0.079 score 0.431 lr 3.01636e-06 
05/06/2021 06:56:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 24740 Ep: 9.16 loss 0.069 score 0.434 lr 3.01224e-06 
05/06/2021 06:57:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 24780 Ep: 9.18 loss 0.066 score 0.439 lr 3.00813e-06 
05/06/2021 06:58:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 24820 Ep: 9.19 loss 0.084 score 0.424 lr 3.00401e-06 
05/06/2021 06:58:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 24860 Ep: 9.21 loss 0.074 score 0.427 lr 2.9999e-06 
05/06/2021 06:59:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 24900 Ep: 9.22 loss 0.075 score 0.427 lr 2.99578e-06 
05/06/2021 07:00:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 24940 Ep: 9.24 loss 0.077 score 0.427 lr 2.99167e-06 
05/06/2021 07:01:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 24980 Ep: 9.25 loss 0.072 score 0.438 lr 2.98755e-06 
05/06/2021 07:01:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 25020 Ep: 9.27 loss 0.068 score 0.431 lr 2.98344e-06 
05/06/2021 07:02:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 25060 Ep: 9.28 loss 0.078 score 0.429 lr 2.97932e-06 
05/06/2021 07:03:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 25100 Ep: 9.30 loss 0.074 score 0.433 lr 2.97521e-06 
05/06/2021 07:03:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 25140 Ep: 9.31 loss 0.066 score 0.442 lr 2.97109e-06 
05/06/2021 07:04:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 25180 Ep: 9.33 loss 0.076 score 0.432 lr 2.96698e-06 
05/06/2021 07:05:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 25220 Ep: 9.34 loss 0.079 score 0.426 lr 2.96286e-06 
05/06/2021 07:05:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 25260 Ep: 9.36 loss 0.074 score 0.435 lr 2.95874e-06 
05/06/2021 07:06:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 25300 Ep: 9.37 loss 0.077 score 0.430 lr 2.95463e-06 
05/06/2021 07:07:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 25340 Ep: 9.39 loss 0.083 score 0.433 lr 2.95051e-06 
05/06/2021 07:08:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 25380 Ep: 9.40 loss 0.076 score 0.429 lr 2.9464e-06 
05/06/2021 07:09:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 25420 Ep: 9.41 loss 0.083 score 0.422 lr 2.94228e-06 
05/06/2021 07:09:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 25460 Ep: 9.43 loss 0.069 score 0.438 lr 2.93817e-06 
05/06/2021 07:10:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 25500 Ep: 9.44 loss 0.062 score 0.437 lr 2.93405e-06 
05/06/2021 07:11:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 25540 Ep: 9.46 loss 0.074 score 0.429 lr 2.92994e-06 
05/06/2021 07:11:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 25580 Ep: 9.47 loss 0.079 score 0.434 lr 2.92582e-06 
05/06/2021 07:12:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 25620 Ep: 9.49 loss 0.083 score 0.425 lr 2.92171e-06 
05/06/2021 07:13:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 25660 Ep: 9.50 loss 0.063 score 0.440 lr 2.91759e-06 
05/06/2021 07:13:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 25700 Ep: 9.52 loss 0.069 score 0.433 lr 2.91348e-06 
05/06/2021 07:14:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 25740 Ep: 9.53 loss 0.085 score 0.431 lr 2.90936e-06 
05/06/2021 07:15:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 25780 Ep: 9.55 loss 0.067 score 0.432 lr 2.90525e-06 
05/06/2021 07:16:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 25820 Ep: 9.56 loss 0.075 score 0.427 lr 2.90113e-06 
05/06/2021 07:17:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 25860 Ep: 9.58 loss 0.071 score 0.430 lr 2.89702e-06 
05/06/2021 07:17:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 25900 Ep: 9.59 loss 0.078 score 0.427 lr 2.8929e-06 
05/06/2021 07:18:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 25940 Ep: 9.61 loss 0.074 score 0.421 lr 2.88879e-06 
05/06/2021 07:19:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 25980 Ep: 9.62 loss 0.066 score 0.432 lr 2.88467e-06 
05/06/2021 07:20:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 26020 Ep: 9.64 loss 0.077 score 0.430 lr 2.88056e-06 
05/06/2021 07:21:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 26060 Ep: 9.65 loss 0.075 score 0.438 lr 2.87644e-06 
05/06/2021 07:21:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 26100 Ep: 9.67 loss 0.090 score 0.420 lr 2.87233e-06 
05/06/2021 07:22:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 26140 Ep: 9.68 loss 0.072 score 0.432 lr 2.86821e-06 
05/06/2021 07:23:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 26180 Ep: 9.70 loss 0.075 score 0.432 lr 2.86409e-06 
05/06/2021 07:23:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 26220 Ep: 9.71 loss 0.085 score 0.425 lr 2.85998e-06 
05/06/2021 07:24:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 26260 Ep: 9.73 loss 0.070 score 0.436 lr 2.85586e-06 
05/06/2021 07:25:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 26300 Ep: 9.74 loss 0.070 score 0.426 lr 2.85175e-06 
05/06/2021 07:26:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 26340 Ep: 9.76 loss 0.073 score 0.427 lr 2.84763e-06 
05/06/2021 07:26:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 26380 Ep: 9.77 loss 0.067 score 0.427 lr 2.84352e-06 
05/06/2021 07:27:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 26420 Ep: 9.79 loss 0.067 score 0.442 lr 2.8394e-06 
05/06/2021 07:28:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 26460 Ep: 9.80 loss 0.081 score 0.429 lr 2.83529e-06 
05/06/2021 07:29:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 26500 Ep: 9.81 loss 0.071 score 0.433 lr 2.83117e-06 
05/06/2021 07:30:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 26540 Ep: 9.83 loss 0.074 score 0.435 lr 2.82706e-06 
05/06/2021 07:30:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 26580 Ep: 9.84 loss 0.073 score 0.432 lr 2.82294e-06 
05/06/2021 07:31:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 26620 Ep: 9.86 loss 0.070 score 0.435 lr 2.81883e-06 
05/06/2021 07:32:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 26660 Ep: 9.87 loss 0.083 score 0.423 lr 2.81471e-06 
05/06/2021 07:33:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 26700 Ep: 9.89 loss 0.063 score 0.434 lr 2.8106e-06 
05/06/2021 07:34:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 26740 Ep: 9.90 loss 0.076 score 0.431 lr 2.80648e-06 
05/06/2021 07:34:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 26780 Ep: 9.92 loss 0.070 score 0.434 lr 2.80237e-06 
05/06/2021 07:35:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 26820 Ep: 9.93 loss 0.076 score 0.425 lr 2.79825e-06 
05/06/2021 07:36:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 26860 Ep: 9.95 loss 0.078 score 0.422 lr 2.79414e-06 
05/06/2021 07:37:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 26900 Ep: 9.96 loss 0.082 score 0.422 lr 2.79002e-06 
05/06/2021 07:37:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 26940 Ep: 9.98 loss 0.077 score 0.423 lr 2.78591e-06 
05/06/2021 07:38:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 26980 Ep: 9.99 loss 0.077 score 0.428 lr 2.78179e-06 
05/06/2021 07:38:50 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  50%|     | 10/20 [12:24:17<12:09:47, 4378.77s/it]05/06/2021 07:56:32 - INFO - volta.train_utils -   Eval task TASK12 on iteration 27000 
05/06/2021 07:56:32 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 0.850 score 69.679 
05/06/2021 07:56:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 27040 Ep: 10.01 loss 0.064 score 0.436 lr 2.77665e-06 
05/06/2021 07:57:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 27080 Ep: 10.03 loss 0.068 score 0.431 lr 2.7715e-06 
05/06/2021 07:58:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 27120 Ep: 10.04 loss 0.067 score 0.439 lr 2.76739e-06 
05/06/2021 07:58:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 27160 Ep: 10.06 loss 0.063 score 0.442 lr 2.76327e-06 
05/06/2021 07:59:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 27200 Ep: 10.07 loss 0.066 score 0.441 lr 2.75916e-06 
05/06/2021 07:59:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 27240 Ep: 10.09 loss 0.065 score 0.439 lr 2.75504e-06 
05/06/2021 08:00:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 27280 Ep: 10.10 loss 0.066 score 0.438 lr 2.75093e-06 
05/06/2021 08:01:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 27320 Ep: 10.12 loss 0.062 score 0.444 lr 2.74681e-06 
05/06/2021 08:01:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 27360 Ep: 10.13 loss 0.063 score 0.443 lr 2.7427e-06 
05/06/2021 08:02:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 27400 Ep: 10.15 loss 0.068 score 0.438 lr 2.73858e-06 
05/06/2021 08:02:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 27440 Ep: 10.16 loss 0.061 score 0.444 lr 2.73447e-06 
05/06/2021 08:03:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 27480 Ep: 10.18 loss 0.061 score 0.439 lr 2.73035e-06 
05/06/2021 08:04:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 27520 Ep: 10.19 loss 0.070 score 0.443 lr 2.72623e-06 
05/06/2021 08:04:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 27560 Ep: 10.21 loss 0.068 score 0.442 lr 2.72212e-06 
05/06/2021 08:05:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 27600 Ep: 10.22 loss 0.069 score 0.436 lr 2.718e-06 
05/06/2021 08:06:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 27640 Ep: 10.24 loss 0.071 score 0.439 lr 2.71389e-06 
05/06/2021 08:06:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 27680 Ep: 10.25 loss 0.065 score 0.436 lr 2.70977e-06 
05/06/2021 08:07:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 27720 Ep: 10.27 loss 0.068 score 0.436 lr 2.70566e-06 
05/06/2021 08:08:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 27760 Ep: 10.28 loss 0.067 score 0.427 lr 2.70154e-06 
05/06/2021 08:09:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 27800 Ep: 10.30 loss 0.066 score 0.438 lr 2.69743e-06 
05/06/2021 08:09:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 27840 Ep: 10.31 loss 0.063 score 0.448 lr 2.69331e-06 
05/06/2021 08:10:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 27880 Ep: 10.33 loss 0.072 score 0.435 lr 2.6892e-06 
05/06/2021 08:11:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 27920 Ep: 10.34 loss 0.068 score 0.435 lr 2.68508e-06 
05/06/2021 08:12:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 27960 Ep: 10.36 loss 0.061 score 0.444 lr 2.68097e-06 
05/06/2021 08:12:48 - INFO - volta.train_utils -   [NLVR2zh]: iter 28000 Ep: 10.37 loss 0.077 score 0.436 lr 2.67685e-06 
05/06/2021 08:13:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 28040 Ep: 10.39 loss 0.061 score 0.445 lr 2.67274e-06 
05/06/2021 08:14:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 28080 Ep: 10.40 loss 0.056 score 0.447 lr 2.66862e-06 
05/06/2021 08:15:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 28120 Ep: 10.41 loss 0.066 score 0.437 lr 2.66451e-06 
05/06/2021 08:15:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 28160 Ep: 10.43 loss 0.057 score 0.446 lr 2.66039e-06 
05/06/2021 08:16:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 28200 Ep: 10.44 loss 0.072 score 0.439 lr 2.65628e-06 
05/06/2021 08:17:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 28240 Ep: 10.46 loss 0.068 score 0.433 lr 2.65216e-06 
05/06/2021 08:18:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 28280 Ep: 10.47 loss 0.067 score 0.434 lr 2.64805e-06 
05/06/2021 08:19:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 28320 Ep: 10.49 loss 0.070 score 0.432 lr 2.64393e-06 
05/06/2021 08:19:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 28360 Ep: 10.50 loss 0.063 score 0.445 lr 2.63981e-06 
05/06/2021 08:20:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 28400 Ep: 10.52 loss 0.055 score 0.445 lr 2.6357e-06 
05/06/2021 08:21:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 28440 Ep: 10.53 loss 0.073 score 0.434 lr 2.63158e-06 
05/06/2021 08:22:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 28480 Ep: 10.55 loss 0.067 score 0.442 lr 2.62747e-06 
05/06/2021 08:23:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 28520 Ep: 10.56 loss 0.067 score 0.434 lr 2.62335e-06 
05/06/2021 08:23:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 28560 Ep: 10.58 loss 0.065 score 0.434 lr 2.61924e-06 
05/06/2021 08:24:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 28600 Ep: 10.59 loss 0.068 score 0.436 lr 2.61512e-06 
05/06/2021 08:25:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 28640 Ep: 10.61 loss 0.064 score 0.440 lr 2.61101e-06 
05/06/2021 08:26:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 28680 Ep: 10.62 loss 0.067 score 0.435 lr 2.60689e-06 
05/06/2021 08:27:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 28720 Ep: 10.64 loss 0.069 score 0.437 lr 2.60278e-06 
05/06/2021 08:27:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 28760 Ep: 10.65 loss 0.066 score 0.437 lr 2.59866e-06 
05/06/2021 08:28:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 28800 Ep: 10.67 loss 0.074 score 0.430 lr 2.59455e-06 
05/06/2021 08:29:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 28840 Ep: 10.68 loss 0.073 score 0.434 lr 2.59043e-06 
05/06/2021 08:29:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 28880 Ep: 10.70 loss 0.066 score 0.438 lr 2.58632e-06 
05/06/2021 08:30:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 28920 Ep: 10.71 loss 0.065 score 0.439 lr 2.5822e-06 
05/06/2021 08:31:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 28960 Ep: 10.73 loss 0.071 score 0.433 lr 2.57809e-06 
05/06/2021 08:31:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 29000 Ep: 10.74 loss 0.072 score 0.434 lr 2.57397e-06 
05/06/2021 08:32:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 29040 Ep: 10.76 loss 0.073 score 0.438 lr 2.56986e-06 
05/06/2021 08:33:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 29080 Ep: 10.77 loss 0.074 score 0.435 lr 2.56574e-06 
05/06/2021 08:34:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 29120 Ep: 10.79 loss 0.062 score 0.441 lr 2.56163e-06 
05/06/2021 08:34:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 29160 Ep: 10.80 loss 0.068 score 0.442 lr 2.55751e-06 
05/06/2021 08:35:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 29200 Ep: 10.81 loss 0.069 score 0.426 lr 2.5534e-06 
05/06/2021 08:36:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 29240 Ep: 10.83 loss 0.069 score 0.438 lr 2.54928e-06 
05/06/2021 08:36:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 29280 Ep: 10.84 loss 0.068 score 0.432 lr 2.54516e-06 
05/06/2021 08:37:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 29320 Ep: 10.86 loss 0.062 score 0.438 lr 2.54105e-06 
05/06/2021 08:38:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 29360 Ep: 10.87 loss 0.074 score 0.431 lr 2.53693e-06 
05/06/2021 08:39:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 29400 Ep: 10.89 loss 0.073 score 0.436 lr 2.53282e-06 
05/06/2021 08:40:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 29440 Ep: 10.90 loss 0.074 score 0.427 lr 2.5287e-06 
05/06/2021 08:40:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 29480 Ep: 10.92 loss 0.066 score 0.441 lr 2.52459e-06 
05/06/2021 08:41:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 29520 Ep: 10.93 loss 0.073 score 0.426 lr 2.52047e-06 
05/06/2021 08:42:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 29560 Ep: 10.95 loss 0.072 score 0.438 lr 2.51636e-06 
05/06/2021 08:43:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 29600 Ep: 10.96 loss 0.075 score 0.441 lr 2.51224e-06 
05/06/2021 08:44:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 29640 Ep: 10.98 loss 0.075 score 0.432 lr 2.50813e-06 
05/06/2021 08:45:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 29680 Ep: 10.99 loss 0.066 score 0.438 lr 2.50401e-06 
05/06/2021 08:45:51 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  55%|    | 11/20 [13:31:16<10:40:39, 4271.06s/it]05/06/2021 09:04:02 - INFO - volta.train_utils -   Eval task TASK12 on iteration 29700 
05/06/2021 09:04:02 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 0.899 score 69.579 
05/06/2021 09:04:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 29740 Ep: 11.01 loss 0.061 score 0.446 lr 2.49887e-06 
05/06/2021 09:05:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 29780 Ep: 11.03 loss 0.061 score 0.445 lr 2.49372e-06 
05/06/2021 09:06:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 29820 Ep: 11.04 loss 0.055 score 0.451 lr 2.48961e-06 
05/06/2021 09:06:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 29860 Ep: 11.06 loss 0.057 score 0.452 lr 2.48549e-06 
05/06/2021 09:08:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 29900 Ep: 11.07 loss 0.063 score 0.445 lr 2.48138e-06 
05/06/2021 09:09:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 29940 Ep: 11.09 loss 0.064 score 0.444 lr 2.47726e-06 
05/06/2021 09:10:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 29980 Ep: 11.10 loss 0.062 score 0.441 lr 2.47315e-06 
05/06/2021 09:11:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 30020 Ep: 11.12 loss 0.066 score 0.441 lr 2.46903e-06 
05/06/2021 09:11:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 30060 Ep: 11.13 loss 0.062 score 0.446 lr 2.46492e-06 
05/06/2021 09:12:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 30100 Ep: 11.15 loss 0.063 score 0.445 lr 2.4608e-06 
05/06/2021 09:13:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 30140 Ep: 11.16 loss 0.066 score 0.442 lr 2.45669e-06 
05/06/2021 09:14:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 30180 Ep: 11.18 loss 0.058 score 0.444 lr 2.45257e-06 
05/06/2021 09:16:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 30220 Ep: 11.19 loss 0.064 score 0.447 lr 2.44846e-06 
05/06/2021 09:17:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 30260 Ep: 11.21 loss 0.063 score 0.445 lr 2.44434e-06 
05/06/2021 09:17:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 30300 Ep: 11.22 loss 0.063 score 0.442 lr 2.44023e-06 
05/06/2021 09:18:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 30340 Ep: 11.24 loss 0.069 score 0.438 lr 2.43611e-06 
05/06/2021 09:19:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 30380 Ep: 11.25 loss 0.058 score 0.448 lr 2.432e-06 
05/06/2021 09:20:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 30420 Ep: 11.27 loss 0.070 score 0.444 lr 2.42788e-06 
05/06/2021 09:22:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 30460 Ep: 11.28 loss 0.053 score 0.455 lr 2.42377e-06 
05/06/2021 09:22:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 30500 Ep: 11.30 loss 0.054 score 0.442 lr 2.41965e-06 
05/06/2021 09:24:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 30540 Ep: 11.31 loss 0.053 score 0.448 lr 2.41553e-06 
05/06/2021 09:24:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 30580 Ep: 11.33 loss 0.056 score 0.452 lr 2.41142e-06 
05/06/2021 09:25:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 30620 Ep: 11.34 loss 0.059 score 0.449 lr 2.4073e-06 
05/06/2021 09:26:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 30660 Ep: 11.36 loss 0.059 score 0.452 lr 2.40319e-06 
05/06/2021 09:27:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 30700 Ep: 11.37 loss 0.062 score 0.443 lr 2.39907e-06 
05/06/2021 09:28:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 30740 Ep: 11.39 loss 0.066 score 0.443 lr 2.39496e-06 
05/06/2021 09:29:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 30780 Ep: 11.40 loss 0.063 score 0.440 lr 2.39084e-06 
05/06/2021 09:30:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 30820 Ep: 11.41 loss 0.056 score 0.441 lr 2.38673e-06 
05/06/2021 09:31:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 30860 Ep: 11.43 loss 0.066 score 0.444 lr 2.38261e-06 
05/06/2021 09:32:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 30900 Ep: 11.44 loss 0.061 score 0.443 lr 2.3785e-06 
05/06/2021 09:33:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 30940 Ep: 11.46 loss 0.058 score 0.441 lr 2.37438e-06 
05/06/2021 09:34:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 30980 Ep: 11.47 loss 0.061 score 0.448 lr 2.37027e-06 
05/06/2021 09:35:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 31020 Ep: 11.49 loss 0.068 score 0.438 lr 2.36615e-06 
05/06/2021 09:35:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 31060 Ep: 11.50 loss 0.058 score 0.451 lr 2.36204e-06 
05/06/2021 09:36:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 31100 Ep: 11.52 loss 0.059 score 0.453 lr 2.35792e-06 
05/06/2021 09:37:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 31140 Ep: 11.53 loss 0.060 score 0.448 lr 2.35381e-06 
05/06/2021 09:38:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 31180 Ep: 11.55 loss 0.068 score 0.439 lr 2.34969e-06 
05/06/2021 09:39:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 31220 Ep: 11.56 loss 0.068 score 0.439 lr 2.34558e-06 
05/06/2021 09:40:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 31260 Ep: 11.58 loss 0.060 score 0.445 lr 2.34146e-06 
05/06/2021 09:41:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 31300 Ep: 11.59 loss 0.062 score 0.440 lr 2.33735e-06 
05/06/2021 09:42:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 31340 Ep: 11.61 loss 0.058 score 0.445 lr 2.33323e-06 
05/06/2021 09:43:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 31380 Ep: 11.62 loss 0.058 score 0.451 lr 2.32912e-06 
05/06/2021 09:44:48 - INFO - volta.train_utils -   [NLVR2zh]: iter 31420 Ep: 11.64 loss 0.055 score 0.447 lr 2.325e-06 
05/06/2021 09:45:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 31460 Ep: 11.65 loss 0.055 score 0.446 lr 2.32088e-06 
05/06/2021 09:46:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 31500 Ep: 11.67 loss 0.054 score 0.448 lr 2.31677e-06 
05/06/2021 09:47:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 31540 Ep: 11.68 loss 0.063 score 0.440 lr 2.31265e-06 
05/06/2021 09:48:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 31580 Ep: 11.70 loss 0.064 score 0.445 lr 2.30854e-06 
05/06/2021 09:49:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 31620 Ep: 11.71 loss 0.065 score 0.440 lr 2.30442e-06 
05/06/2021 09:50:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 31660 Ep: 11.73 loss 0.069 score 0.437 lr 2.30031e-06 
05/06/2021 09:50:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 31700 Ep: 11.74 loss 0.068 score 0.443 lr 2.29619e-06 
05/06/2021 09:52:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 31740 Ep: 11.76 loss 0.058 score 0.451 lr 2.29208e-06 
05/06/2021 09:52:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 31780 Ep: 11.77 loss 0.062 score 0.438 lr 2.28796e-06 
05/06/2021 09:53:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 31820 Ep: 11.79 loss 0.059 score 0.438 lr 2.28385e-06 
05/06/2021 09:54:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 31860 Ep: 11.80 loss 0.066 score 0.436 lr 2.27973e-06 
05/06/2021 09:55:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 31900 Ep: 11.81 loss 0.063 score 0.446 lr 2.27562e-06 
05/06/2021 09:56:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 31940 Ep: 11.83 loss 0.064 score 0.439 lr 2.2715e-06 
05/06/2021 09:57:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 31980 Ep: 11.84 loss 0.062 score 0.443 lr 2.26739e-06 
05/06/2021 09:58:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 32020 Ep: 11.86 loss 0.064 score 0.444 lr 2.26327e-06 
05/06/2021 09:58:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 32060 Ep: 11.87 loss 0.062 score 0.449 lr 2.25916e-06 
05/06/2021 09:59:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 32100 Ep: 11.89 loss 0.061 score 0.443 lr 2.25504e-06 
05/06/2021 10:00:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 32140 Ep: 11.90 loss 0.073 score 0.437 lr 2.25093e-06 
05/06/2021 10:01:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 32180 Ep: 11.92 loss 0.055 score 0.442 lr 2.24681e-06 
05/06/2021 10:02:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 32220 Ep: 11.93 loss 0.060 score 0.447 lr 2.2427e-06 
05/06/2021 10:03:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 32260 Ep: 11.95 loss 0.058 score 0.447 lr 2.23858e-06 
05/06/2021 10:04:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 32300 Ep: 11.96 loss 0.065 score 0.443 lr 2.23447e-06 
05/06/2021 10:05:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 32340 Ep: 11.98 loss 0.056 score 0.445 lr 2.23035e-06 
05/06/2021 10:06:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 32380 Ep: 11.99 loss 0.068 score 0.438 lr 2.22623e-06 
05/06/2021 10:07:10 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  60%|    | 12/20 [14:52:37<9:53:51, 4453.93s/it] 05/06/2021 10:26:03 - INFO - volta.train_utils -   Eval task TASK12 on iteration 32400 
05/06/2021 10:26:03 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 1.010 score 68.333 
05/06/2021 10:26:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 32440 Ep: 12.01 loss 0.056 score 0.452 lr 2.22109e-06 
05/06/2021 10:27:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 32480 Ep: 12.03 loss 0.058 score 0.450 lr 2.21595e-06 
05/06/2021 10:28:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 32520 Ep: 12.04 loss 0.044 score 0.461 lr 2.21183e-06 
05/06/2021 10:29:03 - INFO - volta.train_utils -   [NLVR2zh]: iter 32560 Ep: 12.06 loss 0.057 score 0.454 lr 2.20772e-06 
05/06/2021 10:29:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 32600 Ep: 12.07 loss 0.048 score 0.459 lr 2.2036e-06 
05/06/2021 10:30:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 32640 Ep: 12.09 loss 0.056 score 0.454 lr 2.19949e-06 
05/06/2021 10:31:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 32680 Ep: 12.10 loss 0.054 score 0.448 lr 2.19537e-06 
05/06/2021 10:32:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 32720 Ep: 12.12 loss 0.058 score 0.447 lr 2.19126e-06 
05/06/2021 10:33:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 32760 Ep: 12.13 loss 0.056 score 0.445 lr 2.18714e-06 
05/06/2021 10:34:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 32800 Ep: 12.15 loss 0.052 score 0.457 lr 2.18302e-06 
05/06/2021 10:34:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 32840 Ep: 12.16 loss 0.060 score 0.449 lr 2.17891e-06 
05/06/2021 10:35:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 32880 Ep: 12.18 loss 0.053 score 0.453 lr 2.17479e-06 
05/06/2021 10:36:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 32920 Ep: 12.19 loss 0.057 score 0.450 lr 2.17068e-06 
05/06/2021 10:37:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 32960 Ep: 12.21 loss 0.059 score 0.449 lr 2.16656e-06 
05/06/2021 10:38:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 33000 Ep: 12.22 loss 0.056 score 0.461 lr 2.16245e-06 
05/06/2021 10:39:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 33040 Ep: 12.24 loss 0.062 score 0.448 lr 2.15833e-06 
05/06/2021 10:39:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 33080 Ep: 12.25 loss 0.052 score 0.450 lr 2.15422e-06 
05/06/2021 10:40:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 33120 Ep: 12.27 loss 0.051 score 0.454 lr 2.1501e-06 
05/06/2021 10:41:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 33160 Ep: 12.28 loss 0.054 score 0.454 lr 2.14599e-06 
05/06/2021 10:42:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 33200 Ep: 12.30 loss 0.058 score 0.452 lr 2.14187e-06 
05/06/2021 10:43:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 33240 Ep: 12.31 loss 0.059 score 0.450 lr 2.13776e-06 
05/06/2021 10:44:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 33280 Ep: 12.33 loss 0.050 score 0.457 lr 2.13364e-06 
05/06/2021 10:45:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 33320 Ep: 12.34 loss 0.062 score 0.444 lr 2.12953e-06 
05/06/2021 10:46:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 33360 Ep: 12.36 loss 0.058 score 0.445 lr 2.12541e-06 
05/06/2021 10:46:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 33400 Ep: 12.37 loss 0.049 score 0.452 lr 2.1213e-06 
05/06/2021 10:47:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 33440 Ep: 12.39 loss 0.045 score 0.459 lr 2.11718e-06 
05/06/2021 10:48:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 33480 Ep: 12.40 loss 0.056 score 0.451 lr 2.11307e-06 
05/06/2021 10:49:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 33520 Ep: 12.41 loss 0.057 score 0.459 lr 2.10895e-06 
05/06/2021 10:50:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 33560 Ep: 12.43 loss 0.049 score 0.458 lr 2.10484e-06 
05/06/2021 10:52:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 33600 Ep: 12.44 loss 0.063 score 0.448 lr 2.10072e-06 
05/06/2021 10:53:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 33640 Ep: 12.46 loss 0.054 score 0.442 lr 2.0966e-06 
05/06/2021 10:54:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 33680 Ep: 12.47 loss 0.059 score 0.443 lr 2.09249e-06 
05/06/2021 10:55:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 33720 Ep: 12.49 loss 0.049 score 0.454 lr 2.08837e-06 
05/06/2021 10:56:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 33760 Ep: 12.50 loss 0.052 score 0.454 lr 2.08426e-06 
05/06/2021 10:57:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 33800 Ep: 12.52 loss 0.050 score 0.455 lr 2.08014e-06 
05/06/2021 10:58:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 33840 Ep: 12.53 loss 0.059 score 0.449 lr 2.07603e-06 
05/06/2021 10:59:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 33880 Ep: 12.55 loss 0.053 score 0.456 lr 2.07191e-06 
05/06/2021 11:00:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 33920 Ep: 12.56 loss 0.055 score 0.446 lr 2.0678e-06 
05/06/2021 11:01:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 33960 Ep: 12.58 loss 0.060 score 0.441 lr 2.06368e-06 
05/06/2021 11:02:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 34000 Ep: 12.59 loss 0.057 score 0.441 lr 2.05957e-06 
05/06/2021 11:03:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 34040 Ep: 12.61 loss 0.057 score 0.443 lr 2.05545e-06 
05/06/2021 11:04:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 34080 Ep: 12.62 loss 0.057 score 0.448 lr 2.05134e-06 
05/06/2021 11:05:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 34120 Ep: 12.64 loss 0.048 score 0.455 lr 2.04722e-06 
05/06/2021 11:07:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 34160 Ep: 12.65 loss 0.058 score 0.451 lr 2.04311e-06 
05/06/2021 11:08:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 34200 Ep: 12.67 loss 0.062 score 0.447 lr 2.03899e-06 
05/06/2021 11:09:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 34240 Ep: 12.68 loss 0.067 score 0.448 lr 2.03488e-06 
05/06/2021 11:10:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 34280 Ep: 12.70 loss 0.060 score 0.441 lr 2.03076e-06 
05/06/2021 11:11:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 34320 Ep: 12.71 loss 0.050 score 0.452 lr 2.02665e-06 
05/06/2021 11:12:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 34360 Ep: 12.73 loss 0.057 score 0.452 lr 2.02253e-06 
05/06/2021 11:13:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 34400 Ep: 12.74 loss 0.051 score 0.455 lr 2.01842e-06 
05/06/2021 11:15:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 34440 Ep: 12.76 loss 0.062 score 0.446 lr 2.0143e-06 
05/06/2021 11:16:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 34480 Ep: 12.77 loss 0.062 score 0.450 lr 2.01019e-06 
05/06/2021 11:17:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 34520 Ep: 12.79 loss 0.056 score 0.445 lr 2.00607e-06 
05/06/2021 11:18:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 34560 Ep: 12.80 loss 0.052 score 0.445 lr 2.00195e-06 
05/06/2021 11:19:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 34600 Ep: 12.81 loss 0.065 score 0.444 lr 1.99784e-06 
05/06/2021 11:20:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 34640 Ep: 12.83 loss 0.063 score 0.445 lr 1.99372e-06 
05/06/2021 11:22:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 34680 Ep: 12.84 loss 0.052 score 0.448 lr 1.98961e-06 
05/06/2021 11:23:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 34720 Ep: 12.86 loss 0.054 score 0.454 lr 1.98549e-06 
05/06/2021 11:24:48 - INFO - volta.train_utils -   [NLVR2zh]: iter 34760 Ep: 12.87 loss 0.049 score 0.453 lr 1.98138e-06 
05/06/2021 11:25:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 34800 Ep: 12.89 loss 0.055 score 0.444 lr 1.97726e-06 
05/06/2021 11:27:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 34840 Ep: 12.90 loss 0.066 score 0.449 lr 1.97315e-06 
05/06/2021 11:28:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 34880 Ep: 12.92 loss 0.057 score 0.450 lr 1.96903e-06 
05/06/2021 11:29:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 34920 Ep: 12.93 loss 0.063 score 0.450 lr 1.96492e-06 
05/06/2021 11:30:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 34960 Ep: 12.95 loss 0.069 score 0.448 lr 1.9608e-06 
05/06/2021 11:32:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 35000 Ep: 12.96 loss 0.054 score 0.451 lr 1.95669e-06 
05/06/2021 11:33:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 35040 Ep: 12.98 loss 0.054 score 0.443 lr 1.95257e-06 
05/06/2021 11:34:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 35080 Ep: 12.99 loss 0.050 score 0.451 lr 1.94846e-06 
05/06/2021 11:35:16 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  65%|   | 13/20 [16:20:44<9:08:46, 4703.81s/it]05/06/2021 11:57:35 - INFO - volta.train_utils -   Eval task TASK12 on iteration 35100 
05/06/2021 11:57:35 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 1.030 score 69.235 
05/06/2021 11:58:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 35140 Ep: 13.01 loss 0.048 score 0.457 lr 1.94331e-06 
05/06/2021 11:59:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 35180 Ep: 13.03 loss 0.049 score 0.455 lr 1.93817e-06 
05/06/2021 12:00:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 35220 Ep: 13.04 loss 0.058 score 0.452 lr 1.93405e-06 
05/06/2021 12:01:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 35260 Ep: 13.06 loss 0.049 score 0.456 lr 1.92994e-06 
05/06/2021 12:02:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 35300 Ep: 13.07 loss 0.051 score 0.456 lr 1.92582e-06 
05/06/2021 12:03:48 - INFO - volta.train_utils -   [NLVR2zh]: iter 35340 Ep: 13.09 loss 0.045 score 0.461 lr 1.92171e-06 
05/06/2021 12:04:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 35380 Ep: 13.10 loss 0.047 score 0.453 lr 1.91759e-06 
05/06/2021 12:05:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 35420 Ep: 13.12 loss 0.047 score 0.460 lr 1.91348e-06 
05/06/2021 12:07:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 35460 Ep: 13.13 loss 0.041 score 0.458 lr 1.90936e-06 
05/06/2021 12:08:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 35500 Ep: 13.15 loss 0.049 score 0.459 lr 1.90525e-06 
05/06/2021 12:09:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 35540 Ep: 13.16 loss 0.047 score 0.458 lr 1.90113e-06 
05/06/2021 12:10:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 35580 Ep: 13.18 loss 0.064 score 0.448 lr 1.89702e-06 
05/06/2021 12:11:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 35620 Ep: 13.19 loss 0.066 score 0.454 lr 1.8929e-06 
05/06/2021 12:13:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 35660 Ep: 13.21 loss 0.047 score 0.450 lr 1.88879e-06 
05/06/2021 12:14:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 35700 Ep: 13.22 loss 0.052 score 0.454 lr 1.88467e-06 
05/06/2021 12:15:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 35740 Ep: 13.24 loss 0.055 score 0.454 lr 1.88056e-06 
05/06/2021 12:16:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 35780 Ep: 13.25 loss 0.058 score 0.450 lr 1.87644e-06 
05/06/2021 12:18:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 35820 Ep: 13.27 loss 0.042 score 0.461 lr 1.87233e-06 
05/06/2021 12:19:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 35860 Ep: 13.28 loss 0.056 score 0.458 lr 1.86821e-06 
05/06/2021 12:20:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 35900 Ep: 13.30 loss 0.062 score 0.445 lr 1.86409e-06 
05/06/2021 12:21:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 35940 Ep: 13.31 loss 0.046 score 0.454 lr 1.85998e-06 
05/06/2021 12:22:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 35980 Ep: 13.33 loss 0.044 score 0.457 lr 1.85586e-06 
05/06/2021 12:23:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 36020 Ep: 13.34 loss 0.053 score 0.457 lr 1.85175e-06 
05/06/2021 12:24:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 36060 Ep: 13.36 loss 0.050 score 0.454 lr 1.84763e-06 
05/06/2021 12:25:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 36100 Ep: 13.37 loss 0.046 score 0.456 lr 1.84352e-06 
05/06/2021 12:26:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 36140 Ep: 13.39 loss 0.047 score 0.460 lr 1.8394e-06 
05/06/2021 12:27:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 36180 Ep: 13.40 loss 0.059 score 0.451 lr 1.83529e-06 
05/06/2021 12:29:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 36220 Ep: 13.41 loss 0.041 score 0.462 lr 1.83117e-06 
05/06/2021 12:30:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 36260 Ep: 13.43 loss 0.051 score 0.454 lr 1.82706e-06 
05/06/2021 12:31:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 36300 Ep: 13.44 loss 0.052 score 0.452 lr 1.82294e-06 
05/06/2021 12:32:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 36340 Ep: 13.46 loss 0.045 score 0.462 lr 1.81883e-06 
05/06/2021 12:33:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 36380 Ep: 13.47 loss 0.049 score 0.457 lr 1.81471e-06 
05/06/2021 12:34:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 36420 Ep: 13.49 loss 0.051 score 0.457 lr 1.8106e-06 
05/06/2021 12:35:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 36460 Ep: 13.50 loss 0.064 score 0.449 lr 1.80648e-06 
05/06/2021 12:36:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 36500 Ep: 13.52 loss 0.050 score 0.464 lr 1.80237e-06 
05/06/2021 12:37:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 36540 Ep: 13.53 loss 0.051 score 0.456 lr 1.79825e-06 
05/06/2021 12:38:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 36580 Ep: 13.55 loss 0.051 score 0.450 lr 1.79414e-06 
05/06/2021 12:39:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 36620 Ep: 13.56 loss 0.047 score 0.455 lr 1.79002e-06 
05/06/2021 12:40:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 36660 Ep: 13.58 loss 0.045 score 0.455 lr 1.78591e-06 
05/06/2021 12:42:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 36700 Ep: 13.59 loss 0.050 score 0.460 lr 1.78179e-06 
05/06/2021 12:43:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 36740 Ep: 13.61 loss 0.049 score 0.458 lr 1.77767e-06 
05/06/2021 12:44:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 36780 Ep: 13.62 loss 0.055 score 0.452 lr 1.77356e-06 
05/06/2021 12:46:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 36820 Ep: 13.64 loss 0.053 score 0.453 lr 1.76944e-06 
05/06/2021 12:47:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 36860 Ep: 13.65 loss 0.056 score 0.450 lr 1.76533e-06 
05/06/2021 12:48:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 36900 Ep: 13.67 loss 0.047 score 0.464 lr 1.76121e-06 
05/06/2021 12:49:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 36940 Ep: 13.68 loss 0.045 score 0.456 lr 1.7571e-06 
05/06/2021 12:50:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 36980 Ep: 13.70 loss 0.050 score 0.454 lr 1.75298e-06 
05/06/2021 12:51:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 37020 Ep: 13.71 loss 0.052 score 0.453 lr 1.74887e-06 
05/06/2021 12:52:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 37060 Ep: 13.73 loss 0.053 score 0.455 lr 1.74475e-06 
05/06/2021 12:53:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 37100 Ep: 13.74 loss 0.051 score 0.457 lr 1.74064e-06 
05/06/2021 12:54:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 37140 Ep: 13.76 loss 0.051 score 0.454 lr 1.73652e-06 
05/06/2021 12:55:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 37180 Ep: 13.77 loss 0.049 score 0.459 lr 1.73241e-06 
05/06/2021 12:56:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 37220 Ep: 13.79 loss 0.048 score 0.457 lr 1.72829e-06 
05/06/2021 12:58:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 37260 Ep: 13.80 loss 0.053 score 0.448 lr 1.72418e-06 
05/06/2021 12:59:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 37300 Ep: 13.81 loss 0.051 score 0.457 lr 1.72006e-06 
05/06/2021 13:00:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 37340 Ep: 13.83 loss 0.053 score 0.454 lr 1.71595e-06 
05/06/2021 13:01:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 37380 Ep: 13.84 loss 0.051 score 0.454 lr 1.71183e-06 
05/06/2021 13:02:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 37420 Ep: 13.86 loss 0.045 score 0.457 lr 1.70772e-06 
05/06/2021 13:03:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 37460 Ep: 13.87 loss 0.051 score 0.450 lr 1.7036e-06 
05/06/2021 13:05:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 37500 Ep: 13.89 loss 0.053 score 0.451 lr 1.69949e-06 
05/06/2021 13:06:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 37540 Ep: 13.90 loss 0.049 score 0.456 lr 1.69537e-06 
05/06/2021 13:07:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 37580 Ep: 13.92 loss 0.051 score 0.455 lr 1.69126e-06 
05/06/2021 13:08:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 37620 Ep: 13.93 loss 0.050 score 0.446 lr 1.68714e-06 
05/06/2021 13:10:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 37660 Ep: 13.95 loss 0.054 score 0.448 lr 1.68302e-06 
05/06/2021 13:11:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 37700 Ep: 13.96 loss 0.050 score 0.461 lr 1.67891e-06 
05/06/2021 13:12:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 37740 Ep: 13.98 loss 0.049 score 0.454 lr 1.67479e-06 
05/06/2021 13:13:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 37780 Ep: 13.99 loss 0.038 score 0.462 lr 1.67068e-06 
05/06/2021 13:14:04 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  70%|   | 14/20 [17:59:30<8:27:03, 5070.60s/it]05/06/2021 13:33:03 - INFO - volta.train_utils -   Eval task TASK12 on iteration 37800 
05/06/2021 13:33:03 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 1.104 score 69.192 
05/06/2021 13:33:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 37840 Ep: 14.01 loss 0.052 score 0.460 lr 1.66553e-06 
05/06/2021 13:34:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 37880 Ep: 14.03 loss 0.050 score 0.459 lr 1.66039e-06 
05/06/2021 13:35:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 37920 Ep: 14.04 loss 0.048 score 0.457 lr 1.65628e-06 
05/06/2021 13:36:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 37960 Ep: 14.06 loss 0.048 score 0.457 lr 1.65216e-06 
05/06/2021 13:37:48 - INFO - volta.train_utils -   [NLVR2zh]: iter 38000 Ep: 14.07 loss 0.045 score 0.458 lr 1.64805e-06 
05/06/2021 13:38:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 38040 Ep: 14.09 loss 0.040 score 0.467 lr 1.64393e-06 
05/06/2021 13:39:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 38080 Ep: 14.10 loss 0.044 score 0.458 lr 1.63981e-06 
05/06/2021 13:40:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 38120 Ep: 14.12 loss 0.038 score 0.464 lr 1.6357e-06 
05/06/2021 13:42:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 38160 Ep: 14.13 loss 0.045 score 0.463 lr 1.63158e-06 
05/06/2021 13:42:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 38200 Ep: 14.15 loss 0.047 score 0.464 lr 1.62747e-06 
05/06/2021 13:44:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 38240 Ep: 14.16 loss 0.033 score 0.466 lr 1.62335e-06 
05/06/2021 13:45:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 38280 Ep: 14.18 loss 0.039 score 0.466 lr 1.61924e-06 
05/06/2021 13:46:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 38320 Ep: 14.19 loss 0.036 score 0.467 lr 1.61512e-06 
05/06/2021 13:47:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 38360 Ep: 14.21 loss 0.044 score 0.459 lr 1.61101e-06 
05/06/2021 13:49:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 38400 Ep: 14.22 loss 0.041 score 0.465 lr 1.60689e-06 
05/06/2021 13:50:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 38440 Ep: 14.24 loss 0.045 score 0.457 lr 1.60278e-06 
05/06/2021 13:51:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 38480 Ep: 14.25 loss 0.041 score 0.462 lr 1.59866e-06 
05/06/2021 13:52:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 38520 Ep: 14.27 loss 0.056 score 0.455 lr 1.59455e-06 
05/06/2021 13:53:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 38560 Ep: 14.28 loss 0.046 score 0.459 lr 1.59043e-06 
05/06/2021 13:54:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 38600 Ep: 14.30 loss 0.040 score 0.463 lr 1.58632e-06 
05/06/2021 13:55:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 38640 Ep: 14.31 loss 0.043 score 0.462 lr 1.5822e-06 
05/06/2021 13:56:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 38680 Ep: 14.33 loss 0.048 score 0.457 lr 1.57809e-06 
05/06/2021 13:58:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 38720 Ep: 14.34 loss 0.050 score 0.458 lr 1.57397e-06 
05/06/2021 13:59:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 38760 Ep: 14.36 loss 0.060 score 0.453 lr 1.56986e-06 
05/06/2021 14:00:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 38800 Ep: 14.37 loss 0.046 score 0.456 lr 1.56574e-06 
05/06/2021 14:01:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 38840 Ep: 14.39 loss 0.044 score 0.465 lr 1.56163e-06 
05/06/2021 14:03:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 38880 Ep: 14.40 loss 0.046 score 0.462 lr 1.55751e-06 
05/06/2021 14:04:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 38920 Ep: 14.41 loss 0.047 score 0.459 lr 1.5534e-06 
05/06/2021 14:06:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 38960 Ep: 14.43 loss 0.047 score 0.463 lr 1.54928e-06 
05/06/2021 14:07:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 39000 Ep: 14.44 loss 0.052 score 0.461 lr 1.54516e-06 
05/06/2021 14:08:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 39040 Ep: 14.46 loss 0.044 score 0.462 lr 1.54105e-06 
05/06/2021 14:10:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 39080 Ep: 14.47 loss 0.046 score 0.458 lr 1.53693e-06 
05/06/2021 14:11:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 39120 Ep: 14.49 loss 0.045 score 0.461 lr 1.53282e-06 
05/06/2021 14:12:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 39160 Ep: 14.50 loss 0.048 score 0.464 lr 1.5287e-06 
05/06/2021 14:14:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 39200 Ep: 14.52 loss 0.044 score 0.457 lr 1.52459e-06 
05/06/2021 14:15:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 39240 Ep: 14.53 loss 0.043 score 0.464 lr 1.52047e-06 
05/06/2021 14:16:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 39280 Ep: 14.55 loss 0.047 score 0.461 lr 1.51636e-06 
05/06/2021 14:17:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 39320 Ep: 14.56 loss 0.043 score 0.459 lr 1.51224e-06 
05/06/2021 14:18:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 39360 Ep: 14.58 loss 0.041 score 0.467 lr 1.50813e-06 
05/06/2021 14:20:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 39400 Ep: 14.59 loss 0.041 score 0.456 lr 1.50401e-06 
05/06/2021 14:21:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 39440 Ep: 14.61 loss 0.050 score 0.455 lr 1.4999e-06 
05/06/2021 14:22:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 39480 Ep: 14.62 loss 0.038 score 0.466 lr 1.49578e-06 
05/06/2021 14:24:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 39520 Ep: 14.64 loss 0.038 score 0.462 lr 1.49167e-06 
05/06/2021 14:25:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 39560 Ep: 14.65 loss 0.046 score 0.460 lr 1.48755e-06 
05/06/2021 14:26:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 39600 Ep: 14.67 loss 0.048 score 0.454 lr 1.48344e-06 
05/06/2021 14:27:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 39640 Ep: 14.68 loss 0.051 score 0.463 lr 1.47932e-06 
05/06/2021 14:29:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 39680 Ep: 14.70 loss 0.041 score 0.452 lr 1.47521e-06 
05/06/2021 14:30:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 39720 Ep: 14.71 loss 0.049 score 0.461 lr 1.47109e-06 
05/06/2021 14:31:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 39760 Ep: 14.73 loss 0.042 score 0.458 lr 1.46698e-06 
05/06/2021 14:32:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 39800 Ep: 14.74 loss 0.044 score 0.461 lr 1.46286e-06 
05/06/2021 14:34:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 39840 Ep: 14.76 loss 0.044 score 0.457 lr 1.45874e-06 
05/06/2021 14:35:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 39880 Ep: 14.77 loss 0.049 score 0.456 lr 1.45463e-06 
05/06/2021 14:37:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 39920 Ep: 14.79 loss 0.041 score 0.464 lr 1.45051e-06 
05/06/2021 14:38:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 39960 Ep: 14.80 loss 0.047 score 0.457 lr 1.4464e-06 
05/06/2021 14:39:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 40000 Ep: 14.81 loss 0.047 score 0.457 lr 1.44228e-06 
05/06/2021 14:40:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 40040 Ep: 14.83 loss 0.045 score 0.464 lr 1.43817e-06 
05/06/2021 14:42:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 40080 Ep: 14.84 loss 0.058 score 0.453 lr 1.43405e-06 
05/06/2021 14:43:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 40120 Ep: 14.86 loss 0.046 score 0.464 lr 1.42994e-06 
05/06/2021 14:45:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 40160 Ep: 14.87 loss 0.049 score 0.455 lr 1.42582e-06 
05/06/2021 14:46:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 40200 Ep: 14.89 loss 0.045 score 0.462 lr 1.42171e-06 
05/06/2021 14:47:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 40240 Ep: 14.90 loss 0.043 score 0.463 lr 1.41759e-06 
05/06/2021 14:49:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 40280 Ep: 14.92 loss 0.056 score 0.453 lr 1.41348e-06 
05/06/2021 14:50:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 40320 Ep: 14.93 loss 0.044 score 0.459 lr 1.40936e-06 
05/06/2021 14:51:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 40360 Ep: 14.95 loss 0.041 score 0.461 lr 1.40525e-06 
05/06/2021 14:52:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 40400 Ep: 14.96 loss 0.046 score 0.463 lr 1.40113e-06 
05/06/2021 14:53:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 40440 Ep: 14.98 loss 0.037 score 0.466 lr 1.39702e-06 
05/06/2021 14:54:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 40480 Ep: 14.99 loss 0.048 score 0.457 lr 1.3929e-06 
05/06/2021 14:55:10 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  75%|  | 15/20 [19:40:36<7:27:25, 5369.20s/it]05/06/2021 15:19:03 - INFO - volta.train_utils -   Eval task TASK12 on iteration 40500 
05/06/2021 15:19:03 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 1.139 score 68.920 
05/06/2021 15:19:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 40540 Ep: 15.01 loss 0.038 score 0.469 lr 1.38776e-06 
05/06/2021 15:20:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 40580 Ep: 15.03 loss 0.043 score 0.459 lr 1.38261e-06 
05/06/2021 15:21:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 40620 Ep: 15.04 loss 0.047 score 0.461 lr 1.3785e-06 
05/06/2021 15:22:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 40660 Ep: 15.06 loss 0.042 score 0.463 lr 1.37438e-06 
05/06/2021 15:23:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 40700 Ep: 15.07 loss 0.046 score 0.467 lr 1.37027e-06 
05/06/2021 15:25:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 40740 Ep: 15.09 loss 0.042 score 0.470 lr 1.36615e-06 
05/06/2021 15:26:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 40780 Ep: 15.10 loss 0.052 score 0.457 lr 1.36204e-06 
05/06/2021 15:28:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 40820 Ep: 15.12 loss 0.045 score 0.466 lr 1.35792e-06 
05/06/2021 15:29:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 40860 Ep: 15.13 loss 0.040 score 0.461 lr 1.35381e-06 
05/06/2021 15:31:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 40900 Ep: 15.15 loss 0.042 score 0.464 lr 1.34969e-06 
05/06/2021 15:32:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 40940 Ep: 15.16 loss 0.043 score 0.463 lr 1.34558e-06 
05/06/2021 15:33:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 40980 Ep: 15.18 loss 0.034 score 0.472 lr 1.34146e-06 
05/06/2021 15:35:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 41020 Ep: 15.19 loss 0.036 score 0.468 lr 1.33735e-06 
05/06/2021 15:36:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 41060 Ep: 15.21 loss 0.038 score 0.467 lr 1.33323e-06 
05/06/2021 15:38:03 - INFO - volta.train_utils -   [NLVR2zh]: iter 41100 Ep: 15.22 loss 0.041 score 0.463 lr 1.32912e-06 
05/06/2021 15:39:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 41140 Ep: 15.24 loss 0.035 score 0.467 lr 1.325e-06 
05/06/2021 15:41:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 41180 Ep: 15.25 loss 0.039 score 0.468 lr 1.32088e-06 
05/06/2021 15:42:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 41220 Ep: 15.27 loss 0.047 score 0.465 lr 1.31677e-06 
05/06/2021 15:44:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 41260 Ep: 15.28 loss 0.044 score 0.470 lr 1.31265e-06 
05/06/2021 15:45:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 41300 Ep: 15.30 loss 0.046 score 0.464 lr 1.30854e-06 
05/06/2021 15:47:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 41340 Ep: 15.31 loss 0.046 score 0.458 lr 1.30442e-06 
05/06/2021 15:48:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 41380 Ep: 15.33 loss 0.045 score 0.459 lr 1.30031e-06 
05/06/2021 15:50:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 41420 Ep: 15.34 loss 0.038 score 0.468 lr 1.29619e-06 
05/06/2021 15:52:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 41460 Ep: 15.36 loss 0.044 score 0.469 lr 1.29208e-06 
05/06/2021 15:53:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 41500 Ep: 15.37 loss 0.045 score 0.461 lr 1.28796e-06 
05/06/2021 15:54:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 41540 Ep: 15.39 loss 0.036 score 0.464 lr 1.28385e-06 
05/06/2021 15:55:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 41580 Ep: 15.40 loss 0.040 score 0.470 lr 1.27973e-06 
05/06/2021 15:57:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 41620 Ep: 15.41 loss 0.038 score 0.462 lr 1.27562e-06 
05/06/2021 15:58:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 41660 Ep: 15.43 loss 0.039 score 0.468 lr 1.2715e-06 
05/06/2021 16:00:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 41700 Ep: 15.44 loss 0.036 score 0.470 lr 1.26739e-06 
05/06/2021 16:01:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 41740 Ep: 15.46 loss 0.038 score 0.463 lr 1.26327e-06 
05/06/2021 16:03:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 41780 Ep: 15.47 loss 0.039 score 0.464 lr 1.25916e-06 
05/06/2021 16:04:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 41820 Ep: 15.49 loss 0.042 score 0.464 lr 1.25504e-06 
05/06/2021 16:05:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 41860 Ep: 15.50 loss 0.048 score 0.461 lr 1.25093e-06 
05/06/2021 16:06:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 41900 Ep: 15.52 loss 0.034 score 0.468 lr 1.24681e-06 
05/06/2021 16:08:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 41940 Ep: 15.53 loss 0.046 score 0.464 lr 1.2427e-06 
05/06/2021 16:09:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 41980 Ep: 15.55 loss 0.046 score 0.461 lr 1.23858e-06 
05/06/2021 16:10:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 42020 Ep: 15.56 loss 0.041 score 0.466 lr 1.23447e-06 
05/06/2021 16:12:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 42060 Ep: 15.58 loss 0.038 score 0.466 lr 1.23035e-06 
05/06/2021 16:13:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 42100 Ep: 15.59 loss 0.032 score 0.468 lr 1.22623e-06 
05/06/2021 16:14:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 42140 Ep: 15.61 loss 0.055 score 0.457 lr 1.22212e-06 
05/06/2021 16:16:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 42180 Ep: 15.62 loss 0.034 score 0.461 lr 1.218e-06 
05/06/2021 16:17:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 42220 Ep: 15.64 loss 0.036 score 0.473 lr 1.21389e-06 
05/06/2021 16:19:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 42260 Ep: 15.65 loss 0.045 score 0.467 lr 1.20977e-06 
05/06/2021 16:20:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 42300 Ep: 15.67 loss 0.042 score 0.460 lr 1.20566e-06 
05/06/2021 16:21:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 42340 Ep: 15.68 loss 0.044 score 0.464 lr 1.20154e-06 
05/06/2021 16:22:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 42380 Ep: 15.70 loss 0.039 score 0.464 lr 1.19743e-06 
05/06/2021 16:23:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 42420 Ep: 15.71 loss 0.042 score 0.464 lr 1.19331e-06 
05/06/2021 16:24:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 42460 Ep: 15.73 loss 0.045 score 0.466 lr 1.1892e-06 
05/06/2021 16:26:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 42500 Ep: 15.74 loss 0.041 score 0.465 lr 1.18508e-06 
05/06/2021 16:27:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 42540 Ep: 15.76 loss 0.037 score 0.463 lr 1.18097e-06 
05/06/2021 16:28:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 42580 Ep: 15.77 loss 0.046 score 0.461 lr 1.17685e-06 
05/06/2021 16:29:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 42620 Ep: 15.79 loss 0.048 score 0.459 lr 1.17274e-06 
05/06/2021 16:30:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 42660 Ep: 15.80 loss 0.041 score 0.462 lr 1.16862e-06 
05/06/2021 16:31:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 42700 Ep: 15.81 loss 0.041 score 0.469 lr 1.16451e-06 
05/06/2021 16:33:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 42740 Ep: 15.83 loss 0.046 score 0.469 lr 1.16039e-06 
05/06/2021 16:34:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 42780 Ep: 15.84 loss 0.050 score 0.460 lr 1.15628e-06 
05/06/2021 16:35:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 42820 Ep: 15.86 loss 0.043 score 0.460 lr 1.15216e-06 
05/06/2021 16:36:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 42860 Ep: 15.87 loss 0.042 score 0.467 lr 1.14805e-06 
05/06/2021 16:38:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 42900 Ep: 15.89 loss 0.039 score 0.466 lr 1.14393e-06 
05/06/2021 16:39:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 42940 Ep: 15.90 loss 0.043 score 0.464 lr 1.13981e-06 
05/06/2021 16:40:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 42980 Ep: 15.92 loss 0.053 score 0.458 lr 1.1357e-06 
05/06/2021 16:41:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 43020 Ep: 15.93 loss 0.037 score 0.466 lr 1.13158e-06 
05/06/2021 16:43:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 43060 Ep: 15.95 loss 0.045 score 0.463 lr 1.12747e-06 
05/06/2021 16:44:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 43100 Ep: 15.96 loss 0.036 score 0.471 lr 1.12335e-06 
05/06/2021 16:46:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 43140 Ep: 15.98 loss 0.039 score 0.468 lr 1.11924e-06 
05/06/2021 16:48:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 43180 Ep: 15.99 loss 0.041 score 0.462 lr 1.11512e-06 
05/06/2021 16:48:51 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  80%|  | 16/20 [21:34:17<6:26:58, 5804.54s/it]05/06/2021 17:10:55 - INFO - volta.train_utils -   Eval task TASK12 on iteration 43200 
05/06/2021 17:10:55 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 1.208 score 69.378 
05/06/2021 17:11:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 43240 Ep: 16.01 loss 0.046 score 0.461 lr 1.10998e-06 
05/06/2021 17:12:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 43280 Ep: 16.03 loss 0.044 score 0.467 lr 1.10484e-06 
05/06/2021 17:14:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 43320 Ep: 16.04 loss 0.041 score 0.471 lr 1.10072e-06 
05/06/2021 17:15:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 43360 Ep: 16.06 loss 0.033 score 0.471 lr 1.0966e-06 
05/06/2021 17:16:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 43400 Ep: 16.07 loss 0.042 score 0.464 lr 1.09249e-06 
05/06/2021 17:17:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 43440 Ep: 16.09 loss 0.037 score 0.468 lr 1.08837e-06 
05/06/2021 17:18:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 43480 Ep: 16.10 loss 0.039 score 0.466 lr 1.08426e-06 
05/06/2021 17:19:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 43520 Ep: 16.12 loss 0.037 score 0.466 lr 1.08014e-06 
05/06/2021 17:20:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 43560 Ep: 16.13 loss 0.035 score 0.464 lr 1.07603e-06 
05/06/2021 17:22:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 43600 Ep: 16.15 loss 0.037 score 0.469 lr 1.07191e-06 
05/06/2021 17:23:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 43640 Ep: 16.16 loss 0.036 score 0.469 lr 1.0678e-06 
05/06/2021 17:24:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 43680 Ep: 16.18 loss 0.040 score 0.468 lr 1.06368e-06 
05/06/2021 17:26:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 43720 Ep: 16.19 loss 0.034 score 0.470 lr 1.05957e-06 
05/06/2021 17:28:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 43760 Ep: 16.21 loss 0.035 score 0.466 lr 1.05545e-06 
05/06/2021 17:29:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 43800 Ep: 16.22 loss 0.032 score 0.470 lr 1.05134e-06 
05/06/2021 17:30:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 43840 Ep: 16.24 loss 0.037 score 0.466 lr 1.04722e-06 
05/06/2021 17:31:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 43880 Ep: 16.25 loss 0.040 score 0.466 lr 1.04311e-06 
05/06/2021 17:32:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 43920 Ep: 16.27 loss 0.043 score 0.463 lr 1.03899e-06 
05/06/2021 17:33:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 43960 Ep: 16.28 loss 0.046 score 0.463 lr 1.03488e-06 
05/06/2021 17:35:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 44000 Ep: 16.30 loss 0.038 score 0.466 lr 1.03076e-06 
05/06/2021 17:36:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 44040 Ep: 16.31 loss 0.035 score 0.469 lr 1.02665e-06 
05/06/2021 17:37:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 44080 Ep: 16.33 loss 0.032 score 0.471 lr 1.02253e-06 
05/06/2021 17:38:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 44120 Ep: 16.34 loss 0.036 score 0.471 lr 1.01842e-06 
05/06/2021 17:40:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 44160 Ep: 16.36 loss 0.032 score 0.471 lr 1.0143e-06 
05/06/2021 17:41:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 44200 Ep: 16.37 loss 0.045 score 0.461 lr 1.01019e-06 
05/06/2021 17:42:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 44240 Ep: 16.39 loss 0.038 score 0.469 lr 1.00607e-06 
05/06/2021 17:43:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 44280 Ep: 16.40 loss 0.041 score 0.468 lr 1.00195e-06 
05/06/2021 17:45:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 44320 Ep: 16.41 loss 0.037 score 0.466 lr 9.9784e-07 
05/06/2021 17:46:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 44360 Ep: 16.43 loss 0.039 score 0.464 lr 9.93724e-07 
05/06/2021 17:47:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 44400 Ep: 16.44 loss 0.039 score 0.470 lr 9.89609e-07 
05/06/2021 17:48:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 44440 Ep: 16.46 loss 0.039 score 0.470 lr 9.85494e-07 
05/06/2021 17:49:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 44480 Ep: 16.47 loss 0.039 score 0.471 lr 9.81379e-07 
05/06/2021 17:50:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 44520 Ep: 16.49 loss 0.042 score 0.463 lr 9.77263e-07 
05/06/2021 17:52:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 44560 Ep: 16.50 loss 0.030 score 0.476 lr 9.73148e-07 
05/06/2021 17:53:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 44600 Ep: 16.52 loss 0.042 score 0.467 lr 9.69033e-07 
05/06/2021 17:54:48 - INFO - volta.train_utils -   [NLVR2zh]: iter 44640 Ep: 16.53 loss 0.042 score 0.467 lr 9.64918e-07 
05/06/2021 17:55:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 44680 Ep: 16.55 loss 0.037 score 0.470 lr 9.60802e-07 
05/06/2021 17:57:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 44720 Ep: 16.56 loss 0.044 score 0.467 lr 9.56687e-07 
05/06/2021 17:58:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 44760 Ep: 16.58 loss 0.040 score 0.467 lr 9.52572e-07 
05/06/2021 17:59:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 44800 Ep: 16.59 loss 0.042 score 0.466 lr 9.48457e-07 
05/06/2021 18:01:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 44840 Ep: 16.61 loss 0.038 score 0.467 lr 9.44342e-07 
05/06/2021 18:02:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 44880 Ep: 16.62 loss 0.040 score 0.463 lr 9.40226e-07 
05/06/2021 18:03:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 44920 Ep: 16.64 loss 0.034 score 0.468 lr 9.36111e-07 
05/06/2021 18:05:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 44960 Ep: 16.65 loss 0.038 score 0.468 lr 9.31996e-07 
05/06/2021 18:06:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 45000 Ep: 16.67 loss 0.034 score 0.471 lr 9.27881e-07 
05/06/2021 18:08:06 - INFO - volta.train_utils -   [NLVR2zh]: iter 45040 Ep: 16.68 loss 0.044 score 0.465 lr 9.23765e-07 
05/06/2021 18:09:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 45080 Ep: 16.70 loss 0.045 score 0.464 lr 9.1965e-07 
05/06/2021 18:10:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 45120 Ep: 16.71 loss 0.037 score 0.471 lr 9.15535e-07 
05/06/2021 18:11:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 45160 Ep: 16.73 loss 0.037 score 0.470 lr 9.1142e-07 
05/06/2021 18:13:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 45200 Ep: 16.74 loss 0.040 score 0.469 lr 9.07305e-07 
05/06/2021 18:14:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 45240 Ep: 16.76 loss 0.031 score 0.467 lr 9.03189e-07 
05/06/2021 18:15:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 45280 Ep: 16.77 loss 0.035 score 0.469 lr 8.99074e-07 
05/06/2021 18:16:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 45320 Ep: 16.79 loss 0.040 score 0.466 lr 8.94959e-07 
05/06/2021 18:18:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 45360 Ep: 16.80 loss 0.037 score 0.464 lr 8.90844e-07 
05/06/2021 18:19:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 45400 Ep: 16.81 loss 0.039 score 0.465 lr 8.86728e-07 
05/06/2021 18:20:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 45440 Ep: 16.83 loss 0.038 score 0.468 lr 8.82613e-07 
05/06/2021 18:21:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 45480 Ep: 16.84 loss 0.034 score 0.471 lr 8.78498e-07 
05/06/2021 18:22:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 45520 Ep: 16.86 loss 0.044 score 0.464 lr 8.74383e-07 
05/06/2021 18:23:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 45560 Ep: 16.87 loss 0.037 score 0.471 lr 8.70267e-07 
05/06/2021 18:24:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 45600 Ep: 16.89 loss 0.047 score 0.465 lr 8.66152e-07 
05/06/2021 18:25:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 45640 Ep: 16.90 loss 0.045 score 0.461 lr 8.62037e-07 
05/06/2021 18:27:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 45680 Ep: 16.92 loss 0.049 score 0.460 lr 8.57922e-07 
05/06/2021 18:27:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 45720 Ep: 16.93 loss 0.038 score 0.468 lr 8.53807e-07 
05/06/2021 18:29:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 45760 Ep: 16.95 loss 0.044 score 0.466 lr 8.49691e-07 
05/06/2021 18:29:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 45800 Ep: 16.96 loss 0.041 score 0.462 lr 8.45576e-07 
05/06/2021 18:30:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 45840 Ep: 16.98 loss 0.042 score 0.468 lr 8.41461e-07 
05/06/2021 18:31:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 45880 Ep: 16.99 loss 0.035 score 0.469 lr 8.37346e-07 
05/06/2021 18:32:04 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  85%| | 17/20 [23:17:34<4:56:06, 5922.29s/it]05/06/2021 18:50:12 - INFO - volta.train_utils -   Eval task TASK12 on iteration 45900 
05/06/2021 18:50:12 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 1.205 score 69.049 
05/06/2021 18:50:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 45940 Ep: 17.01 loss 0.042 score 0.468 lr 8.32202e-07 
05/06/2021 18:51:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 45980 Ep: 17.03 loss 0.028 score 0.471 lr 8.27058e-07 
05/06/2021 18:52:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 46020 Ep: 17.04 loss 0.038 score 0.472 lr 8.22942e-07 
05/06/2021 18:53:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 46060 Ep: 17.06 loss 0.039 score 0.471 lr 8.18827e-07 
05/06/2021 18:54:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 46100 Ep: 17.07 loss 0.030 score 0.473 lr 8.14712e-07 
05/06/2021 18:55:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 46140 Ep: 17.09 loss 0.033 score 0.472 lr 8.10597e-07 
05/06/2021 18:56:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 46180 Ep: 17.10 loss 0.035 score 0.471 lr 8.06481e-07 
05/06/2021 18:57:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 46220 Ep: 17.12 loss 0.040 score 0.464 lr 8.02366e-07 
05/06/2021 18:58:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 46260 Ep: 17.13 loss 0.031 score 0.467 lr 7.98251e-07 
05/06/2021 18:59:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 46300 Ep: 17.15 loss 0.038 score 0.468 lr 7.94136e-07 
05/06/2021 19:00:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 46340 Ep: 17.16 loss 0.035 score 0.468 lr 7.90021e-07 
05/06/2021 19:00:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 46380 Ep: 17.18 loss 0.032 score 0.472 lr 7.85905e-07 
05/06/2021 19:02:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 46420 Ep: 17.19 loss 0.035 score 0.470 lr 7.8179e-07 
05/06/2021 19:03:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 46460 Ep: 17.21 loss 0.047 score 0.467 lr 7.77675e-07 
05/06/2021 19:04:07 - INFO - volta.train_utils -   [NLVR2zh]: iter 46500 Ep: 17.22 loss 0.044 score 0.464 lr 7.7356e-07 
05/06/2021 19:04:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 46540 Ep: 17.24 loss 0.036 score 0.470 lr 7.69444e-07 
05/06/2021 19:06:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 46580 Ep: 17.25 loss 0.038 score 0.470 lr 7.65329e-07 
05/06/2021 19:06:48 - INFO - volta.train_utils -   [NLVR2zh]: iter 46620 Ep: 17.27 loss 0.032 score 0.473 lr 7.61214e-07 
05/06/2021 19:07:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 46660 Ep: 17.28 loss 0.044 score 0.464 lr 7.57099e-07 
05/06/2021 19:08:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 46700 Ep: 17.30 loss 0.035 score 0.470 lr 7.52984e-07 
05/06/2021 19:09:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 46740 Ep: 17.31 loss 0.037 score 0.467 lr 7.48868e-07 
05/06/2021 19:10:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 46780 Ep: 17.33 loss 0.033 score 0.469 lr 7.44753e-07 
05/06/2021 19:11:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 46820 Ep: 17.34 loss 0.032 score 0.469 lr 7.40638e-07 
05/06/2021 19:11:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 46860 Ep: 17.36 loss 0.040 score 0.469 lr 7.36523e-07 
05/06/2021 19:12:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 46900 Ep: 17.37 loss 0.040 score 0.461 lr 7.32407e-07 
05/06/2021 19:13:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 46940 Ep: 17.39 loss 0.030 score 0.472 lr 7.28292e-07 
05/06/2021 19:14:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 46980 Ep: 17.40 loss 0.045 score 0.473 lr 7.24177e-07 
05/06/2021 19:15:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 47020 Ep: 17.41 loss 0.034 score 0.472 lr 7.20062e-07 
05/06/2021 19:16:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 47060 Ep: 17.43 loss 0.044 score 0.465 lr 7.15947e-07 
05/06/2021 19:17:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 47100 Ep: 17.44 loss 0.039 score 0.468 lr 7.11831e-07 
05/06/2021 19:18:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 47140 Ep: 17.46 loss 0.034 score 0.471 lr 7.07716e-07 
05/06/2021 19:19:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 47180 Ep: 17.47 loss 0.046 score 0.468 lr 7.03601e-07 
05/06/2021 19:20:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 47220 Ep: 17.49 loss 0.036 score 0.467 lr 6.99486e-07 
05/06/2021 19:21:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 47260 Ep: 17.50 loss 0.032 score 0.471 lr 6.9537e-07 
05/06/2021 19:23:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 47300 Ep: 17.52 loss 0.038 score 0.467 lr 6.91255e-07 
05/06/2021 19:24:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 47340 Ep: 17.53 loss 0.031 score 0.476 lr 6.8714e-07 
05/06/2021 19:25:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 47380 Ep: 17.55 loss 0.040 score 0.467 lr 6.83025e-07 
05/06/2021 19:26:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 47420 Ep: 17.56 loss 0.037 score 0.471 lr 6.78909e-07 
05/06/2021 19:27:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 47460 Ep: 17.58 loss 0.032 score 0.471 lr 6.74794e-07 
05/06/2021 19:28:34 - INFO - volta.train_utils -   [NLVR2zh]: iter 47500 Ep: 17.59 loss 0.029 score 0.470 lr 6.70679e-07 
05/06/2021 19:29:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 47540 Ep: 17.61 loss 0.043 score 0.464 lr 6.66564e-07 
05/06/2021 19:30:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 47580 Ep: 17.62 loss 0.032 score 0.473 lr 6.62449e-07 
05/06/2021 19:31:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 47620 Ep: 17.64 loss 0.034 score 0.471 lr 6.58333e-07 
05/06/2021 19:32:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 47660 Ep: 17.65 loss 0.032 score 0.473 lr 6.54218e-07 
05/06/2021 19:33:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 47700 Ep: 17.67 loss 0.036 score 0.468 lr 6.50103e-07 
05/06/2021 19:34:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 47740 Ep: 17.68 loss 0.044 score 0.464 lr 6.45988e-07 
05/06/2021 19:35:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 47780 Ep: 17.70 loss 0.035 score 0.468 lr 6.41872e-07 
05/06/2021 19:36:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 47820 Ep: 17.71 loss 0.037 score 0.468 lr 6.37757e-07 
05/06/2021 19:37:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 47860 Ep: 17.73 loss 0.036 score 0.470 lr 6.33642e-07 
05/06/2021 19:38:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 47900 Ep: 17.74 loss 0.038 score 0.469 lr 6.29527e-07 
05/06/2021 19:39:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 47940 Ep: 17.76 loss 0.032 score 0.470 lr 6.25412e-07 
05/06/2021 19:40:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 47980 Ep: 17.77 loss 0.037 score 0.467 lr 6.21296e-07 
05/06/2021 19:41:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 48020 Ep: 17.79 loss 0.040 score 0.468 lr 6.17181e-07 
05/06/2021 19:42:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 48060 Ep: 17.80 loss 0.040 score 0.467 lr 6.13066e-07 
05/06/2021 19:43:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 48100 Ep: 17.81 loss 0.039 score 0.467 lr 6.08951e-07 
05/06/2021 19:44:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 48140 Ep: 17.83 loss 0.038 score 0.469 lr 6.04835e-07 
05/06/2021 19:45:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 48180 Ep: 17.84 loss 0.037 score 0.468 lr 6.0072e-07 
05/06/2021 19:46:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 48220 Ep: 17.86 loss 0.036 score 0.468 lr 5.96605e-07 
05/06/2021 19:47:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 48260 Ep: 17.87 loss 0.037 score 0.472 lr 5.9249e-07 
05/06/2021 19:48:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 48300 Ep: 17.89 loss 0.033 score 0.471 lr 5.88374e-07 
05/06/2021 19:49:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 48340 Ep: 17.90 loss 0.043 score 0.466 lr 5.84259e-07 
05/06/2021 19:50:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 48380 Ep: 17.92 loss 0.047 score 0.469 lr 5.80144e-07 
05/06/2021 19:51:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 48420 Ep: 17.93 loss 0.035 score 0.472 lr 5.76029e-07 
05/06/2021 19:52:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 48460 Ep: 17.95 loss 0.038 score 0.468 lr 5.71914e-07 
05/06/2021 19:53:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 48500 Ep: 17.96 loss 0.043 score 0.463 lr 5.67798e-07 
05/06/2021 19:54:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 48540 Ep: 17.98 loss 0.037 score 0.471 lr 5.63683e-07 
05/06/2021 19:55:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 48580 Ep: 17.99 loss 0.041 score 0.468 lr 5.59568e-07 
05/06/2021 19:55:38 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  90%| | 18/20 [24:41:04<3:08:17, 5648.55s/it]05/06/2021 20:13:33 - INFO - volta.train_utils -   Eval task TASK12 on iteration 48600 
05/06/2021 20:13:33 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 1.279 score 68.763 
05/06/2021 20:13:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 48640 Ep: 18.01 loss 0.035 score 0.470 lr 5.54424e-07 
05/06/2021 20:14:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 48680 Ep: 18.03 loss 0.031 score 0.479 lr 5.4928e-07 
05/06/2021 20:15:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 48720 Ep: 18.04 loss 0.032 score 0.470 lr 5.45165e-07 
05/06/2021 20:16:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 48760 Ep: 18.06 loss 0.034 score 0.471 lr 5.41049e-07 
05/06/2021 20:17:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 48800 Ep: 18.07 loss 0.034 score 0.470 lr 5.36934e-07 
05/06/2021 20:18:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 48840 Ep: 18.09 loss 0.034 score 0.470 lr 5.32819e-07 
05/06/2021 20:19:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 48880 Ep: 18.10 loss 0.030 score 0.469 lr 5.28704e-07 
05/06/2021 20:20:15 - INFO - volta.train_utils -   [NLVR2zh]: iter 48920 Ep: 18.12 loss 0.035 score 0.476 lr 5.24588e-07 
05/06/2021 20:21:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 48960 Ep: 18.13 loss 0.040 score 0.468 lr 5.20473e-07 
05/06/2021 20:22:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 49000 Ep: 18.15 loss 0.032 score 0.474 lr 5.16358e-07 
05/06/2021 20:23:10 - INFO - volta.train_utils -   [NLVR2zh]: iter 49040 Ep: 18.16 loss 0.033 score 0.473 lr 5.12243e-07 
05/06/2021 20:24:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 49080 Ep: 18.18 loss 0.036 score 0.469 lr 5.08128e-07 
05/06/2021 20:25:21 - INFO - volta.train_utils -   [NLVR2zh]: iter 49120 Ep: 18.19 loss 0.037 score 0.470 lr 5.04012e-07 
05/06/2021 20:26:24 - INFO - volta.train_utils -   [NLVR2zh]: iter 49160 Ep: 18.21 loss 0.047 score 0.467 lr 4.99897e-07 
05/06/2021 20:27:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 49200 Ep: 18.22 loss 0.031 score 0.471 lr 4.95782e-07 
05/06/2021 20:28:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 49240 Ep: 18.24 loss 0.034 score 0.466 lr 4.91667e-07 
05/06/2021 20:29:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 49280 Ep: 18.25 loss 0.037 score 0.466 lr 4.87551e-07 
05/06/2021 20:30:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 49320 Ep: 18.27 loss 0.034 score 0.471 lr 4.83436e-07 
05/06/2021 20:31:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 49360 Ep: 18.28 loss 0.036 score 0.470 lr 4.79321e-07 
05/06/2021 20:32:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 49400 Ep: 18.30 loss 0.029 score 0.473 lr 4.75206e-07 
05/06/2021 20:33:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 49440 Ep: 18.31 loss 0.042 score 0.468 lr 4.71091e-07 
05/06/2021 20:34:59 - INFO - volta.train_utils -   [NLVR2zh]: iter 49480 Ep: 18.33 loss 0.030 score 0.472 lr 4.66975e-07 
05/06/2021 20:36:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 49520 Ep: 18.34 loss 0.028 score 0.480 lr 4.6286e-07 
05/06/2021 20:37:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 49560 Ep: 18.36 loss 0.034 score 0.477 lr 4.58745e-07 
05/06/2021 20:38:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 49600 Ep: 18.37 loss 0.040 score 0.464 lr 4.5463e-07 
05/06/2021 20:39:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 49640 Ep: 18.39 loss 0.029 score 0.479 lr 4.50514e-07 
05/06/2021 20:40:18 - INFO - volta.train_utils -   [NLVR2zh]: iter 49680 Ep: 18.40 loss 0.029 score 0.474 lr 4.46399e-07 
05/06/2021 20:41:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 49720 Ep: 18.41 loss 0.034 score 0.473 lr 4.42284e-07 
05/06/2021 20:42:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 49760 Ep: 18.43 loss 0.037 score 0.469 lr 4.38169e-07 
05/06/2021 20:43:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 49800 Ep: 18.44 loss 0.039 score 0.471 lr 4.34053e-07 
05/06/2021 20:44:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 49840 Ep: 18.46 loss 0.038 score 0.470 lr 4.29938e-07 
05/06/2021 20:45:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 49880 Ep: 18.47 loss 0.044 score 0.461 lr 4.25823e-07 
05/06/2021 20:46:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 49920 Ep: 18.49 loss 0.037 score 0.469 lr 4.21708e-07 
05/06/2021 20:47:28 - INFO - volta.train_utils -   [NLVR2zh]: iter 49960 Ep: 18.50 loss 0.036 score 0.477 lr 4.17593e-07 
05/06/2021 20:48:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 50000 Ep: 18.52 loss 0.034 score 0.473 lr 4.13477e-07 
05/06/2021 20:49:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 50040 Ep: 18.53 loss 0.036 score 0.471 lr 4.09362e-07 
05/06/2021 20:50:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 50080 Ep: 18.55 loss 0.038 score 0.469 lr 4.05247e-07 
05/06/2021 20:51:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 50120 Ep: 18.56 loss 0.034 score 0.469 lr 4.01132e-07 
05/06/2021 20:52:17 - INFO - volta.train_utils -   [NLVR2zh]: iter 50160 Ep: 18.58 loss 0.037 score 0.472 lr 3.97016e-07 
05/06/2021 20:53:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 50200 Ep: 18.59 loss 0.033 score 0.469 lr 3.92901e-07 
05/06/2021 20:54:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 50240 Ep: 18.61 loss 0.034 score 0.475 lr 3.88786e-07 
05/06/2021 20:54:55 - INFO - volta.train_utils -   [NLVR2zh]: iter 50280 Ep: 18.62 loss 0.028 score 0.473 lr 3.84671e-07 
05/06/2021 20:55:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 50320 Ep: 18.64 loss 0.039 score 0.468 lr 3.80556e-07 
05/06/2021 20:56:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 50360 Ep: 18.65 loss 0.036 score 0.471 lr 3.7644e-07 
05/06/2021 20:57:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 50400 Ep: 18.67 loss 0.041 score 0.469 lr 3.72325e-07 
05/06/2021 20:58:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 50440 Ep: 18.68 loss 0.037 score 0.476 lr 3.6821e-07 
05/06/2021 20:59:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 50480 Ep: 18.70 loss 0.035 score 0.470 lr 3.64095e-07 
05/06/2021 21:00:09 - INFO - volta.train_utils -   [NLVR2zh]: iter 50520 Ep: 18.71 loss 0.030 score 0.476 lr 3.59979e-07 
05/06/2021 21:00:56 - INFO - volta.train_utils -   [NLVR2zh]: iter 50560 Ep: 18.73 loss 0.031 score 0.471 lr 3.55864e-07 
05/06/2021 21:01:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 50600 Ep: 18.74 loss 0.033 score 0.473 lr 3.51749e-07 
05/06/2021 21:02:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 50640 Ep: 18.76 loss 0.033 score 0.469 lr 3.47634e-07 
05/06/2021 21:03:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 50680 Ep: 18.77 loss 0.040 score 0.468 lr 3.43519e-07 
05/06/2021 21:04:20 - INFO - volta.train_utils -   [NLVR2zh]: iter 50720 Ep: 18.79 loss 0.032 score 0.473 lr 3.39403e-07 
05/06/2021 21:05:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 50760 Ep: 18.80 loss 0.041 score 0.473 lr 3.35288e-07 
05/06/2021 21:06:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 50800 Ep: 18.81 loss 0.035 score 0.474 lr 3.31173e-07 
05/06/2021 21:07:04 - INFO - volta.train_utils -   [NLVR2zh]: iter 50840 Ep: 18.83 loss 0.032 score 0.471 lr 3.27058e-07 
05/06/2021 21:07:50 - INFO - volta.train_utils -   [NLVR2zh]: iter 50880 Ep: 18.84 loss 0.028 score 0.473 lr 3.22942e-07 
05/06/2021 21:08:47 - INFO - volta.train_utils -   [NLVR2zh]: iter 50920 Ep: 18.86 loss 0.042 score 0.469 lr 3.18827e-07 
05/06/2021 21:09:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 50960 Ep: 18.87 loss 0.030 score 0.475 lr 3.14712e-07 
05/06/2021 21:10:22 - INFO - volta.train_utils -   [NLVR2zh]: iter 51000 Ep: 18.89 loss 0.033 score 0.472 lr 3.10597e-07 
05/06/2021 21:11:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 51040 Ep: 18.90 loss 0.035 score 0.473 lr 3.06481e-07 
05/06/2021 21:12:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 51080 Ep: 18.92 loss 0.034 score 0.472 lr 3.02366e-07 
05/06/2021 21:12:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 51120 Ep: 18.93 loss 0.036 score 0.472 lr 2.98251e-07 
05/06/2021 21:13:44 - INFO - volta.train_utils -   [NLVR2zh]: iter 51160 Ep: 18.95 loss 0.029 score 0.476 lr 2.94136e-07 
05/06/2021 21:14:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 51200 Ep: 18.96 loss 0.037 score 0.473 lr 2.90021e-07 
05/06/2021 21:15:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 51240 Ep: 18.98 loss 0.029 score 0.469 lr 2.85905e-07 
05/06/2021 21:16:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 51280 Ep: 18.99 loss 0.037 score 0.471 lr 2.8179e-07 
05/06/2021 21:16:55 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  95%|| 19/20 [26:02:23<1:30:17, 5417.83s/it]05/06/2021 21:35:49 - INFO - volta.train_utils -   Eval task TASK12 on iteration 51300 
05/06/2021 21:35:49 - INFO - volta.train_utils -   Validation [NLVR2zh]: loss 1.324 score 68.877 
05/06/2021 21:36:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 51340 Ep: 19.01 loss 0.036 score 0.474 lr 2.76646e-07 
05/06/2021 21:37:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 51380 Ep: 19.03 loss 0.028 score 0.476 lr 2.71502e-07 
05/06/2021 21:38:13 - INFO - volta.train_utils -   [NLVR2zh]: iter 51420 Ep: 19.04 loss 0.031 score 0.476 lr 2.67387e-07 
05/06/2021 21:39:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 51460 Ep: 19.06 loss 0.033 score 0.466 lr 2.63272e-07 
05/06/2021 21:39:57 - INFO - volta.train_utils -   [NLVR2zh]: iter 51500 Ep: 19.07 loss 0.039 score 0.471 lr 2.59156e-07 
05/06/2021 21:41:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 51540 Ep: 19.09 loss 0.031 score 0.470 lr 2.55041e-07 
05/06/2021 21:41:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 51580 Ep: 19.10 loss 0.034 score 0.474 lr 2.50926e-07 
05/06/2021 21:42:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 51620 Ep: 19.12 loss 0.030 score 0.472 lr 2.46811e-07 
05/06/2021 21:43:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 51660 Ep: 19.13 loss 0.024 score 0.476 lr 2.42695e-07 
05/06/2021 21:44:54 - INFO - volta.train_utils -   [NLVR2zh]: iter 51700 Ep: 19.15 loss 0.033 score 0.473 lr 2.3858e-07 
05/06/2021 21:46:01 - INFO - volta.train_utils -   [NLVR2zh]: iter 51740 Ep: 19.16 loss 0.037 score 0.470 lr 2.34465e-07 
05/06/2021 21:47:19 - INFO - volta.train_utils -   [NLVR2zh]: iter 51780 Ep: 19.18 loss 0.039 score 0.470 lr 2.3035e-07 
05/06/2021 21:48:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 51820 Ep: 19.19 loss 0.042 score 0.468 lr 2.26235e-07 
05/06/2021 21:49:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 51860 Ep: 19.21 loss 0.044 score 0.466 lr 2.22119e-07 
05/06/2021 21:51:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 51900 Ep: 19.22 loss 0.039 score 0.473 lr 2.18004e-07 
05/06/2021 21:52:05 - INFO - volta.train_utils -   [NLVR2zh]: iter 51940 Ep: 19.24 loss 0.031 score 0.475 lr 2.13889e-07 
05/06/2021 21:53:02 - INFO - volta.train_utils -   [NLVR2zh]: iter 51980 Ep: 19.25 loss 0.028 score 0.473 lr 2.09774e-07 
05/06/2021 21:54:08 - INFO - volta.train_utils -   [NLVR2zh]: iter 52020 Ep: 19.27 loss 0.034 score 0.473 lr 2.05658e-07 
05/06/2021 21:55:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 52060 Ep: 19.28 loss 0.034 score 0.478 lr 2.01543e-07 
05/06/2021 21:56:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 52100 Ep: 19.30 loss 0.033 score 0.473 lr 1.97428e-07 
05/06/2021 21:57:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 52140 Ep: 19.31 loss 0.037 score 0.468 lr 1.93313e-07 
05/06/2021 21:59:16 - INFO - volta.train_utils -   [NLVR2zh]: iter 52180 Ep: 19.33 loss 0.032 score 0.475 lr 1.89198e-07 
05/06/2021 22:00:14 - INFO - volta.train_utils -   [NLVR2zh]: iter 52220 Ep: 19.34 loss 0.030 score 0.471 lr 1.85082e-07 
05/06/2021 22:01:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 52260 Ep: 19.36 loss 0.033 score 0.469 lr 1.80967e-07 
05/06/2021 22:02:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 52300 Ep: 19.37 loss 0.027 score 0.471 lr 1.76852e-07 
05/06/2021 22:03:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 52340 Ep: 19.39 loss 0.037 score 0.471 lr 1.72737e-07 
05/06/2021 22:04:51 - INFO - volta.train_utils -   [NLVR2zh]: iter 52380 Ep: 19.40 loss 0.038 score 0.472 lr 1.68621e-07 
05/06/2021 22:06:03 - INFO - volta.train_utils -   [NLVR2zh]: iter 52420 Ep: 19.41 loss 0.034 score 0.475 lr 1.64506e-07 
05/06/2021 22:07:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 52460 Ep: 19.43 loss 0.034 score 0.475 lr 1.60391e-07 
05/06/2021 22:08:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 52500 Ep: 19.44 loss 0.031 score 0.474 lr 1.56276e-07 
05/06/2021 22:09:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 52540 Ep: 19.46 loss 0.026 score 0.477 lr 1.5216e-07 
05/06/2021 22:10:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 52580 Ep: 19.47 loss 0.034 score 0.476 lr 1.48045e-07 
05/06/2021 22:11:39 - INFO - volta.train_utils -   [NLVR2zh]: iter 52620 Ep: 19.49 loss 0.028 score 0.477 lr 1.4393e-07 
05/06/2021 22:12:48 - INFO - volta.train_utils -   [NLVR2zh]: iter 52660 Ep: 19.50 loss 0.029 score 0.474 lr 1.39815e-07 
05/06/2021 22:13:40 - INFO - volta.train_utils -   [NLVR2zh]: iter 52700 Ep: 19.52 loss 0.032 score 0.469 lr 1.357e-07 
05/06/2021 22:14:41 - INFO - volta.train_utils -   [NLVR2zh]: iter 52740 Ep: 19.53 loss 0.031 score 0.475 lr 1.31584e-07 
05/06/2021 22:15:29 - INFO - volta.train_utils -   [NLVR2zh]: iter 52780 Ep: 19.55 loss 0.035 score 0.473 lr 1.27469e-07 
05/06/2021 22:16:36 - INFO - volta.train_utils -   [NLVR2zh]: iter 52820 Ep: 19.56 loss 0.030 score 0.474 lr 1.23354e-07 
05/06/2021 22:17:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 52860 Ep: 19.58 loss 0.031 score 0.471 lr 1.19239e-07 
05/06/2021 22:18:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 52900 Ep: 19.59 loss 0.026 score 0.482 lr 1.15123e-07 
05/06/2021 22:19:23 - INFO - volta.train_utils -   [NLVR2zh]: iter 52940 Ep: 19.61 loss 0.027 score 0.476 lr 1.11008e-07 
05/06/2021 22:20:30 - INFO - volta.train_utils -   [NLVR2zh]: iter 52980 Ep: 19.62 loss 0.030 score 0.477 lr 1.06893e-07 
05/06/2021 22:21:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 53020 Ep: 19.64 loss 0.032 score 0.474 lr 1.02778e-07 
05/06/2021 22:22:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 53060 Ep: 19.65 loss 0.034 score 0.470 lr 9.86626e-08 
05/06/2021 22:23:33 - INFO - volta.train_utils -   [NLVR2zh]: iter 53100 Ep: 19.67 loss 0.050 score 0.471 lr 9.45473e-08 
05/06/2021 22:24:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 53140 Ep: 19.68 loss 0.035 score 0.469 lr 9.04321e-08 
05/06/2021 22:25:38 - INFO - volta.train_utils -   [NLVR2zh]: iter 53180 Ep: 19.70 loss 0.026 score 0.475 lr 8.63169e-08 
05/06/2021 22:26:42 - INFO - volta.train_utils -   [NLVR2zh]: iter 53220 Ep: 19.71 loss 0.031 score 0.477 lr 8.22016e-08 
05/06/2021 22:27:37 - INFO - volta.train_utils -   [NLVR2zh]: iter 53260 Ep: 19.73 loss 0.036 score 0.469 lr 7.80864e-08 
05/06/2021 22:28:43 - INFO - volta.train_utils -   [NLVR2zh]: iter 53300 Ep: 19.74 loss 0.031 score 0.473 lr 7.39712e-08 
05/06/2021 22:29:26 - INFO - volta.train_utils -   [NLVR2zh]: iter 53340 Ep: 19.76 loss 0.027 score 0.477 lr 6.9856e-08 
05/06/2021 22:30:49 - INFO - volta.train_utils -   [NLVR2zh]: iter 53380 Ep: 19.77 loss 0.035 score 0.471 lr 6.57407e-08 
05/06/2021 22:31:45 - INFO - volta.train_utils -   [NLVR2zh]: iter 53420 Ep: 19.79 loss 0.034 score 0.468 lr 6.16255e-08 
05/06/2021 22:32:58 - INFO - volta.train_utils -   [NLVR2zh]: iter 53460 Ep: 19.80 loss 0.028 score 0.480 lr 5.75103e-08 
05/06/2021 22:33:53 - INFO - volta.train_utils -   [NLVR2zh]: iter 53500 Ep: 19.81 loss 0.032 score 0.473 lr 5.33951e-08 
05/06/2021 22:35:00 - INFO - volta.train_utils -   [NLVR2zh]: iter 53540 Ep: 19.83 loss 0.033 score 0.473 lr 4.92798e-08 
05/06/2021 22:36:12 - INFO - volta.train_utils -   [NLVR2zh]: iter 53580 Ep: 19.84 loss 0.039 score 0.471 lr 4.51646e-08 
05/06/2021 22:37:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 53620 Ep: 19.86 loss 0.035 score 0.470 lr 4.10494e-08 
05/06/2021 22:38:25 - INFO - volta.train_utils -   [NLVR2zh]: iter 53660 Ep: 19.87 loss 0.031 score 0.475 lr 3.69342e-08 
05/06/2021 22:39:52 - INFO - volta.train_utils -   [NLVR2zh]: iter 53700 Ep: 19.89 loss 0.033 score 0.473 lr 3.28189e-08 
05/06/2021 22:41:11 - INFO - volta.train_utils -   [NLVR2zh]: iter 53740 Ep: 19.90 loss 0.030 score 0.470 lr 2.87037e-08 
05/06/2021 22:42:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 53780 Ep: 19.92 loss 0.032 score 0.476 lr 2.45885e-08 
05/06/2021 22:43:32 - INFO - volta.train_utils -   [NLVR2zh]: iter 53820 Ep: 19.93 loss 0.035 score 0.472 lr 2.04733e-08 
05/06/2021 22:44:31 - INFO - volta.train_utils -   [NLVR2zh]: iter 53860 Ep: 19.95 loss 0.028 score 0.478 lr 1.6358e-08 
05/06/2021 22:45:46 - INFO - volta.train_utils -   [NLVR2zh]: iter 53900 Ep: 19.96 loss 0.035 score 0.472 lr 1.22428e-08 
05/06/2021 22:47:27 - INFO - volta.train_utils -   [NLVR2zh]: iter 53940 Ep: 19.98 loss 0.029 score 0.468 lr 8.12757e-09 
05/06/2021 22:48:35 - INFO - volta.train_utils -   [NLVR2zh]: iter 53980 Ep: 19.99 loss 0.032 score 0.477 lr 4.01235e-09 
05/06/2021 22:48:51 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch: 100%|| 20/20 [27:34:19<00:00, 5447.15s/it]  
