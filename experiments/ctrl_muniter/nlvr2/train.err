WARNING:tensorflow:From /home/projects/ku_00062/envs/marvl/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/marvl/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/marvl/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.

05/02/2021 10:29:30 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False
05/02/2021 10:29:31 - INFO - volta.task_utils -   Loading NLVR2 Dataset with batch size 32
05/02/2021 10:29:31 - INFO - volta.datasets.nlvr2_dataset -   Loading from /home/projects/ku_00062/data/nlvr2/annotations/cache/NLVR2_train_80.pkl
05/02/2021 10:29:54 - INFO - volta.datasets.nlvr2_dataset -   Loading from /home/projects/ku_00062/data/nlvr2/annotations/cache/NLVR2_dev_80.pkl
05/02/2021 10:29:55 - INFO - volta.train_utils -   logging file at: /home/projects/ku_00062/logs/mlvr/ctrl_muniter_base/NLVR2_ctrl_muniter_base
05/02/2021 10:29:55 - INFO - volta.utils -   loading weights file /home/projects/ku_00062/checkpoints/mlvr/ctrl_muniter/conceptual_captions_wikipedia/ctrl_muniter_base/pytorch_model_9.bin
05/02/2021 10:30:01 - INFO - volta.utils -   
05/02/2021 10:30:01 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['bert.embeddings.image_token_type_embeddings.weight', 'clfs_dict.TASK12.logit_fc.0.weight', 'clfs_dict.TASK12.logit_fc.0.bias', 'clfs_dict.TASK12.logit_fc.2.weight', 'clfs_dict.TASK12.logit_fc.2.bias', 'clfs_dict.TASK12.logit_fc.3.weight', 'clfs_dict.TASK12.logit_fc.3.bias']
05/02/2021 10:30:01 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLTasks: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
05/02/2021 10:30:05 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/02/2021 10:30:11 - INFO - __main__ -   >> Parameters:
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |Name                                                       |Dtype            |Shape            |#Params     |Trainable|
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.word_embeddings.weight                     |torch.float32    |(119547, 768)    |91812096    |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.position_embeddings.weight                 |torch.float32    |(512, 768)       |393216      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.token_type_embeddings.weight               |torch.float32    |(2, 768)         |1536        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.LayerNorm.weight                           |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.LayerNorm.bias                             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)      |1572864     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.image_embeddings.bias                      |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.image_location_embeddings.weight           |torch.float32    |(768, 5)         |3840        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.image_location_embeddings.bias             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.image_layer_norm.weight                    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.image_layer_norm.bias                      |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.image_location_layer_norm.weight           |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.image_location_layer_norm.bias             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.v_LayerNorm.weight                         |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.embeddings.v_LayerNorm.bias                           |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.t_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.t_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.v_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432      |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |bert.v_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.0.weight                         |torch.float32    |(1536, 2048)     |3145728     |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.0.bias                           |torch.float32    |(1536,)          |1536        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.2.weight                         |torch.float32    |(1536,)          |1536        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.2.bias                           |torch.float32    |(1536,)          |1536        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.3.weight                         |torch.float32    |(2, 1536)        |3072        |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.3.bias                           |torch.float32    |(2,)             |2           |True    |
05/02/2021 10:30:11 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
05/02/2021 10:30:11 - INFO - __main__ -   >> # TrainableParams:       	183.57	M
05/02/2021 10:30:11 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
05/02/2021 10:30:11 - INFO - __main__ -   >> # TotalParams:           	183.57	M

Epoch:   0%|          | 0/20 [00:00<?, ?it/s]05/02/2021 10:31:28 - INFO - volta.train_utils -   [NLVR2]: iter 40 Ep: 0.01 loss 0.214 score 0.245 lr 1.94444e-08 
05/02/2021 10:32:31 - INFO - volta.train_utils -   [NLVR2]: iter 80 Ep: 0.03 loss 0.212 score 0.242 lr 5.64815e-08 
05/02/2021 10:33:21 - INFO - volta.train_utils -   [NLVR2]: iter 120 Ep: 0.04 loss 0.212 score 0.247 lr 9.35185e-08 
05/02/2021 10:34:22 - INFO - volta.train_utils -   [NLVR2]: iter 160 Ep: 0.06 loss 0.206 score 0.250 lr 1.30556e-07 
05/02/2021 10:35:20 - INFO - volta.train_utils -   [NLVR2]: iter 200 Ep: 0.07 loss 0.201 score 0.243 lr 1.67593e-07 
05/02/2021 10:36:09 - INFO - volta.train_utils -   [NLVR2]: iter 240 Ep: 0.09 loss 0.196 score 0.249 lr 2.0463e-07 
05/02/2021 10:37:12 - INFO - volta.train_utils -   [NLVR2]: iter 280 Ep: 0.10 loss 0.192 score 0.253 lr 2.41667e-07 
05/02/2021 10:37:59 - INFO - volta.train_utils -   [NLVR2]: iter 320 Ep: 0.12 loss 0.183 score 0.248 lr 2.78704e-07 
05/02/2021 10:38:55 - INFO - volta.train_utils -   [NLVR2]: iter 360 Ep: 0.13 loss 0.181 score 0.238 lr 3.15741e-07 
05/02/2021 10:39:44 - INFO - volta.train_utils -   [NLVR2]: iter 400 Ep: 0.15 loss 0.178 score 0.247 lr 3.52778e-07 
05/02/2021 10:40:37 - INFO - volta.train_utils -   [NLVR2]: iter 440 Ep: 0.16 loss 0.178 score 0.266 lr 3.89815e-07 
05/02/2021 10:41:19 - INFO - volta.train_utils -   [NLVR2]: iter 480 Ep: 0.18 loss 0.176 score 0.262 lr 4.26852e-07 
05/02/2021 10:42:13 - INFO - volta.train_utils -   [NLVR2]: iter 520 Ep: 0.19 loss 0.175 score 0.272 lr 4.63889e-07 
05/02/2021 10:42:57 - INFO - volta.train_utils -   [NLVR2]: iter 560 Ep: 0.21 loss 0.175 score 0.267 lr 5.00926e-07 
05/02/2021 10:43:49 - INFO - volta.train_utils -   [NLVR2]: iter 600 Ep: 0.22 loss 0.172 score 0.266 lr 5.37963e-07 
05/02/2021 10:44:30 - INFO - volta.train_utils -   [NLVR2]: iter 640 Ep: 0.24 loss 0.174 score 0.274 lr 5.75e-07 
05/02/2021 10:45:22 - INFO - volta.train_utils -   [NLVR2]: iter 680 Ep: 0.25 loss 0.171 score 0.284 lr 6.12037e-07 
05/02/2021 10:46:06 - INFO - volta.train_utils -   [NLVR2]: iter 720 Ep: 0.27 loss 0.172 score 0.276 lr 6.49074e-07 
05/02/2021 10:46:55 - INFO - volta.train_utils -   [NLVR2]: iter 760 Ep: 0.28 loss 0.174 score 0.279 lr 6.86111e-07 
05/02/2021 10:47:36 - INFO - volta.train_utils -   [NLVR2]: iter 800 Ep: 0.30 loss 0.168 score 0.282 lr 7.23148e-07 
05/02/2021 10:48:30 - INFO - volta.train_utils -   [NLVR2]: iter 840 Ep: 0.31 loss 0.171 score 0.282 lr 7.60185e-07 
05/02/2021 10:49:12 - INFO - volta.train_utils -   [NLVR2]: iter 880 Ep: 0.33 loss 0.172 score 0.270 lr 7.97222e-07 
05/02/2021 10:50:04 - INFO - volta.train_utils -   [NLVR2]: iter 920 Ep: 0.34 loss 0.173 score 0.277 lr 8.34259e-07 
05/02/2021 10:50:48 - INFO - volta.train_utils -   [NLVR2]: iter 960 Ep: 0.36 loss 0.174 score 0.278 lr 8.71296e-07 
05/02/2021 10:51:43 - INFO - volta.train_utils -   [NLVR2]: iter 1000 Ep: 0.37 loss 0.171 score 0.278 lr 9.08333e-07 
05/02/2021 10:52:27 - INFO - volta.train_utils -   [NLVR2]: iter 1040 Ep: 0.39 loss 0.171 score 0.284 lr 9.4537e-07 
05/02/2021 10:53:27 - INFO - volta.train_utils -   [NLVR2]: iter 1080 Ep: 0.40 loss 0.170 score 0.287 lr 9.82407e-07 
05/02/2021 10:54:11 - INFO - volta.train_utils -   [NLVR2]: iter 1120 Ep: 0.41 loss 0.168 score 0.298 lr 1.01944e-06 
05/02/2021 10:55:07 - INFO - volta.train_utils -   [NLVR2]: iter 1160 Ep: 0.43 loss 0.171 score 0.284 lr 1.05648e-06 
05/02/2021 10:55:52 - INFO - volta.train_utils -   [NLVR2]: iter 1200 Ep: 0.44 loss 0.170 score 0.278 lr 1.09352e-06 
05/02/2021 10:56:48 - INFO - volta.train_utils -   [NLVR2]: iter 1240 Ep: 0.46 loss 0.168 score 0.285 lr 1.13056e-06 
05/02/2021 10:57:31 - INFO - volta.train_utils -   [NLVR2]: iter 1280 Ep: 0.47 loss 0.170 score 0.277 lr 1.16759e-06 
05/02/2021 10:58:25 - INFO - volta.train_utils -   [NLVR2]: iter 1320 Ep: 0.49 loss 0.168 score 0.304 lr 1.20463e-06 
05/02/2021 10:59:10 - INFO - volta.train_utils -   [NLVR2]: iter 1360 Ep: 0.50 loss 0.169 score 0.284 lr 1.24167e-06 
05/02/2021 11:00:06 - INFO - volta.train_utils -   [NLVR2]: iter 1400 Ep: 0.52 loss 0.162 score 0.306 lr 1.2787e-06 
05/02/2021 11:00:52 - INFO - volta.train_utils -   [NLVR2]: iter 1440 Ep: 0.53 loss 0.172 score 0.282 lr 1.31574e-06 
05/02/2021 11:01:47 - INFO - volta.train_utils -   [NLVR2]: iter 1480 Ep: 0.55 loss 0.171 score 0.296 lr 1.35278e-06 
05/02/2021 11:02:30 - INFO - volta.train_utils -   [NLVR2]: iter 1520 Ep: 0.56 loss 0.167 score 0.301 lr 1.38981e-06 
05/02/2021 11:03:28 - INFO - volta.train_utils -   [NLVR2]: iter 1560 Ep: 0.58 loss 0.171 score 0.291 lr 1.42685e-06 
05/02/2021 11:04:10 - INFO - volta.train_utils -   [NLVR2]: iter 1600 Ep: 0.59 loss 0.165 score 0.298 lr 1.46389e-06 
05/02/2021 11:05:05 - INFO - volta.train_utils -   [NLVR2]: iter 1640 Ep: 0.61 loss 0.163 score 0.305 lr 1.50093e-06 
05/02/2021 11:05:46 - INFO - volta.train_utils -   [NLVR2]: iter 1680 Ep: 0.62 loss 0.166 score 0.312 lr 1.53796e-06 
05/02/2021 11:06:43 - INFO - volta.train_utils -   [NLVR2]: iter 1720 Ep: 0.64 loss 0.164 score 0.301 lr 1.575e-06 
05/02/2021 11:07:31 - INFO - volta.train_utils -   [NLVR2]: iter 1760 Ep: 0.65 loss 0.166 score 0.285 lr 1.61204e-06 
05/02/2021 11:08:27 - INFO - volta.train_utils -   [NLVR2]: iter 1800 Ep: 0.67 loss 0.165 score 0.297 lr 1.64907e-06 
05/02/2021 11:09:11 - INFO - volta.train_utils -   [NLVR2]: iter 1840 Ep: 0.68 loss 0.164 score 0.302 lr 1.68611e-06 
05/02/2021 11:10:07 - INFO - volta.train_utils -   [NLVR2]: iter 1880 Ep: 0.70 loss 0.165 score 0.308 lr 1.72315e-06 
05/02/2021 11:10:51 - INFO - volta.train_utils -   [NLVR2]: iter 1920 Ep: 0.71 loss 0.165 score 0.299 lr 1.76019e-06 
05/02/2021 11:11:47 - INFO - volta.train_utils -   [NLVR2]: iter 1960 Ep: 0.73 loss 0.166 score 0.300 lr 1.79722e-06 
05/02/2021 11:12:33 - INFO - volta.train_utils -   [NLVR2]: iter 2000 Ep: 0.74 loss 0.160 score 0.310 lr 1.83426e-06 
05/02/2021 11:13:29 - INFO - volta.train_utils -   [NLVR2]: iter 2040 Ep: 0.76 loss 0.163 score 0.308 lr 1.8713e-06 
05/02/2021 11:14:09 - INFO - volta.train_utils -   [NLVR2]: iter 2080 Ep: 0.77 loss 0.166 score 0.310 lr 1.90833e-06 
05/02/2021 11:15:06 - INFO - volta.train_utils -   [NLVR2]: iter 2120 Ep: 0.79 loss 0.165 score 0.299 lr 1.94537e-06 
05/02/2021 11:15:51 - INFO - volta.train_utils -   [NLVR2]: iter 2160 Ep: 0.80 loss 0.159 score 0.306 lr 1.98241e-06 
05/02/2021 11:16:49 - INFO - volta.train_utils -   [NLVR2]: iter 2200 Ep: 0.81 loss 0.159 score 0.315 lr 2.01944e-06 
05/02/2021 11:17:35 - INFO - volta.train_utils -   [NLVR2]: iter 2240 Ep: 0.83 loss 0.156 score 0.322 lr 2.05648e-06 
05/02/2021 11:18:28 - INFO - volta.train_utils -   [NLVR2]: iter 2280 Ep: 0.84 loss 0.166 score 0.300 lr 2.09352e-06 
05/02/2021 11:19:12 - INFO - volta.train_utils -   [NLVR2]: iter 2320 Ep: 0.86 loss 0.157 score 0.310 lr 2.13056e-06 
05/02/2021 11:20:07 - INFO - volta.train_utils -   [NLVR2]: iter 2360 Ep: 0.87 loss 0.158 score 0.312 lr 2.16759e-06 
05/02/2021 11:20:51 - INFO - volta.train_utils -   [NLVR2]: iter 2400 Ep: 0.89 loss 0.163 score 0.300 lr 2.20463e-06 
05/02/2021 11:21:49 - INFO - volta.train_utils -   [NLVR2]: iter 2440 Ep: 0.90 loss 0.159 score 0.314 lr 2.24167e-06 
05/02/2021 11:22:34 - INFO - volta.train_utils -   [NLVR2]: iter 2480 Ep: 0.92 loss 0.159 score 0.306 lr 2.2787e-06 
05/02/2021 11:23:28 - INFO - volta.train_utils -   [NLVR2]: iter 2520 Ep: 0.93 loss 0.156 score 0.318 lr 2.31574e-06 
05/02/2021 11:24:13 - INFO - volta.train_utils -   [NLVR2]: iter 2560 Ep: 0.95 loss 0.154 score 0.308 lr 2.35278e-06 
05/02/2021 11:25:13 - INFO - volta.train_utils -   [NLVR2]: iter 2600 Ep: 0.96 loss 0.153 score 0.313 lr 2.38981e-06 
05/02/2021 11:26:02 - INFO - volta.train_utils -   [NLVR2]: iter 2640 Ep: 0.98 loss 0.163 score 0.316 lr 2.42685e-06 
05/02/2021 11:26:50 - INFO - volta.train_utils -   [NLVR2]: iter 2680 Ep: 0.99 loss 0.163 score 0.311 lr 2.46389e-06 
05/02/2021 11:27:07 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:   5%|         | 1/20 [57:07<18:05:16, 3427.17s/it]05/02/2021 11:43:10 - INFO - volta.train_utils -   Eval task TASK12 on iteration 2700 
05/02/2021 11:43:10 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.622 score 64.366 
05/02/2021 11:43:10 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/02/2021 11:43:46 - INFO - volta.train_utils -   [NLVR2]: iter 2740 Ep: 1.01 loss 0.153 score 0.322 lr 2.51019e-06 
05/02/2021 11:44:34 - INFO - volta.train_utils -   [NLVR2]: iter 2780 Ep: 1.03 loss 0.157 score 0.329 lr 2.55648e-06 
05/02/2021 11:45:31 - INFO - volta.train_utils -   [NLVR2]: iter 2820 Ep: 1.04 loss 0.158 score 0.336 lr 2.59352e-06 
05/02/2021 11:46:20 - INFO - volta.train_utils -   [NLVR2]: iter 2860 Ep: 1.06 loss 0.156 score 0.317 lr 2.63056e-06 
05/02/2021 11:47:20 - INFO - volta.train_utils -   [NLVR2]: iter 2900 Ep: 1.07 loss 0.158 score 0.327 lr 2.66759e-06 
05/02/2021 11:48:07 - INFO - volta.train_utils -   [NLVR2]: iter 2940 Ep: 1.09 loss 0.158 score 0.309 lr 2.70463e-06 
05/02/2021 11:49:02 - INFO - volta.train_utils -   [NLVR2]: iter 2980 Ep: 1.10 loss 0.153 score 0.321 lr 2.74167e-06 
05/02/2021 11:49:43 - INFO - volta.train_utils -   [NLVR2]: iter 3020 Ep: 1.12 loss 0.161 score 0.308 lr 2.7787e-06 
05/02/2021 11:50:37 - INFO - volta.train_utils -   [NLVR2]: iter 3060 Ep: 1.13 loss 0.147 score 0.327 lr 2.81574e-06 
05/02/2021 11:51:19 - INFO - volta.train_utils -   [NLVR2]: iter 3100 Ep: 1.15 loss 0.153 score 0.328 lr 2.85278e-06 
05/02/2021 11:52:07 - INFO - volta.train_utils -   [NLVR2]: iter 3140 Ep: 1.16 loss 0.151 score 0.331 lr 2.88981e-06 
05/02/2021 11:52:52 - INFO - volta.train_utils -   [NLVR2]: iter 3180 Ep: 1.18 loss 0.159 score 0.320 lr 2.92685e-06 
05/02/2021 11:53:39 - INFO - volta.train_utils -   [NLVR2]: iter 3220 Ep: 1.19 loss 0.157 score 0.318 lr 2.96389e-06 
05/02/2021 11:54:23 - INFO - volta.train_utils -   [NLVR2]: iter 3260 Ep: 1.21 loss 0.150 score 0.334 lr 3.00093e-06 
05/02/2021 11:55:09 - INFO - volta.train_utils -   [NLVR2]: iter 3300 Ep: 1.22 loss 0.156 score 0.318 lr 3.03796e-06 
05/02/2021 11:55:46 - INFO - volta.train_utils -   [NLVR2]: iter 3340 Ep: 1.24 loss 0.154 score 0.330 lr 3.075e-06 
05/02/2021 11:56:33 - INFO - volta.train_utils -   [NLVR2]: iter 3380 Ep: 1.25 loss 0.159 score 0.336 lr 3.11204e-06 
05/02/2021 11:57:12 - INFO - volta.train_utils -   [NLVR2]: iter 3420 Ep: 1.27 loss 0.155 score 0.309 lr 3.14907e-06 
05/02/2021 11:57:55 - INFO - volta.train_utils -   [NLVR2]: iter 3460 Ep: 1.28 loss 0.151 score 0.326 lr 3.18611e-06 
05/02/2021 11:58:33 - INFO - volta.train_utils -   [NLVR2]: iter 3500 Ep: 1.30 loss 0.159 score 0.314 lr 3.22315e-06 
05/02/2021 11:59:20 - INFO - volta.train_utils -   [NLVR2]: iter 3540 Ep: 1.31 loss 0.156 score 0.328 lr 3.26019e-06 
05/02/2021 12:00:00 - INFO - volta.train_utils -   [NLVR2]: iter 3580 Ep: 1.33 loss 0.152 score 0.326 lr 3.29722e-06 
05/02/2021 12:00:46 - INFO - volta.train_utils -   [NLVR2]: iter 3620 Ep: 1.34 loss 0.155 score 0.328 lr 3.33426e-06 
05/02/2021 12:01:28 - INFO - volta.train_utils -   [NLVR2]: iter 3660 Ep: 1.36 loss 0.151 score 0.327 lr 3.3713e-06 
05/02/2021 12:02:08 - INFO - volta.train_utils -   [NLVR2]: iter 3700 Ep: 1.37 loss 0.153 score 0.321 lr 3.40833e-06 
05/02/2021 12:02:50 - INFO - volta.train_utils -   [NLVR2]: iter 3740 Ep: 1.39 loss 0.160 score 0.313 lr 3.44537e-06 
05/02/2021 12:03:30 - INFO - volta.train_utils -   [NLVR2]: iter 3780 Ep: 1.40 loss 0.151 score 0.324 lr 3.48241e-06 
05/02/2021 12:04:10 - INFO - volta.train_utils -   [NLVR2]: iter 3820 Ep: 1.41 loss 0.150 score 0.326 lr 3.51944e-06 
05/02/2021 12:04:56 - INFO - volta.train_utils -   [NLVR2]: iter 3860 Ep: 1.43 loss 0.148 score 0.332 lr 3.55648e-06 
05/02/2021 12:05:41 - INFO - volta.train_utils -   [NLVR2]: iter 3900 Ep: 1.44 loss 0.154 score 0.321 lr 3.59352e-06 
05/02/2021 12:06:24 - INFO - volta.train_utils -   [NLVR2]: iter 3940 Ep: 1.46 loss 0.145 score 0.338 lr 3.63056e-06 
05/02/2021 12:07:09 - INFO - volta.train_utils -   [NLVR2]: iter 3980 Ep: 1.47 loss 0.150 score 0.333 lr 3.66759e-06 
05/02/2021 12:07:53 - INFO - volta.train_utils -   [NLVR2]: iter 4020 Ep: 1.49 loss 0.157 score 0.316 lr 3.70463e-06 
05/02/2021 12:08:34 - INFO - volta.train_utils -   [NLVR2]: iter 4060 Ep: 1.50 loss 0.147 score 0.326 lr 3.74167e-06 
05/02/2021 12:09:22 - INFO - volta.train_utils -   [NLVR2]: iter 4100 Ep: 1.52 loss 0.148 score 0.332 lr 3.7787e-06 
05/02/2021 12:10:02 - INFO - volta.train_utils -   [NLVR2]: iter 4140 Ep: 1.53 loss 0.154 score 0.329 lr 3.81574e-06 
05/02/2021 12:10:49 - INFO - volta.train_utils -   [NLVR2]: iter 4180 Ep: 1.55 loss 0.151 score 0.328 lr 3.85278e-06 
05/02/2021 12:11:32 - INFO - volta.train_utils -   [NLVR2]: iter 4220 Ep: 1.56 loss 0.146 score 0.336 lr 3.88981e-06 
05/02/2021 12:12:17 - INFO - volta.train_utils -   [NLVR2]: iter 4260 Ep: 1.58 loss 0.150 score 0.323 lr 3.92685e-06 
05/02/2021 12:13:01 - INFO - volta.train_utils -   [NLVR2]: iter 4300 Ep: 1.59 loss 0.149 score 0.320 lr 3.96389e-06 
05/02/2021 12:13:47 - INFO - volta.train_utils -   [NLVR2]: iter 4340 Ep: 1.61 loss 0.153 score 0.330 lr 4.00093e-06 
05/02/2021 12:14:27 - INFO - volta.train_utils -   [NLVR2]: iter 4380 Ep: 1.62 loss 0.148 score 0.322 lr 4.03796e-06 
05/02/2021 12:15:15 - INFO - volta.train_utils -   [NLVR2]: iter 4420 Ep: 1.64 loss 0.145 score 0.343 lr 4.075e-06 
05/02/2021 12:15:59 - INFO - volta.train_utils -   [NLVR2]: iter 4460 Ep: 1.65 loss 0.146 score 0.327 lr 4.11204e-06 
05/02/2021 12:16:50 - INFO - volta.train_utils -   [NLVR2]: iter 4500 Ep: 1.67 loss 0.152 score 0.332 lr 4.14907e-06 
05/02/2021 12:17:34 - INFO - volta.train_utils -   [NLVR2]: iter 4540 Ep: 1.68 loss 0.155 score 0.320 lr 4.18611e-06 
05/02/2021 12:18:30 - INFO - volta.train_utils -   [NLVR2]: iter 4580 Ep: 1.70 loss 0.145 score 0.338 lr 4.22315e-06 
05/02/2021 12:19:13 - INFO - volta.train_utils -   [NLVR2]: iter 4620 Ep: 1.71 loss 0.150 score 0.332 lr 4.26019e-06 
05/02/2021 12:20:05 - INFO - volta.train_utils -   [NLVR2]: iter 4660 Ep: 1.73 loss 0.154 score 0.318 lr 4.29722e-06 
05/02/2021 12:20:47 - INFO - volta.train_utils -   [NLVR2]: iter 4700 Ep: 1.74 loss 0.147 score 0.341 lr 4.33426e-06 
05/02/2021 12:21:41 - INFO - volta.train_utils -   [NLVR2]: iter 4740 Ep: 1.76 loss 0.148 score 0.336 lr 4.3713e-06 
05/02/2021 12:22:23 - INFO - volta.train_utils -   [NLVR2]: iter 4780 Ep: 1.77 loss 0.144 score 0.335 lr 4.40833e-06 
05/02/2021 12:23:15 - INFO - volta.train_utils -   [NLVR2]: iter 4820 Ep: 1.79 loss 0.148 score 0.328 lr 4.44537e-06 
05/02/2021 12:23:54 - INFO - volta.train_utils -   [NLVR2]: iter 4860 Ep: 1.80 loss 0.143 score 0.337 lr 4.48241e-06 
05/02/2021 12:24:46 - INFO - volta.train_utils -   [NLVR2]: iter 4900 Ep: 1.81 loss 0.145 score 0.338 lr 4.51944e-06 
05/02/2021 12:25:28 - INFO - volta.train_utils -   [NLVR2]: iter 4940 Ep: 1.83 loss 0.153 score 0.334 lr 4.55648e-06 
05/02/2021 12:26:20 - INFO - volta.train_utils -   [NLVR2]: iter 4980 Ep: 1.84 loss 0.152 score 0.330 lr 4.59352e-06 
05/02/2021 12:27:07 - INFO - volta.train_utils -   [NLVR2]: iter 5020 Ep: 1.86 loss 0.151 score 0.326 lr 4.63056e-06 
05/02/2021 12:28:00 - INFO - volta.train_utils -   [NLVR2]: iter 5060 Ep: 1.87 loss 0.147 score 0.338 lr 4.66759e-06 
05/02/2021 12:28:55 - INFO - volta.train_utils -   [NLVR2]: iter 5100 Ep: 1.89 loss 0.146 score 0.352 lr 4.70463e-06 
05/02/2021 12:29:43 - INFO - volta.train_utils -   [NLVR2]: iter 5140 Ep: 1.90 loss 0.152 score 0.326 lr 4.74167e-06 
05/02/2021 12:30:32 - INFO - volta.train_utils -   [NLVR2]: iter 5180 Ep: 1.92 loss 0.150 score 0.330 lr 4.7787e-06 
05/02/2021 12:31:17 - INFO - volta.train_utils -   [NLVR2]: iter 5220 Ep: 1.93 loss 0.142 score 0.341 lr 4.81574e-06 
05/02/2021 12:32:06 - INFO - volta.train_utils -   [NLVR2]: iter 5260 Ep: 1.95 loss 0.153 score 0.334 lr 4.85278e-06 
05/02/2021 12:32:53 - INFO - volta.train_utils -   [NLVR2]: iter 5300 Ep: 1.96 loss 0.152 score 0.321 lr 4.88981e-06 
05/02/2021 12:33:40 - INFO - volta.train_utils -   [NLVR2]: iter 5340 Ep: 1.98 loss 0.146 score 0.346 lr 4.92685e-06 
05/02/2021 12:34:28 - INFO - volta.train_utils -   [NLVR2]: iter 5380 Ep: 1.99 loss 0.157 score 0.317 lr 4.96389e-06 
05/02/2021 12:34:41 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  10%|         | 2/20 [2:04:40<18:04:31, 3615.08s/it]05/02/2021 12:51:13 - INFO - volta.train_utils -   Eval task TASK12 on iteration 5400 
05/02/2021 12:51:13 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.582 score 68.419 
05/02/2021 12:51:13 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/02/2021 12:51:51 - INFO - volta.train_utils -   [NLVR2]: iter 5440 Ep: 2.01 loss 0.146 score 0.337 lr 4.99578e-06 
05/02/2021 12:52:38 - INFO - volta.train_utils -   [NLVR2]: iter 5480 Ep: 2.03 loss 0.136 score 0.349 lr 4.99372e-06 
05/02/2021 12:53:36 - INFO - volta.train_utils -   [NLVR2]: iter 5520 Ep: 2.04 loss 0.134 score 0.362 lr 4.98961e-06 
05/02/2021 12:54:25 - INFO - volta.train_utils -   [NLVR2]: iter 5560 Ep: 2.06 loss 0.139 score 0.361 lr 4.98549e-06 
05/02/2021 12:55:24 - INFO - volta.train_utils -   [NLVR2]: iter 5600 Ep: 2.07 loss 0.137 score 0.346 lr 4.98138e-06 
05/02/2021 12:56:13 - INFO - volta.train_utils -   [NLVR2]: iter 5640 Ep: 2.09 loss 0.134 score 0.348 lr 4.97726e-06 
05/02/2021 12:57:11 - INFO - volta.train_utils -   [NLVR2]: iter 5680 Ep: 2.10 loss 0.135 score 0.358 lr 4.97315e-06 
05/02/2021 12:57:56 - INFO - volta.train_utils -   [NLVR2]: iter 5720 Ep: 2.12 loss 0.140 score 0.354 lr 4.96903e-06 
05/02/2021 12:58:54 - INFO - volta.train_utils -   [NLVR2]: iter 5760 Ep: 2.13 loss 0.136 score 0.349 lr 4.96492e-06 
05/02/2021 12:59:37 - INFO - volta.train_utils -   [NLVR2]: iter 5800 Ep: 2.15 loss 0.144 score 0.348 lr 4.9608e-06 
05/02/2021 13:00:32 - INFO - volta.train_utils -   [NLVR2]: iter 5840 Ep: 2.16 loss 0.141 score 0.344 lr 4.95669e-06 
05/02/2021 13:01:15 - INFO - volta.train_utils -   [NLVR2]: iter 5880 Ep: 2.18 loss 0.136 score 0.355 lr 4.95257e-06 
05/02/2021 13:02:06 - INFO - volta.train_utils -   [NLVR2]: iter 5920 Ep: 2.19 loss 0.139 score 0.346 lr 4.94846e-06 
05/02/2021 13:02:45 - INFO - volta.train_utils -   [NLVR2]: iter 5960 Ep: 2.21 loss 0.131 score 0.350 lr 4.94434e-06 
05/02/2021 13:03:35 - INFO - volta.train_utils -   [NLVR2]: iter 6000 Ep: 2.22 loss 0.130 score 0.355 lr 4.94023e-06 
05/02/2021 13:04:13 - INFO - volta.train_utils -   [NLVR2]: iter 6040 Ep: 2.24 loss 0.122 score 0.364 lr 4.93611e-06 
05/02/2021 13:05:00 - INFO - volta.train_utils -   [NLVR2]: iter 6080 Ep: 2.25 loss 0.146 score 0.335 lr 4.932e-06 
05/02/2021 13:05:42 - INFO - volta.train_utils -   [NLVR2]: iter 6120 Ep: 2.27 loss 0.134 score 0.351 lr 4.92788e-06 
05/02/2021 13:06:27 - INFO - volta.train_utils -   [NLVR2]: iter 6160 Ep: 2.28 loss 0.149 score 0.340 lr 4.92377e-06 
05/02/2021 13:07:04 - INFO - volta.train_utils -   [NLVR2]: iter 6200 Ep: 2.30 loss 0.139 score 0.354 lr 4.91965e-06 
05/02/2021 13:07:56 - INFO - volta.train_utils -   [NLVR2]: iter 6240 Ep: 2.31 loss 0.137 score 0.359 lr 4.91553e-06 
05/02/2021 13:08:41 - INFO - volta.train_utils -   [NLVR2]: iter 6280 Ep: 2.33 loss 0.142 score 0.342 lr 4.91142e-06 
05/02/2021 13:09:30 - INFO - volta.train_utils -   [NLVR2]: iter 6320 Ep: 2.34 loss 0.138 score 0.348 lr 4.9073e-06 
05/02/2021 13:10:11 - INFO - volta.train_utils -   [NLVR2]: iter 6360 Ep: 2.36 loss 0.139 score 0.354 lr 4.90319e-06 
05/02/2021 13:11:01 - INFO - volta.train_utils -   [NLVR2]: iter 6400 Ep: 2.37 loss 0.139 score 0.345 lr 4.89907e-06 
05/02/2021 13:11:41 - INFO - volta.train_utils -   [NLVR2]: iter 6440 Ep: 2.39 loss 0.140 score 0.350 lr 4.89496e-06 
05/02/2021 13:12:30 - INFO - volta.train_utils -   [NLVR2]: iter 6480 Ep: 2.40 loss 0.142 score 0.352 lr 4.89084e-06 
05/02/2021 13:13:09 - INFO - volta.train_utils -   [NLVR2]: iter 6520 Ep: 2.41 loss 0.143 score 0.349 lr 4.88673e-06 
05/02/2021 13:13:57 - INFO - volta.train_utils -   [NLVR2]: iter 6560 Ep: 2.43 loss 0.136 score 0.357 lr 4.88261e-06 
05/02/2021 13:14:38 - INFO - volta.train_utils -   [NLVR2]: iter 6600 Ep: 2.44 loss 0.142 score 0.354 lr 4.8785e-06 
05/02/2021 13:15:25 - INFO - volta.train_utils -   [NLVR2]: iter 6640 Ep: 2.46 loss 0.140 score 0.350 lr 4.87438e-06 
05/02/2021 13:16:02 - INFO - volta.train_utils -   [NLVR2]: iter 6680 Ep: 2.47 loss 0.141 score 0.352 lr 4.87027e-06 
05/02/2021 13:16:48 - INFO - volta.train_utils -   [NLVR2]: iter 6720 Ep: 2.49 loss 0.135 score 0.356 lr 4.86615e-06 
05/02/2021 13:17:23 - INFO - volta.train_utils -   [NLVR2]: iter 6760 Ep: 2.50 loss 0.135 score 0.357 lr 4.86204e-06 
05/02/2021 13:18:06 - INFO - volta.train_utils -   [NLVR2]: iter 6800 Ep: 2.52 loss 0.136 score 0.341 lr 4.85792e-06 
05/02/2021 13:18:45 - INFO - volta.train_utils -   [NLVR2]: iter 6840 Ep: 2.53 loss 0.145 score 0.330 lr 4.85381e-06 
05/02/2021 13:19:30 - INFO - volta.train_utils -   [NLVR2]: iter 6880 Ep: 2.55 loss 0.136 score 0.354 lr 4.84969e-06 
05/02/2021 13:20:07 - INFO - volta.train_utils -   [NLVR2]: iter 6920 Ep: 2.56 loss 0.135 score 0.352 lr 4.84558e-06 
05/02/2021 13:20:49 - INFO - volta.train_utils -   [NLVR2]: iter 6960 Ep: 2.58 loss 0.134 score 0.352 lr 4.84146e-06 
05/02/2021 13:21:31 - INFO - volta.train_utils -   [NLVR2]: iter 7000 Ep: 2.59 loss 0.137 score 0.357 lr 4.83735e-06 
05/02/2021 13:22:14 - INFO - volta.train_utils -   [NLVR2]: iter 7040 Ep: 2.61 loss 0.139 score 0.350 lr 4.83323e-06 
05/02/2021 13:22:58 - INFO - volta.train_utils -   [NLVR2]: iter 7080 Ep: 2.62 loss 0.137 score 0.352 lr 4.82912e-06 
05/02/2021 13:23:41 - INFO - volta.train_utils -   [NLVR2]: iter 7120 Ep: 2.64 loss 0.149 score 0.343 lr 4.825e-06 
05/02/2021 13:24:19 - INFO - volta.train_utils -   [NLVR2]: iter 7160 Ep: 2.65 loss 0.134 score 0.352 lr 4.82088e-06 
05/02/2021 13:25:03 - INFO - volta.train_utils -   [NLVR2]: iter 7200 Ep: 2.67 loss 0.129 score 0.363 lr 4.81677e-06 
05/02/2021 13:25:48 - INFO - volta.train_utils -   [NLVR2]: iter 7240 Ep: 2.68 loss 0.138 score 0.353 lr 4.81265e-06 
05/02/2021 13:26:38 - INFO - volta.train_utils -   [NLVR2]: iter 7280 Ep: 2.70 loss 0.140 score 0.339 lr 4.80854e-06 
05/02/2021 13:27:17 - INFO - volta.train_utils -   [NLVR2]: iter 7320 Ep: 2.71 loss 0.130 score 0.367 lr 4.80442e-06 
05/02/2021 13:28:01 - INFO - volta.train_utils -   [NLVR2]: iter 7360 Ep: 2.73 loss 0.133 score 0.359 lr 4.80031e-06 
05/02/2021 13:28:40 - INFO - volta.train_utils -   [NLVR2]: iter 7400 Ep: 2.74 loss 0.134 score 0.357 lr 4.79619e-06 
05/02/2021 13:29:26 - INFO - volta.train_utils -   [NLVR2]: iter 7440 Ep: 2.76 loss 0.141 score 0.355 lr 4.79208e-06 
05/02/2021 13:30:00 - INFO - volta.train_utils -   [NLVR2]: iter 7480 Ep: 2.77 loss 0.129 score 0.360 lr 4.78796e-06 
05/02/2021 13:30:40 - INFO - volta.train_utils -   [NLVR2]: iter 7520 Ep: 2.79 loss 0.130 score 0.361 lr 4.78385e-06 
05/02/2021 13:31:13 - INFO - volta.train_utils -   [NLVR2]: iter 7560 Ep: 2.80 loss 0.130 score 0.359 lr 4.77973e-06 
05/02/2021 13:31:56 - INFO - volta.train_utils -   [NLVR2]: iter 7600 Ep: 2.81 loss 0.139 score 0.362 lr 4.77562e-06 
05/02/2021 13:32:34 - INFO - volta.train_utils -   [NLVR2]: iter 7640 Ep: 2.83 loss 0.131 score 0.357 lr 4.7715e-06 
05/02/2021 13:33:19 - INFO - volta.train_utils -   [NLVR2]: iter 7680 Ep: 2.84 loss 0.140 score 0.353 lr 4.76739e-06 
05/02/2021 13:33:57 - INFO - volta.train_utils -   [NLVR2]: iter 7720 Ep: 2.86 loss 0.140 score 0.361 lr 4.76327e-06 
05/02/2021 13:34:46 - INFO - volta.train_utils -   [NLVR2]: iter 7760 Ep: 2.87 loss 0.131 score 0.359 lr 4.75916e-06 
05/02/2021 13:35:25 - INFO - volta.train_utils -   [NLVR2]: iter 7800 Ep: 2.89 loss 0.130 score 0.354 lr 4.75504e-06 
05/02/2021 13:36:12 - INFO - volta.train_utils -   [NLVR2]: iter 7840 Ep: 2.90 loss 0.130 score 0.362 lr 4.75093e-06 
05/02/2021 13:36:52 - INFO - volta.train_utils -   [NLVR2]: iter 7880 Ep: 2.92 loss 0.141 score 0.350 lr 4.74681e-06 
05/02/2021 13:37:40 - INFO - volta.train_utils -   [NLVR2]: iter 7920 Ep: 2.93 loss 0.135 score 0.352 lr 4.7427e-06 
05/02/2021 13:38:19 - INFO - volta.train_utils -   [NLVR2]: iter 7960 Ep: 2.95 loss 0.133 score 0.358 lr 4.73858e-06 
05/02/2021 13:39:03 - INFO - volta.train_utils -   [NLVR2]: iter 8000 Ep: 2.96 loss 0.129 score 0.361 lr 4.73447e-06 
05/02/2021 13:39:41 - INFO - volta.train_utils -   [NLVR2]: iter 8040 Ep: 2.98 loss 0.126 score 0.362 lr 4.73035e-06 
05/02/2021 13:40:30 - INFO - volta.train_utils -   [NLVR2]: iter 8080 Ep: 2.99 loss 0.132 score 0.365 lr 4.72623e-06 
05/02/2021 13:40:42 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  15%|        | 3/20 [3:10:41<17:33:40, 3718.87s/it]05/02/2021 13:56:55 - INFO - volta.train_utils -   Eval task TASK12 on iteration 8100 
05/02/2021 13:56:55 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.558 score 70.653 
05/02/2021 13:56:55 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/02/2021 13:57:31 - INFO - volta.train_utils -   [NLVR2]: iter 8140 Ep: 3.01 loss 0.124 score 0.372 lr 4.72109e-06 
05/02/2021 13:58:08 - INFO - volta.train_utils -   [NLVR2]: iter 8180 Ep: 3.03 loss 0.130 score 0.370 lr 4.71595e-06 
05/02/2021 13:58:54 - INFO - volta.train_utils -   [NLVR2]: iter 8220 Ep: 3.04 loss 0.109 score 0.387 lr 4.71183e-06 
05/02/2021 13:59:30 - INFO - volta.train_utils -   [NLVR2]: iter 8260 Ep: 3.06 loss 0.110 score 0.379 lr 4.70772e-06 
05/02/2021 14:00:23 - INFO - volta.train_utils -   [NLVR2]: iter 8300 Ep: 3.07 loss 0.115 score 0.373 lr 4.7036e-06 
05/02/2021 14:01:04 - INFO - volta.train_utils -   [NLVR2]: iter 8340 Ep: 3.09 loss 0.114 score 0.378 lr 4.69949e-06 
05/02/2021 14:01:54 - INFO - volta.train_utils -   [NLVR2]: iter 8380 Ep: 3.10 loss 0.117 score 0.376 lr 4.69537e-06 
05/02/2021 14:02:35 - INFO - volta.train_utils -   [NLVR2]: iter 8420 Ep: 3.12 loss 0.118 score 0.371 lr 4.69126e-06 
05/02/2021 14:03:27 - INFO - volta.train_utils -   [NLVR2]: iter 8460 Ep: 3.13 loss 0.119 score 0.386 lr 4.68714e-06 
05/02/2021 14:04:11 - INFO - volta.train_utils -   [NLVR2]: iter 8500 Ep: 3.15 loss 0.118 score 0.381 lr 4.68302e-06 
05/02/2021 14:04:58 - INFO - volta.train_utils -   [NLVR2]: iter 8540 Ep: 3.16 loss 0.123 score 0.368 lr 4.67891e-06 
05/02/2021 14:05:36 - INFO - volta.train_utils -   [NLVR2]: iter 8580 Ep: 3.18 loss 0.119 score 0.379 lr 4.67479e-06 
05/02/2021 14:06:26 - INFO - volta.train_utils -   [NLVR2]: iter 8620 Ep: 3.19 loss 0.117 score 0.376 lr 4.67068e-06 
05/02/2021 14:07:03 - INFO - volta.train_utils -   [NLVR2]: iter 8660 Ep: 3.21 loss 0.120 score 0.377 lr 4.66656e-06 
05/02/2021 14:07:49 - INFO - volta.train_utils -   [NLVR2]: iter 8700 Ep: 3.22 loss 0.117 score 0.377 lr 4.66245e-06 
05/02/2021 14:08:25 - INFO - volta.train_utils -   [NLVR2]: iter 8740 Ep: 3.24 loss 0.125 score 0.378 lr 4.65833e-06 
05/02/2021 14:09:13 - INFO - volta.train_utils -   [NLVR2]: iter 8780 Ep: 3.25 loss 0.123 score 0.380 lr 4.65422e-06 
05/02/2021 14:09:50 - INFO - volta.train_utils -   [NLVR2]: iter 8820 Ep: 3.27 loss 0.119 score 0.375 lr 4.6501e-06 
05/02/2021 14:10:32 - INFO - volta.train_utils -   [NLVR2]: iter 8860 Ep: 3.28 loss 0.116 score 0.381 lr 4.64599e-06 
05/02/2021 14:11:10 - INFO - volta.train_utils -   [NLVR2]: iter 8900 Ep: 3.30 loss 0.123 score 0.378 lr 4.64187e-06 
05/02/2021 14:11:54 - INFO - volta.train_utils -   [NLVR2]: iter 8940 Ep: 3.31 loss 0.125 score 0.365 lr 4.63776e-06 
05/02/2021 14:12:34 - INFO - volta.train_utils -   [NLVR2]: iter 8980 Ep: 3.33 loss 0.123 score 0.368 lr 4.63364e-06 
05/02/2021 14:13:23 - INFO - volta.train_utils -   [NLVR2]: iter 9020 Ep: 3.34 loss 0.112 score 0.386 lr 4.62953e-06 
05/02/2021 14:14:01 - INFO - volta.train_utils -   [NLVR2]: iter 9060 Ep: 3.36 loss 0.121 score 0.377 lr 4.62541e-06 
05/02/2021 14:14:46 - INFO - volta.train_utils -   [NLVR2]: iter 9100 Ep: 3.37 loss 0.126 score 0.366 lr 4.6213e-06 
05/02/2021 14:15:25 - INFO - volta.train_utils -   [NLVR2]: iter 9140 Ep: 3.39 loss 0.115 score 0.386 lr 4.61718e-06 
05/02/2021 14:16:10 - INFO - volta.train_utils -   [NLVR2]: iter 9180 Ep: 3.40 loss 0.115 score 0.374 lr 4.61307e-06 
05/02/2021 14:16:44 - INFO - volta.train_utils -   [NLVR2]: iter 9220 Ep: 3.41 loss 0.120 score 0.379 lr 4.60895e-06 
05/02/2021 14:17:27 - INFO - volta.train_utils -   [NLVR2]: iter 9260 Ep: 3.43 loss 0.118 score 0.373 lr 4.60484e-06 
05/02/2021 14:18:02 - INFO - volta.train_utils -   [NLVR2]: iter 9300 Ep: 3.44 loss 0.122 score 0.384 lr 4.60072e-06 
05/02/2021 14:18:40 - INFO - volta.train_utils -   [NLVR2]: iter 9340 Ep: 3.46 loss 0.116 score 0.381 lr 4.5966e-06 
05/02/2021 14:19:13 - INFO - volta.train_utils -   [NLVR2]: iter 9380 Ep: 3.47 loss 0.114 score 0.389 lr 4.59249e-06 
05/02/2021 14:19:53 - INFO - volta.train_utils -   [NLVR2]: iter 9420 Ep: 3.49 loss 0.124 score 0.364 lr 4.58837e-06 
05/02/2021 14:20:27 - INFO - volta.train_utils -   [NLVR2]: iter 9460 Ep: 3.50 loss 0.111 score 0.393 lr 4.58426e-06 
05/02/2021 14:21:03 - INFO - volta.train_utils -   [NLVR2]: iter 9500 Ep: 3.52 loss 0.122 score 0.382 lr 4.58014e-06 
05/02/2021 14:21:44 - INFO - volta.train_utils -   [NLVR2]: iter 9540 Ep: 3.53 loss 0.125 score 0.369 lr 4.57603e-06 
05/02/2021 14:22:19 - INFO - volta.train_utils -   [NLVR2]: iter 9580 Ep: 3.55 loss 0.120 score 0.389 lr 4.57191e-06 
05/02/2021 14:22:53 - INFO - volta.train_utils -   [NLVR2]: iter 9620 Ep: 3.56 loss 0.116 score 0.387 lr 4.5678e-06 
05/02/2021 14:23:29 - INFO - volta.train_utils -   [NLVR2]: iter 9660 Ep: 3.58 loss 0.115 score 0.384 lr 4.56368e-06 
05/02/2021 14:24:05 - INFO - volta.train_utils -   [NLVR2]: iter 9700 Ep: 3.59 loss 0.110 score 0.393 lr 4.55957e-06 
05/02/2021 14:24:38 - INFO - volta.train_utils -   [NLVR2]: iter 9740 Ep: 3.61 loss 0.127 score 0.366 lr 4.55545e-06 
05/02/2021 14:25:17 - INFO - volta.train_utils -   [NLVR2]: iter 9780 Ep: 3.62 loss 0.122 score 0.373 lr 4.55134e-06 
05/02/2021 14:25:50 - INFO - volta.train_utils -   [NLVR2]: iter 9820 Ep: 3.64 loss 0.122 score 0.384 lr 4.54722e-06 
05/02/2021 14:26:27 - INFO - volta.train_utils -   [NLVR2]: iter 9860 Ep: 3.65 loss 0.114 score 0.388 lr 4.54311e-06 
05/02/2021 14:27:03 - INFO - volta.train_utils -   [NLVR2]: iter 9900 Ep: 3.67 loss 0.126 score 0.371 lr 4.53899e-06 
05/02/2021 14:27:36 - INFO - volta.train_utils -   [NLVR2]: iter 9940 Ep: 3.68 loss 0.114 score 0.384 lr 4.53488e-06 
05/02/2021 14:28:14 - INFO - volta.train_utils -   [NLVR2]: iter 9980 Ep: 3.70 loss 0.121 score 0.370 lr 4.53076e-06 
05/02/2021 14:28:47 - INFO - volta.train_utils -   [NLVR2]: iter 10020 Ep: 3.71 loss 0.116 score 0.382 lr 4.52665e-06 
05/02/2021 14:29:24 - INFO - volta.train_utils -   [NLVR2]: iter 10060 Ep: 3.73 loss 0.118 score 0.382 lr 4.52253e-06 
05/02/2021 14:29:59 - INFO - volta.train_utils -   [NLVR2]: iter 10100 Ep: 3.74 loss 0.118 score 0.379 lr 4.51842e-06 
05/02/2021 14:30:34 - INFO - volta.train_utils -   [NLVR2]: iter 10140 Ep: 3.76 loss 0.119 score 0.382 lr 4.5143e-06 
05/02/2021 14:31:09 - INFO - volta.train_utils -   [NLVR2]: iter 10180 Ep: 3.77 loss 0.113 score 0.381 lr 4.51019e-06 
05/02/2021 14:31:48 - INFO - volta.train_utils -   [NLVR2]: iter 10220 Ep: 3.79 loss 0.121 score 0.369 lr 4.50607e-06 
05/02/2021 14:32:24 - INFO - volta.train_utils -   [NLVR2]: iter 10260 Ep: 3.80 loss 0.113 score 0.382 lr 4.50195e-06 
05/02/2021 14:33:00 - INFO - volta.train_utils -   [NLVR2]: iter 10300 Ep: 3.81 loss 0.121 score 0.380 lr 4.49784e-06 
05/02/2021 14:33:34 - INFO - volta.train_utils -   [NLVR2]: iter 10340 Ep: 3.83 loss 0.116 score 0.379 lr 4.49372e-06 
05/02/2021 14:34:14 - INFO - volta.train_utils -   [NLVR2]: iter 10380 Ep: 3.84 loss 0.114 score 0.384 lr 4.48961e-06 
05/02/2021 14:34:50 - INFO - volta.train_utils -   [NLVR2]: iter 10420 Ep: 3.86 loss 0.126 score 0.379 lr 4.48549e-06 
05/02/2021 14:35:30 - INFO - volta.train_utils -   [NLVR2]: iter 10460 Ep: 3.87 loss 0.119 score 0.379 lr 4.48138e-06 
05/02/2021 14:36:09 - INFO - volta.train_utils -   [NLVR2]: iter 10500 Ep: 3.89 loss 0.114 score 0.381 lr 4.47726e-06 
05/02/2021 14:36:49 - INFO - volta.train_utils -   [NLVR2]: iter 10540 Ep: 3.90 loss 0.122 score 0.376 lr 4.47315e-06 
05/02/2021 14:37:28 - INFO - volta.train_utils -   [NLVR2]: iter 10580 Ep: 3.92 loss 0.120 score 0.385 lr 4.46903e-06 
05/02/2021 14:38:07 - INFO - volta.train_utils -   [NLVR2]: iter 10620 Ep: 3.93 loss 0.116 score 0.381 lr 4.46492e-06 
05/02/2021 14:38:45 - INFO - volta.train_utils -   [NLVR2]: iter 10660 Ep: 3.95 loss 0.120 score 0.379 lr 4.4608e-06 
05/02/2021 14:39:27 - INFO - volta.train_utils -   [NLVR2]: iter 10700 Ep: 3.96 loss 0.120 score 0.376 lr 4.45669e-06 
05/02/2021 14:40:03 - INFO - volta.train_utils -   [NLVR2]: iter 10740 Ep: 3.98 loss 0.116 score 0.379 lr 4.45257e-06 
05/02/2021 14:40:46 - INFO - volta.train_utils -   [NLVR2]: iter 10780 Ep: 3.99 loss 0.121 score 0.378 lr 4.44846e-06 
05/02/2021 14:40:57 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  20%|        | 4/20 [4:10:59<16:23:36, 3688.50s/it]05/02/2021 14:55:56 - INFO - volta.train_utils -   Eval task TASK12 on iteration 10800 
05/02/2021 14:55:56 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.564 score 73.074 
05/02/2021 14:55:56 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/02/2021 14:56:29 - INFO - volta.train_utils -   [NLVR2]: iter 10840 Ep: 4.01 loss 0.111 score 0.396 lr 4.44331e-06 
05/02/2021 14:57:05 - INFO - volta.train_utils -   [NLVR2]: iter 10880 Ep: 4.03 loss 0.103 score 0.398 lr 4.43817e-06 
05/02/2021 14:57:45 - INFO - volta.train_utils -   [NLVR2]: iter 10920 Ep: 4.04 loss 0.098 score 0.400 lr 4.43405e-06 
05/02/2021 14:58:23 - INFO - volta.train_utils -   [NLVR2]: iter 10960 Ep: 4.06 loss 0.102 score 0.385 lr 4.42994e-06 
05/02/2021 14:59:03 - INFO - volta.train_utils -   [NLVR2]: iter 11000 Ep: 4.07 loss 0.106 score 0.399 lr 4.42582e-06 
05/02/2021 14:59:41 - INFO - volta.train_utils -   [NLVR2]: iter 11040 Ep: 4.09 loss 0.097 score 0.400 lr 4.42171e-06 
05/02/2021 15:00:24 - INFO - volta.train_utils -   [NLVR2]: iter 11080 Ep: 4.10 loss 0.115 score 0.387 lr 4.41759e-06 
05/02/2021 15:01:02 - INFO - volta.train_utils -   [NLVR2]: iter 11120 Ep: 4.12 loss 0.109 score 0.388 lr 4.41348e-06 
05/02/2021 15:01:47 - INFO - volta.train_utils -   [NLVR2]: iter 11160 Ep: 4.13 loss 0.103 score 0.398 lr 4.40936e-06 
05/02/2021 15:02:25 - INFO - volta.train_utils -   [NLVR2]: iter 11200 Ep: 4.15 loss 0.099 score 0.403 lr 4.40525e-06 
05/02/2021 15:03:14 - INFO - volta.train_utils -   [NLVR2]: iter 11240 Ep: 4.16 loss 0.112 score 0.395 lr 4.40113e-06 
05/02/2021 15:03:55 - INFO - volta.train_utils -   [NLVR2]: iter 11280 Ep: 4.18 loss 0.102 score 0.410 lr 4.39702e-06 
05/02/2021 15:04:52 - INFO - volta.train_utils -   [NLVR2]: iter 11320 Ep: 4.19 loss 0.096 score 0.413 lr 4.3929e-06 
05/02/2021 15:05:37 - INFO - volta.train_utils -   [NLVR2]: iter 11360 Ep: 4.21 loss 0.099 score 0.397 lr 4.38879e-06 
05/02/2021 15:06:32 - INFO - volta.train_utils -   [NLVR2]: iter 11400 Ep: 4.22 loss 0.100 score 0.403 lr 4.38467e-06 
05/02/2021 15:07:17 - INFO - volta.train_utils -   [NLVR2]: iter 11440 Ep: 4.24 loss 0.111 score 0.390 lr 4.38056e-06 
05/02/2021 15:08:15 - INFO - volta.train_utils -   [NLVR2]: iter 11480 Ep: 4.25 loss 0.104 score 0.392 lr 4.37644e-06 
05/02/2021 15:08:55 - INFO - volta.train_utils -   [NLVR2]: iter 11520 Ep: 4.27 loss 0.104 score 0.400 lr 4.37233e-06 
05/02/2021 15:09:42 - INFO - volta.train_utils -   [NLVR2]: iter 11560 Ep: 4.28 loss 0.101 score 0.390 lr 4.36821e-06 
05/02/2021 15:10:22 - INFO - volta.train_utils -   [NLVR2]: iter 11600 Ep: 4.30 loss 0.101 score 0.403 lr 4.36409e-06 
05/02/2021 15:11:12 - INFO - volta.train_utils -   [NLVR2]: iter 11640 Ep: 4.31 loss 0.096 score 0.400 lr 4.35998e-06 
05/02/2021 15:11:55 - INFO - volta.train_utils -   [NLVR2]: iter 11680 Ep: 4.33 loss 0.105 score 0.393 lr 4.35586e-06 
05/02/2021 15:12:40 - INFO - volta.train_utils -   [NLVR2]: iter 11720 Ep: 4.34 loss 0.108 score 0.393 lr 4.35175e-06 
05/02/2021 15:13:20 - INFO - volta.train_utils -   [NLVR2]: iter 11760 Ep: 4.36 loss 0.105 score 0.398 lr 4.34763e-06 
05/02/2021 15:14:14 - INFO - volta.train_utils -   [NLVR2]: iter 11800 Ep: 4.37 loss 0.110 score 0.382 lr 4.34352e-06 
05/02/2021 15:14:57 - INFO - volta.train_utils -   [NLVR2]: iter 11840 Ep: 4.39 loss 0.104 score 0.406 lr 4.3394e-06 
05/02/2021 15:15:49 - INFO - volta.train_utils -   [NLVR2]: iter 11880 Ep: 4.40 loss 0.114 score 0.389 lr 4.33529e-06 
05/02/2021 15:16:30 - INFO - volta.train_utils -   [NLVR2]: iter 11920 Ep: 4.41 loss 0.108 score 0.399 lr 4.33117e-06 
05/02/2021 15:17:21 - INFO - volta.train_utils -   [NLVR2]: iter 11960 Ep: 4.43 loss 0.102 score 0.400 lr 4.32706e-06 
05/02/2021 15:18:04 - INFO - volta.train_utils -   [NLVR2]: iter 12000 Ep: 4.44 loss 0.109 score 0.394 lr 4.32294e-06 
05/02/2021 15:18:52 - INFO - volta.train_utils -   [NLVR2]: iter 12040 Ep: 4.46 loss 0.110 score 0.390 lr 4.31883e-06 
05/02/2021 15:19:30 - INFO - volta.train_utils -   [NLVR2]: iter 12080 Ep: 4.47 loss 0.104 score 0.397 lr 4.31471e-06 
05/02/2021 15:20:20 - INFO - volta.train_utils -   [NLVR2]: iter 12120 Ep: 4.49 loss 0.112 score 0.393 lr 4.3106e-06 
05/02/2021 15:20:55 - INFO - volta.train_utils -   [NLVR2]: iter 12160 Ep: 4.50 loss 0.117 score 0.391 lr 4.30648e-06 
05/02/2021 15:21:42 - INFO - volta.train_utils -   [NLVR2]: iter 12200 Ep: 4.52 loss 0.106 score 0.400 lr 4.30237e-06 
05/02/2021 15:22:24 - INFO - volta.train_utils -   [NLVR2]: iter 12240 Ep: 4.53 loss 0.108 score 0.392 lr 4.29825e-06 
05/02/2021 15:23:12 - INFO - volta.train_utils -   [NLVR2]: iter 12280 Ep: 4.55 loss 0.102 score 0.389 lr 4.29414e-06 
05/02/2021 15:23:54 - INFO - volta.train_utils -   [NLVR2]: iter 12320 Ep: 4.56 loss 0.102 score 0.398 lr 4.29002e-06 
05/02/2021 15:24:41 - INFO - volta.train_utils -   [NLVR2]: iter 12360 Ep: 4.58 loss 0.101 score 0.402 lr 4.28591e-06 
05/02/2021 15:25:22 - INFO - volta.train_utils -   [NLVR2]: iter 12400 Ep: 4.59 loss 0.102 score 0.395 lr 4.28179e-06 
05/02/2021 15:26:12 - INFO - volta.train_utils -   [NLVR2]: iter 12440 Ep: 4.61 loss 0.111 score 0.390 lr 4.27767e-06 
05/02/2021 15:26:52 - INFO - volta.train_utils -   [NLVR2]: iter 12480 Ep: 4.62 loss 0.108 score 0.391 lr 4.27356e-06 
05/02/2021 15:27:38 - INFO - volta.train_utils -   [NLVR2]: iter 12520 Ep: 4.64 loss 0.113 score 0.380 lr 4.26944e-06 
05/02/2021 15:28:22 - INFO - volta.train_utils -   [NLVR2]: iter 12560 Ep: 4.65 loss 0.114 score 0.390 lr 4.26533e-06 
05/02/2021 15:29:10 - INFO - volta.train_utils -   [NLVR2]: iter 12600 Ep: 4.67 loss 0.102 score 0.396 lr 4.26121e-06 
05/02/2021 15:29:49 - INFO - volta.train_utils -   [NLVR2]: iter 12640 Ep: 4.68 loss 0.116 score 0.384 lr 4.2571e-06 
05/02/2021 15:30:34 - INFO - volta.train_utils -   [NLVR2]: iter 12680 Ep: 4.70 loss 0.109 score 0.391 lr 4.25298e-06 
05/02/2021 15:31:16 - INFO - volta.train_utils -   [NLVR2]: iter 12720 Ep: 4.71 loss 0.106 score 0.406 lr 4.24887e-06 
05/02/2021 15:32:03 - INFO - volta.train_utils -   [NLVR2]: iter 12760 Ep: 4.73 loss 0.112 score 0.401 lr 4.24475e-06 
05/02/2021 15:32:42 - INFO - volta.train_utils -   [NLVR2]: iter 12800 Ep: 4.74 loss 0.103 score 0.394 lr 4.24064e-06 
05/02/2021 15:33:24 - INFO - volta.train_utils -   [NLVR2]: iter 12840 Ep: 4.76 loss 0.113 score 0.393 lr 4.23652e-06 
05/02/2021 15:34:11 - INFO - volta.train_utils -   [NLVR2]: iter 12880 Ep: 4.77 loss 0.107 score 0.401 lr 4.23241e-06 
05/02/2021 15:34:52 - INFO - volta.train_utils -   [NLVR2]: iter 12920 Ep: 4.79 loss 0.114 score 0.388 lr 4.22829e-06 
05/02/2021 15:35:38 - INFO - volta.train_utils -   [NLVR2]: iter 12960 Ep: 4.80 loss 0.098 score 0.389 lr 4.22418e-06 
05/02/2021 15:36:19 - INFO - volta.train_utils -   [NLVR2]: iter 13000 Ep: 4.81 loss 0.106 score 0.399 lr 4.22006e-06 
05/02/2021 15:37:10 - INFO - volta.train_utils -   [NLVR2]: iter 13040 Ep: 4.83 loss 0.105 score 0.395 lr 4.21595e-06 
05/02/2021 15:37:55 - INFO - volta.train_utils -   [NLVR2]: iter 13080 Ep: 4.84 loss 0.102 score 0.400 lr 4.21183e-06 
05/02/2021 15:38:44 - INFO - volta.train_utils -   [NLVR2]: iter 13120 Ep: 4.86 loss 0.101 score 0.397 lr 4.20772e-06 
05/02/2021 15:39:28 - INFO - volta.train_utils -   [NLVR2]: iter 13160 Ep: 4.87 loss 0.102 score 0.397 lr 4.2036e-06 
05/02/2021 15:40:20 - INFO - volta.train_utils -   [NLVR2]: iter 13200 Ep: 4.89 loss 0.117 score 0.388 lr 4.19949e-06 
05/02/2021 15:41:03 - INFO - volta.train_utils -   [NLVR2]: iter 13240 Ep: 4.90 loss 0.111 score 0.388 lr 4.19537e-06 
05/02/2021 15:41:54 - INFO - volta.train_utils -   [NLVR2]: iter 13280 Ep: 4.92 loss 0.103 score 0.399 lr 4.19126e-06 
05/02/2021 15:42:41 - INFO - volta.train_utils -   [NLVR2]: iter 13320 Ep: 4.93 loss 0.106 score 0.395 lr 4.18714e-06 
05/02/2021 15:43:32 - INFO - volta.train_utils -   [NLVR2]: iter 13360 Ep: 4.95 loss 0.113 score 0.387 lr 4.18302e-06 
05/02/2021 15:44:13 - INFO - volta.train_utils -   [NLVR2]: iter 13400 Ep: 4.96 loss 0.097 score 0.403 lr 4.17891e-06 
05/02/2021 15:45:05 - INFO - volta.train_utils -   [NLVR2]: iter 13440 Ep: 4.98 loss 0.098 score 0.393 lr 4.17479e-06 
05/02/2021 15:45:45 - INFO - volta.train_utils -   [NLVR2]: iter 13480 Ep: 4.99 loss 0.107 score 0.395 lr 4.17068e-06 
05/02/2021 15:46:03 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  25%|       | 5/20 [5:16:01<15:38:10, 3752.69s/it]05/02/2021 16:01:20 - INFO - volta.train_utils -   Eval task TASK12 on iteration 13500 
05/02/2021 16:01:20 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.581 score 72.673 
05/02/2021 16:01:40 - INFO - volta.train_utils -   [NLVR2]: iter 13540 Ep: 5.01 loss 0.100 score 0.400 lr 4.16553e-06 
05/02/2021 16:02:17 - INFO - volta.train_utils -   [NLVR2]: iter 13580 Ep: 5.03 loss 0.094 score 0.421 lr 4.16039e-06 
05/02/2021 16:02:57 - INFO - volta.train_utils -   [NLVR2]: iter 13620 Ep: 5.04 loss 0.090 score 0.419 lr 4.15628e-06 
05/02/2021 16:03:35 - INFO - volta.train_utils -   [NLVR2]: iter 13660 Ep: 5.06 loss 0.092 score 0.414 lr 4.15216e-06 
05/02/2021 16:04:20 - INFO - volta.train_utils -   [NLVR2]: iter 13700 Ep: 5.07 loss 0.097 score 0.411 lr 4.14805e-06 
05/02/2021 16:04:59 - INFO - volta.train_utils -   [NLVR2]: iter 13740 Ep: 5.09 loss 0.083 score 0.416 lr 4.14393e-06 
05/02/2021 16:05:43 - INFO - volta.train_utils -   [NLVR2]: iter 13780 Ep: 5.10 loss 0.091 score 0.405 lr 4.13981e-06 
05/02/2021 16:06:27 - INFO - volta.train_utils -   [NLVR2]: iter 13820 Ep: 5.12 loss 0.088 score 0.419 lr 4.1357e-06 
05/02/2021 16:07:10 - INFO - volta.train_utils -   [NLVR2]: iter 13860 Ep: 5.13 loss 0.098 score 0.410 lr 4.13158e-06 
05/02/2021 16:07:55 - INFO - volta.train_utils -   [NLVR2]: iter 13900 Ep: 5.15 loss 0.095 score 0.414 lr 4.12747e-06 
05/02/2021 16:08:40 - INFO - volta.train_utils -   [NLVR2]: iter 13940 Ep: 5.16 loss 0.095 score 0.407 lr 4.12335e-06 
05/02/2021 16:09:32 - INFO - volta.train_utils -   [NLVR2]: iter 13980 Ep: 5.18 loss 0.093 score 0.412 lr 4.11924e-06 
05/02/2021 16:10:15 - INFO - volta.train_utils -   [NLVR2]: iter 14020 Ep: 5.19 loss 0.089 score 0.409 lr 4.11512e-06 
05/02/2021 16:11:03 - INFO - volta.train_utils -   [NLVR2]: iter 14060 Ep: 5.21 loss 0.092 score 0.409 lr 4.11101e-06 
05/02/2021 16:11:43 - INFO - volta.train_utils -   [NLVR2]: iter 14100 Ep: 5.22 loss 0.097 score 0.412 lr 4.10689e-06 
05/02/2021 16:12:32 - INFO - volta.train_utils -   [NLVR2]: iter 14140 Ep: 5.24 loss 0.094 score 0.404 lr 4.10278e-06 
05/02/2021 16:13:12 - INFO - volta.train_utils -   [NLVR2]: iter 14180 Ep: 5.25 loss 0.102 score 0.402 lr 4.09866e-06 
05/02/2021 16:13:59 - INFO - volta.train_utils -   [NLVR2]: iter 14220 Ep: 5.27 loss 0.084 score 0.412 lr 4.09455e-06 
05/02/2021 16:14:40 - INFO - volta.train_utils -   [NLVR2]: iter 14260 Ep: 5.28 loss 0.097 score 0.409 lr 4.09043e-06 
05/02/2021 16:15:27 - INFO - volta.train_utils -   [NLVR2]: iter 14300 Ep: 5.30 loss 0.093 score 0.411 lr 4.08632e-06 
05/02/2021 16:16:04 - INFO - volta.train_utils -   [NLVR2]: iter 14340 Ep: 5.31 loss 0.097 score 0.403 lr 4.0822e-06 
05/02/2021 16:16:50 - INFO - volta.train_utils -   [NLVR2]: iter 14380 Ep: 5.33 loss 0.088 score 0.409 lr 4.07809e-06 
05/02/2021 16:17:39 - INFO - volta.train_utils -   [NLVR2]: iter 14420 Ep: 5.34 loss 0.099 score 0.412 lr 4.07397e-06 
05/02/2021 16:18:21 - INFO - volta.train_utils -   [NLVR2]: iter 14460 Ep: 5.36 loss 0.092 score 0.412 lr 4.06986e-06 
05/02/2021 16:19:09 - INFO - volta.train_utils -   [NLVR2]: iter 14500 Ep: 5.37 loss 0.090 score 0.410 lr 4.06574e-06 
05/02/2021 16:19:49 - INFO - volta.train_utils -   [NLVR2]: iter 14540 Ep: 5.39 loss 0.094 score 0.409 lr 4.06163e-06 
05/02/2021 16:20:38 - INFO - volta.train_utils -   [NLVR2]: iter 14580 Ep: 5.40 loss 0.095 score 0.414 lr 4.05751e-06 
05/02/2021 16:21:16 - INFO - volta.train_utils -   [NLVR2]: iter 14620 Ep: 5.41 loss 0.100 score 0.404 lr 4.0534e-06 
05/02/2021 16:22:11 - INFO - volta.train_utils -   [NLVR2]: iter 14660 Ep: 5.43 loss 0.094 score 0.416 lr 4.04928e-06 
05/02/2021 16:22:50 - INFO - volta.train_utils -   [NLVR2]: iter 14700 Ep: 5.44 loss 0.083 score 0.418 lr 4.04516e-06 
05/02/2021 16:23:36 - INFO - volta.train_utils -   [NLVR2]: iter 14740 Ep: 5.46 loss 0.096 score 0.406 lr 4.04105e-06 
05/02/2021 16:24:18 - INFO - volta.train_utils -   [NLVR2]: iter 14780 Ep: 5.47 loss 0.092 score 0.407 lr 4.03693e-06 
05/02/2021 16:25:10 - INFO - volta.train_utils -   [NLVR2]: iter 14820 Ep: 5.49 loss 0.089 score 0.418 lr 4.03282e-06 
05/02/2021 16:25:51 - INFO - volta.train_utils -   [NLVR2]: iter 14860 Ep: 5.50 loss 0.092 score 0.408 lr 4.0287e-06 
05/02/2021 16:26:39 - INFO - volta.train_utils -   [NLVR2]: iter 14900 Ep: 5.52 loss 0.089 score 0.414 lr 4.02459e-06 
05/02/2021 16:27:16 - INFO - volta.train_utils -   [NLVR2]: iter 14940 Ep: 5.53 loss 0.097 score 0.412 lr 4.02047e-06 
05/02/2021 16:28:06 - INFO - volta.train_utils -   [NLVR2]: iter 14980 Ep: 5.55 loss 0.096 score 0.402 lr 4.01636e-06 
05/02/2021 16:28:43 - INFO - volta.train_utils -   [NLVR2]: iter 15020 Ep: 5.56 loss 0.091 score 0.412 lr 4.01224e-06 
05/02/2021 16:29:27 - INFO - volta.train_utils -   [NLVR2]: iter 15060 Ep: 5.58 loss 0.099 score 0.407 lr 4.00813e-06 
05/02/2021 16:30:07 - INFO - volta.train_utils -   [NLVR2]: iter 15100 Ep: 5.59 loss 0.092 score 0.405 lr 4.00401e-06 
05/02/2021 16:30:59 - INFO - volta.train_utils -   [NLVR2]: iter 15140 Ep: 5.61 loss 0.095 score 0.407 lr 3.9999e-06 
05/02/2021 16:31:40 - INFO - volta.train_utils -   [NLVR2]: iter 15180 Ep: 5.62 loss 0.089 score 0.411 lr 3.99578e-06 
05/02/2021 16:32:35 - INFO - volta.train_utils -   [NLVR2]: iter 15220 Ep: 5.64 loss 0.092 score 0.411 lr 3.99167e-06 
05/02/2021 16:33:19 - INFO - volta.train_utils -   [NLVR2]: iter 15260 Ep: 5.65 loss 0.099 score 0.408 lr 3.98755e-06 
05/02/2021 16:34:16 - INFO - volta.train_utils -   [NLVR2]: iter 15300 Ep: 5.67 loss 0.089 score 0.405 lr 3.98344e-06 
05/02/2021 16:35:03 - INFO - volta.train_utils -   [NLVR2]: iter 15340 Ep: 5.68 loss 0.099 score 0.411 lr 3.97932e-06 
05/02/2021 16:35:55 - INFO - volta.train_utils -   [NLVR2]: iter 15380 Ep: 5.70 loss 0.099 score 0.401 lr 3.97521e-06 
05/02/2021 16:36:39 - INFO - volta.train_utils -   [NLVR2]: iter 15420 Ep: 5.71 loss 0.093 score 0.407 lr 3.97109e-06 
05/02/2021 16:37:34 - INFO - volta.train_utils -   [NLVR2]: iter 15460 Ep: 5.73 loss 0.089 score 0.409 lr 3.96698e-06 
05/02/2021 16:38:17 - INFO - volta.train_utils -   [NLVR2]: iter 15500 Ep: 5.74 loss 0.097 score 0.403 lr 3.96286e-06 
05/02/2021 16:39:11 - INFO - volta.train_utils -   [NLVR2]: iter 15540 Ep: 5.76 loss 0.093 score 0.412 lr 3.95874e-06 
05/02/2021 16:39:55 - INFO - volta.train_utils -   [NLVR2]: iter 15580 Ep: 5.77 loss 0.096 score 0.407 lr 3.95463e-06 
05/02/2021 16:40:46 - INFO - volta.train_utils -   [NLVR2]: iter 15620 Ep: 5.79 loss 0.092 score 0.414 lr 3.95051e-06 
05/02/2021 16:41:33 - INFO - volta.train_utils -   [NLVR2]: iter 15660 Ep: 5.80 loss 0.085 score 0.415 lr 3.9464e-06 
05/02/2021 16:42:24 - INFO - volta.train_utils -   [NLVR2]: iter 15700 Ep: 5.81 loss 0.093 score 0.400 lr 3.94228e-06 
05/02/2021 16:43:07 - INFO - volta.train_utils -   [NLVR2]: iter 15740 Ep: 5.83 loss 0.094 score 0.401 lr 3.93817e-06 
05/02/2021 16:44:01 - INFO - volta.train_utils -   [NLVR2]: iter 15780 Ep: 5.84 loss 0.096 score 0.404 lr 3.93405e-06 
05/02/2021 16:44:42 - INFO - volta.train_utils -   [NLVR2]: iter 15820 Ep: 5.86 loss 0.093 score 0.410 lr 3.92994e-06 
05/02/2021 16:45:36 - INFO - volta.train_utils -   [NLVR2]: iter 15860 Ep: 5.87 loss 0.092 score 0.399 lr 3.92582e-06 
05/02/2021 16:46:15 - INFO - volta.train_utils -   [NLVR2]: iter 15900 Ep: 5.89 loss 0.094 score 0.412 lr 3.92171e-06 
05/02/2021 16:47:07 - INFO - volta.train_utils -   [NLVR2]: iter 15940 Ep: 5.90 loss 0.096 score 0.404 lr 3.91759e-06 
05/02/2021 16:47:52 - INFO - volta.train_utils -   [NLVR2]: iter 15980 Ep: 5.92 loss 0.096 score 0.410 lr 3.91348e-06 
05/02/2021 16:48:42 - INFO - volta.train_utils -   [NLVR2]: iter 16020 Ep: 5.93 loss 0.099 score 0.402 lr 3.90936e-06 
05/02/2021 16:49:19 - INFO - volta.train_utils -   [NLVR2]: iter 16060 Ep: 5.95 loss 0.096 score 0.406 lr 3.90525e-06 
05/02/2021 16:50:07 - INFO - volta.train_utils -   [NLVR2]: iter 16100 Ep: 5.96 loss 0.097 score 0.408 lr 3.90113e-06 
05/02/2021 16:50:46 - INFO - volta.train_utils -   [NLVR2]: iter 16140 Ep: 5.98 loss 0.091 score 0.409 lr 3.89702e-06 
05/02/2021 16:51:33 - INFO - volta.train_utils -   [NLVR2]: iter 16180 Ep: 5.99 loss 0.093 score 0.410 lr 3.8929e-06 
05/02/2021 16:51:47 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  30%|       | 6/20 [6:21:46<14:49:04, 3810.35s/it]05/02/2021 17:07:04 - INFO - volta.train_utils -   Eval task TASK12 on iteration 16200 
05/02/2021 17:07:04 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.630 score 73.761 
05/02/2021 17:07:04 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/02/2021 17:07:38 - INFO - volta.train_utils -   [NLVR2]: iter 16240 Ep: 6.01 loss 0.082 score 0.425 lr 3.88776e-06 
05/02/2021 17:08:20 - INFO - volta.train_utils -   [NLVR2]: iter 16280 Ep: 6.03 loss 0.078 score 0.423 lr 3.88261e-06 
05/02/2021 17:09:06 - INFO - volta.train_utils -   [NLVR2]: iter 16320 Ep: 6.04 loss 0.078 score 0.421 lr 3.8785e-06 
05/02/2021 17:09:51 - INFO - volta.train_utils -   [NLVR2]: iter 16360 Ep: 6.06 loss 0.085 score 0.425 lr 3.87438e-06 
05/02/2021 17:10:45 - INFO - volta.train_utils -   [NLVR2]: iter 16400 Ep: 6.07 loss 0.085 score 0.426 lr 3.87027e-06 
05/02/2021 17:11:27 - INFO - volta.train_utils -   [NLVR2]: iter 16440 Ep: 6.09 loss 0.093 score 0.412 lr 3.86615e-06 
05/02/2021 17:12:18 - INFO - volta.train_utils -   [NLVR2]: iter 16480 Ep: 6.10 loss 0.088 score 0.418 lr 3.86204e-06 
05/02/2021 17:12:58 - INFO - volta.train_utils -   [NLVR2]: iter 16520 Ep: 6.12 loss 0.082 score 0.429 lr 3.85792e-06 
05/02/2021 17:13:45 - INFO - volta.train_utils -   [NLVR2]: iter 16560 Ep: 6.13 loss 0.079 score 0.423 lr 3.85381e-06 
05/02/2021 17:14:34 - INFO - volta.train_utils -   [NLVR2]: iter 16600 Ep: 6.15 loss 0.083 score 0.423 lr 3.84969e-06 
05/02/2021 17:15:17 - INFO - volta.train_utils -   [NLVR2]: iter 16640 Ep: 6.16 loss 0.078 score 0.423 lr 3.84558e-06 
05/02/2021 17:16:05 - INFO - volta.train_utils -   [NLVR2]: iter 16680 Ep: 6.18 loss 0.079 score 0.423 lr 3.84146e-06 
05/02/2021 17:16:46 - INFO - volta.train_utils -   [NLVR2]: iter 16720 Ep: 6.19 loss 0.086 score 0.419 lr 3.83735e-06 
05/02/2021 17:17:34 - INFO - volta.train_utils -   [NLVR2]: iter 16760 Ep: 6.21 loss 0.089 score 0.411 lr 3.83323e-06 
05/02/2021 17:18:16 - INFO - volta.train_utils -   [NLVR2]: iter 16800 Ep: 6.22 loss 0.081 score 0.423 lr 3.82912e-06 
05/02/2021 17:19:03 - INFO - volta.train_utils -   [NLVR2]: iter 16840 Ep: 6.24 loss 0.086 score 0.416 lr 3.825e-06 
05/02/2021 17:19:46 - INFO - volta.train_utils -   [NLVR2]: iter 16880 Ep: 6.25 loss 0.077 score 0.426 lr 3.82088e-06 
05/02/2021 17:20:36 - INFO - volta.train_utils -   [NLVR2]: iter 16920 Ep: 6.27 loss 0.082 score 0.423 lr 3.81677e-06 
05/02/2021 17:21:18 - INFO - volta.train_utils -   [NLVR2]: iter 16960 Ep: 6.28 loss 0.084 score 0.421 lr 3.81265e-06 
05/02/2021 17:22:03 - INFO - volta.train_utils -   [NLVR2]: iter 17000 Ep: 6.30 loss 0.090 score 0.415 lr 3.80854e-06 
05/02/2021 17:22:42 - INFO - volta.train_utils -   [NLVR2]: iter 17040 Ep: 6.31 loss 0.086 score 0.418 lr 3.80442e-06 
05/02/2021 17:23:29 - INFO - volta.train_utils -   [NLVR2]: iter 17080 Ep: 6.33 loss 0.087 score 0.411 lr 3.80031e-06 
05/02/2021 17:24:11 - INFO - volta.train_utils -   [NLVR2]: iter 17120 Ep: 6.34 loss 0.087 score 0.410 lr 3.79619e-06 
05/02/2021 17:25:00 - INFO - volta.train_utils -   [NLVR2]: iter 17160 Ep: 6.36 loss 0.075 score 0.429 lr 3.79208e-06 
05/02/2021 17:25:37 - INFO - volta.train_utils -   [NLVR2]: iter 17200 Ep: 6.37 loss 0.073 score 0.429 lr 3.78796e-06 
05/02/2021 17:26:20 - INFO - volta.train_utils -   [NLVR2]: iter 17240 Ep: 6.39 loss 0.079 score 0.430 lr 3.78385e-06 
05/02/2021 17:27:02 - INFO - volta.train_utils -   [NLVR2]: iter 17280 Ep: 6.40 loss 0.085 score 0.418 lr 3.77973e-06 
05/02/2021 17:27:41 - INFO - volta.train_utils -   [NLVR2]: iter 17320 Ep: 6.41 loss 0.086 score 0.422 lr 3.77562e-06 
05/02/2021 17:28:27 - INFO - volta.train_utils -   [NLVR2]: iter 17360 Ep: 6.43 loss 0.087 score 0.416 lr 3.7715e-06 
05/02/2021 17:29:09 - INFO - volta.train_utils -   [NLVR2]: iter 17400 Ep: 6.44 loss 0.082 score 0.424 lr 3.76739e-06 
05/02/2021 17:29:53 - INFO - volta.train_utils -   [NLVR2]: iter 17440 Ep: 6.46 loss 0.078 score 0.423 lr 3.76327e-06 
05/02/2021 17:30:35 - INFO - volta.train_utils -   [NLVR2]: iter 17480 Ep: 6.47 loss 0.078 score 0.423 lr 3.75916e-06 
05/02/2021 17:31:20 - INFO - volta.train_utils -   [NLVR2]: iter 17520 Ep: 6.49 loss 0.077 score 0.423 lr 3.75504e-06 
05/02/2021 17:32:03 - INFO - volta.train_utils -   [NLVR2]: iter 17560 Ep: 6.50 loss 0.085 score 0.427 lr 3.75093e-06 
05/02/2021 17:32:46 - INFO - volta.train_utils -   [NLVR2]: iter 17600 Ep: 6.52 loss 0.083 score 0.419 lr 3.74681e-06 
05/02/2021 17:33:31 - INFO - volta.train_utils -   [NLVR2]: iter 17640 Ep: 6.53 loss 0.093 score 0.417 lr 3.7427e-06 
05/02/2021 17:34:17 - INFO - volta.train_utils -   [NLVR2]: iter 17680 Ep: 6.55 loss 0.084 score 0.412 lr 3.73858e-06 
05/02/2021 17:35:01 - INFO - volta.train_utils -   [NLVR2]: iter 17720 Ep: 6.56 loss 0.088 score 0.415 lr 3.73447e-06 
05/02/2021 17:35:44 - INFO - volta.train_utils -   [NLVR2]: iter 17760 Ep: 6.58 loss 0.090 score 0.412 lr 3.73035e-06 
05/02/2021 17:36:32 - INFO - volta.train_utils -   [NLVR2]: iter 17800 Ep: 6.59 loss 0.079 score 0.422 lr 3.72623e-06 
05/02/2021 17:37:16 - INFO - volta.train_utils -   [NLVR2]: iter 17840 Ep: 6.61 loss 0.089 score 0.416 lr 3.72212e-06 
05/02/2021 17:38:00 - INFO - volta.train_utils -   [NLVR2]: iter 17880 Ep: 6.62 loss 0.082 score 0.424 lr 3.718e-06 
05/02/2021 17:38:47 - INFO - volta.train_utils -   [NLVR2]: iter 17920 Ep: 6.64 loss 0.080 score 0.427 lr 3.71389e-06 
05/02/2021 17:39:33 - INFO - volta.train_utils -   [NLVR2]: iter 17960 Ep: 6.65 loss 0.083 score 0.416 lr 3.70977e-06 
05/02/2021 17:40:19 - INFO - volta.train_utils -   [NLVR2]: iter 18000 Ep: 6.67 loss 0.079 score 0.421 lr 3.70566e-06 
05/02/2021 17:41:05 - INFO - volta.train_utils -   [NLVR2]: iter 18040 Ep: 6.68 loss 0.087 score 0.415 lr 3.70154e-06 
05/02/2021 17:41:51 - INFO - volta.train_utils -   [NLVR2]: iter 18080 Ep: 6.70 loss 0.087 score 0.412 lr 3.69743e-06 
05/02/2021 17:42:35 - INFO - volta.train_utils -   [NLVR2]: iter 18120 Ep: 6.71 loss 0.088 score 0.418 lr 3.69331e-06 
05/02/2021 17:43:19 - INFO - volta.train_utils -   [NLVR2]: iter 18160 Ep: 6.73 loss 0.093 score 0.410 lr 3.6892e-06 
05/02/2021 17:44:00 - INFO - volta.train_utils -   [NLVR2]: iter 18200 Ep: 6.74 loss 0.091 score 0.414 lr 3.68508e-06 
05/02/2021 17:44:40 - INFO - volta.train_utils -   [NLVR2]: iter 18240 Ep: 6.76 loss 0.088 score 0.424 lr 3.68097e-06 
05/02/2021 17:45:24 - INFO - volta.train_utils -   [NLVR2]: iter 18280 Ep: 6.77 loss 0.081 score 0.431 lr 3.67685e-06 
05/02/2021 17:46:08 - INFO - volta.train_utils -   [NLVR2]: iter 18320 Ep: 6.79 loss 0.082 score 0.426 lr 3.67274e-06 
05/02/2021 17:46:52 - INFO - volta.train_utils -   [NLVR2]: iter 18360 Ep: 6.80 loss 0.086 score 0.419 lr 3.66862e-06 
05/02/2021 17:47:33 - INFO - volta.train_utils -   [NLVR2]: iter 18400 Ep: 6.81 loss 0.090 score 0.417 lr 3.66451e-06 
05/02/2021 17:48:18 - INFO - volta.train_utils -   [NLVR2]: iter 18440 Ep: 6.83 loss 0.078 score 0.423 lr 3.66039e-06 
05/02/2021 17:49:01 - INFO - volta.train_utils -   [NLVR2]: iter 18480 Ep: 6.84 loss 0.086 score 0.414 lr 3.65628e-06 
05/02/2021 17:49:51 - INFO - volta.train_utils -   [NLVR2]: iter 18520 Ep: 6.86 loss 0.078 score 0.424 lr 3.65216e-06 
05/02/2021 17:50:33 - INFO - volta.train_utils -   [NLVR2]: iter 18560 Ep: 6.87 loss 0.076 score 0.429 lr 3.64805e-06 
05/02/2021 17:51:23 - INFO - volta.train_utils -   [NLVR2]: iter 18600 Ep: 6.89 loss 0.080 score 0.411 lr 3.64393e-06 
05/02/2021 17:52:05 - INFO - volta.train_utils -   [NLVR2]: iter 18640 Ep: 6.90 loss 0.084 score 0.416 lr 3.63981e-06 
05/02/2021 17:52:51 - INFO - volta.train_utils -   [NLVR2]: iter 18680 Ep: 6.92 loss 0.089 score 0.417 lr 3.6357e-06 
05/02/2021 17:53:29 - INFO - volta.train_utils -   [NLVR2]: iter 18720 Ep: 6.93 loss 0.087 score 0.416 lr 3.63158e-06 
05/02/2021 17:54:15 - INFO - volta.train_utils -   [NLVR2]: iter 18760 Ep: 6.95 loss 0.089 score 0.411 lr 3.62747e-06 
05/02/2021 17:54:49 - INFO - volta.train_utils -   [NLVR2]: iter 18800 Ep: 6.96 loss 0.076 score 0.424 lr 3.62335e-06 
05/02/2021 17:55:32 - INFO - volta.train_utils -   [NLVR2]: iter 18840 Ep: 6.98 loss 0.078 score 0.420 lr 3.61924e-06 
05/02/2021 17:56:10 - INFO - volta.train_utils -   [NLVR2]: iter 18880 Ep: 6.99 loss 0.084 score 0.416 lr 3.61512e-06 
05/02/2021 17:56:22 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  35%|      | 7/20 [7:26:21<13:49:46, 3829.69s/it]05/02/2021 18:11:18 - INFO - volta.train_utils -   Eval task TASK12 on iteration 18900 
05/02/2021 18:11:18 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.663 score 73.546 
05/02/2021 18:11:38 - INFO - volta.train_utils -   [NLVR2]: iter 18940 Ep: 7.01 loss 0.073 score 0.428 lr 3.60998e-06 
05/02/2021 18:12:12 - INFO - volta.train_utils -   [NLVR2]: iter 18980 Ep: 7.03 loss 0.071 score 0.434 lr 3.60484e-06 
05/02/2021 18:12:52 - INFO - volta.train_utils -   [NLVR2]: iter 19020 Ep: 7.04 loss 0.067 score 0.432 lr 3.60072e-06 
05/02/2021 18:13:28 - INFO - volta.train_utils -   [NLVR2]: iter 19060 Ep: 7.06 loss 0.074 score 0.437 lr 3.5966e-06 
05/02/2021 18:14:11 - INFO - volta.train_utils -   [NLVR2]: iter 19100 Ep: 7.07 loss 0.071 score 0.431 lr 3.59249e-06 
05/02/2021 18:14:52 - INFO - volta.train_utils -   [NLVR2]: iter 19140 Ep: 7.09 loss 0.065 score 0.436 lr 3.58837e-06 
05/02/2021 18:15:32 - INFO - volta.train_utils -   [NLVR2]: iter 19180 Ep: 7.10 loss 0.087 score 0.421 lr 3.58426e-06 
05/02/2021 18:16:16 - INFO - volta.train_utils -   [NLVR2]: iter 19220 Ep: 7.12 loss 0.073 score 0.429 lr 3.58014e-06 
05/02/2021 18:16:55 - INFO - volta.train_utils -   [NLVR2]: iter 19260 Ep: 7.13 loss 0.090 score 0.415 lr 3.57603e-06 
05/02/2021 18:17:42 - INFO - volta.train_utils -   [NLVR2]: iter 19300 Ep: 7.15 loss 0.074 score 0.435 lr 3.57191e-06 
05/02/2021 18:18:20 - INFO - volta.train_utils -   [NLVR2]: iter 19340 Ep: 7.16 loss 0.069 score 0.437 lr 3.5678e-06 
05/02/2021 18:19:09 - INFO - volta.train_utils -   [NLVR2]: iter 19380 Ep: 7.18 loss 0.068 score 0.442 lr 3.56368e-06 
05/02/2021 18:19:51 - INFO - volta.train_utils -   [NLVR2]: iter 19420 Ep: 7.19 loss 0.073 score 0.435 lr 3.55957e-06 
05/02/2021 18:20:40 - INFO - volta.train_utils -   [NLVR2]: iter 19460 Ep: 7.21 loss 0.073 score 0.432 lr 3.55545e-06 
05/02/2021 18:21:17 - INFO - volta.train_utils -   [NLVR2]: iter 19500 Ep: 7.22 loss 0.067 score 0.436 lr 3.55134e-06 
05/02/2021 18:22:03 - INFO - volta.train_utils -   [NLVR2]: iter 19540 Ep: 7.24 loss 0.091 score 0.427 lr 3.54722e-06 
05/02/2021 18:22:41 - INFO - volta.train_utils -   [NLVR2]: iter 19580 Ep: 7.25 loss 0.066 score 0.434 lr 3.54311e-06 
05/02/2021 18:23:27 - INFO - volta.train_utils -   [NLVR2]: iter 19620 Ep: 7.27 loss 0.075 score 0.433 lr 3.53899e-06 
05/02/2021 18:24:09 - INFO - volta.train_utils -   [NLVR2]: iter 19660 Ep: 7.28 loss 0.076 score 0.428 lr 3.53488e-06 
05/02/2021 18:24:58 - INFO - volta.train_utils -   [NLVR2]: iter 19700 Ep: 7.30 loss 0.070 score 0.433 lr 3.53076e-06 
05/02/2021 18:25:38 - INFO - volta.train_utils -   [NLVR2]: iter 19740 Ep: 7.31 loss 0.075 score 0.427 lr 3.52665e-06 
05/02/2021 18:26:24 - INFO - volta.train_utils -   [NLVR2]: iter 19780 Ep: 7.33 loss 0.062 score 0.434 lr 3.52253e-06 
05/02/2021 18:27:04 - INFO - volta.train_utils -   [NLVR2]: iter 19820 Ep: 7.34 loss 0.066 score 0.433 lr 3.51842e-06 
05/02/2021 18:27:53 - INFO - volta.train_utils -   [NLVR2]: iter 19860 Ep: 7.36 loss 0.076 score 0.424 lr 3.5143e-06 
05/02/2021 18:28:29 - INFO - volta.train_utils -   [NLVR2]: iter 19900 Ep: 7.37 loss 0.078 score 0.433 lr 3.51019e-06 
05/02/2021 18:29:13 - INFO - volta.train_utils -   [NLVR2]: iter 19940 Ep: 7.39 loss 0.075 score 0.425 lr 3.50607e-06 
05/02/2021 18:29:52 - INFO - volta.train_utils -   [NLVR2]: iter 19980 Ep: 7.40 loss 0.073 score 0.435 lr 3.50195e-06 
05/02/2021 18:30:38 - INFO - volta.train_utils -   [NLVR2]: iter 20020 Ep: 7.41 loss 0.072 score 0.432 lr 3.49784e-06 
05/02/2021 18:31:14 - INFO - volta.train_utils -   [NLVR2]: iter 20060 Ep: 7.43 loss 0.070 score 0.442 lr 3.49372e-06 
05/02/2021 18:31:57 - INFO - volta.train_utils -   [NLVR2]: iter 20100 Ep: 7.44 loss 0.073 score 0.430 lr 3.48961e-06 
05/02/2021 18:32:33 - INFO - volta.train_utils -   [NLVR2]: iter 20140 Ep: 7.46 loss 0.074 score 0.431 lr 3.48549e-06 
05/02/2021 18:33:17 - INFO - volta.train_utils -   [NLVR2]: iter 20180 Ep: 7.47 loss 0.074 score 0.430 lr 3.48138e-06 
05/02/2021 18:33:54 - INFO - volta.train_utils -   [NLVR2]: iter 20220 Ep: 7.49 loss 0.078 score 0.432 lr 3.47726e-06 
05/02/2021 18:34:41 - INFO - volta.train_utils -   [NLVR2]: iter 20260 Ep: 7.50 loss 0.068 score 0.432 lr 3.47315e-06 
05/02/2021 18:35:16 - INFO - volta.train_utils -   [NLVR2]: iter 20300 Ep: 7.52 loss 0.083 score 0.425 lr 3.46903e-06 
05/02/2021 18:36:00 - INFO - volta.train_utils -   [NLVR2]: iter 20340 Ep: 7.53 loss 0.075 score 0.432 lr 3.46492e-06 
05/02/2021 18:36:36 - INFO - volta.train_utils -   [NLVR2]: iter 20380 Ep: 7.55 loss 0.077 score 0.425 lr 3.4608e-06 
05/02/2021 18:37:22 - INFO - volta.train_utils -   [NLVR2]: iter 20420 Ep: 7.56 loss 0.071 score 0.430 lr 3.45669e-06 
05/02/2021 18:37:59 - INFO - volta.train_utils -   [NLVR2]: iter 20460 Ep: 7.58 loss 0.077 score 0.428 lr 3.45257e-06 
05/02/2021 18:38:47 - INFO - volta.train_utils -   [NLVR2]: iter 20500 Ep: 7.59 loss 0.076 score 0.434 lr 3.44846e-06 
05/02/2021 18:39:26 - INFO - volta.train_utils -   [NLVR2]: iter 20540 Ep: 7.61 loss 0.073 score 0.443 lr 3.44434e-06 
05/02/2021 18:40:08 - INFO - volta.train_utils -   [NLVR2]: iter 20580 Ep: 7.62 loss 0.070 score 0.431 lr 3.44023e-06 
05/02/2021 18:40:47 - INFO - volta.train_utils -   [NLVR2]: iter 20620 Ep: 7.64 loss 0.074 score 0.432 lr 3.43611e-06 
05/02/2021 18:41:37 - INFO - volta.train_utils -   [NLVR2]: iter 20660 Ep: 7.65 loss 0.079 score 0.424 lr 3.432e-06 
05/02/2021 18:42:16 - INFO - volta.train_utils -   [NLVR2]: iter 20700 Ep: 7.67 loss 0.078 score 0.435 lr 3.42788e-06 
05/02/2021 18:43:00 - INFO - volta.train_utils -   [NLVR2]: iter 20740 Ep: 7.68 loss 0.079 score 0.420 lr 3.42377e-06 
05/02/2021 18:43:41 - INFO - volta.train_utils -   [NLVR2]: iter 20780 Ep: 7.70 loss 0.076 score 0.428 lr 3.41965e-06 
05/02/2021 18:44:28 - INFO - volta.train_utils -   [NLVR2]: iter 20820 Ep: 7.71 loss 0.070 score 0.435 lr 3.41553e-06 
05/02/2021 18:45:10 - INFO - volta.train_utils -   [NLVR2]: iter 20860 Ep: 7.73 loss 0.080 score 0.426 lr 3.41142e-06 
05/02/2021 18:45:58 - INFO - volta.train_utils -   [NLVR2]: iter 20900 Ep: 7.74 loss 0.087 score 0.420 lr 3.4073e-06 
05/02/2021 18:46:44 - INFO - volta.train_utils -   [NLVR2]: iter 20940 Ep: 7.76 loss 0.080 score 0.431 lr 3.40319e-06 
05/02/2021 18:47:27 - INFO - volta.train_utils -   [NLVR2]: iter 20980 Ep: 7.77 loss 0.072 score 0.432 lr 3.39907e-06 
05/02/2021 18:48:16 - INFO - volta.train_utils -   [NLVR2]: iter 21020 Ep: 7.79 loss 0.070 score 0.431 lr 3.39496e-06 
05/02/2021 18:49:03 - INFO - volta.train_utils -   [NLVR2]: iter 21060 Ep: 7.80 loss 0.074 score 0.432 lr 3.39084e-06 
05/02/2021 18:49:55 - INFO - volta.train_utils -   [NLVR2]: iter 21100 Ep: 7.81 loss 0.069 score 0.430 lr 3.38673e-06 
05/02/2021 18:50:35 - INFO - volta.train_utils -   [NLVR2]: iter 21140 Ep: 7.83 loss 0.086 score 0.421 lr 3.38261e-06 
05/02/2021 18:51:26 - INFO - volta.train_utils -   [NLVR2]: iter 21180 Ep: 7.84 loss 0.074 score 0.430 lr 3.3785e-06 
05/02/2021 18:52:13 - INFO - volta.train_utils -   [NLVR2]: iter 21220 Ep: 7.86 loss 0.085 score 0.420 lr 3.37438e-06 
05/02/2021 18:53:02 - INFO - volta.train_utils -   [NLVR2]: iter 21260 Ep: 7.87 loss 0.073 score 0.436 lr 3.37027e-06 
05/02/2021 18:53:48 - INFO - volta.train_utils -   [NLVR2]: iter 21300 Ep: 7.89 loss 0.077 score 0.434 lr 3.36615e-06 
05/02/2021 18:54:36 - INFO - volta.train_utils -   [NLVR2]: iter 21340 Ep: 7.90 loss 0.080 score 0.422 lr 3.36204e-06 
05/02/2021 18:55:24 - INFO - volta.train_utils -   [NLVR2]: iter 21380 Ep: 7.92 loss 0.081 score 0.424 lr 3.35792e-06 
05/02/2021 18:56:11 - INFO - volta.train_utils -   [NLVR2]: iter 21420 Ep: 7.93 loss 0.082 score 0.427 lr 3.35381e-06 
05/02/2021 18:56:55 - INFO - volta.train_utils -   [NLVR2]: iter 21460 Ep: 7.95 loss 0.079 score 0.427 lr 3.34969e-06 
05/02/2021 18:57:39 - INFO - volta.train_utils -   [NLVR2]: iter 21500 Ep: 7.96 loss 0.073 score 0.433 lr 3.34558e-06 
05/02/2021 18:58:24 - INFO - volta.train_utils -   [NLVR2]: iter 21540 Ep: 7.98 loss 0.074 score 0.431 lr 3.34146e-06 
05/02/2021 18:59:02 - INFO - volta.train_utils -   [NLVR2]: iter 21580 Ep: 7.99 loss 0.082 score 0.430 lr 3.33735e-06 
05/02/2021 18:59:18 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  40%|      | 8/20 [8:29:19<12:42:49, 3814.13s/it]05/02/2021 19:14:11 - INFO - volta.train_utils -   Eval task TASK12 on iteration 21600 
05/02/2021 19:14:11 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.671 score 73.976 
05/02/2021 19:14:11 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/02/2021 19:14:44 - INFO - volta.train_utils -   [NLVR2]: iter 21640 Ep: 8.01 loss 0.072 score 0.429 lr 3.3322e-06 
05/02/2021 19:15:21 - INFO - volta.train_utils -   [NLVR2]: iter 21680 Ep: 8.03 loss 0.055 score 0.450 lr 3.32706e-06 
05/02/2021 19:16:03 - INFO - volta.train_utils -   [NLVR2]: iter 21720 Ep: 8.04 loss 0.057 score 0.443 lr 3.32294e-06 
05/02/2021 19:16:35 - INFO - volta.train_utils -   [NLVR2]: iter 21760 Ep: 8.06 loss 0.068 score 0.439 lr 3.31883e-06 
05/02/2021 19:17:13 - INFO - volta.train_utils -   [NLVR2]: iter 21800 Ep: 8.07 loss 0.054 score 0.443 lr 3.31471e-06 
05/02/2021 19:17:45 - INFO - volta.train_utils -   [NLVR2]: iter 21840 Ep: 8.09 loss 0.063 score 0.443 lr 3.3106e-06 
05/02/2021 19:18:25 - INFO - volta.train_utils -   [NLVR2]: iter 21880 Ep: 8.10 loss 0.066 score 0.440 lr 3.30648e-06 
05/02/2021 19:19:01 - INFO - volta.train_utils -   [NLVR2]: iter 21920 Ep: 8.12 loss 0.062 score 0.440 lr 3.30237e-06 
05/02/2021 19:19:41 - INFO - volta.train_utils -   [NLVR2]: iter 21960 Ep: 8.13 loss 0.082 score 0.431 lr 3.29825e-06 
05/02/2021 19:20:15 - INFO - volta.train_utils -   [NLVR2]: iter 22000 Ep: 8.15 loss 0.063 score 0.444 lr 3.29414e-06 
05/02/2021 19:20:58 - INFO - volta.train_utils -   [NLVR2]: iter 22040 Ep: 8.16 loss 0.063 score 0.443 lr 3.29002e-06 
05/02/2021 19:21:34 - INFO - volta.train_utils -   [NLVR2]: iter 22080 Ep: 8.18 loss 0.063 score 0.443 lr 3.28591e-06 
05/02/2021 19:22:17 - INFO - volta.train_utils -   [NLVR2]: iter 22120 Ep: 8.19 loss 0.062 score 0.432 lr 3.28179e-06 
05/02/2021 19:22:57 - INFO - volta.train_utils -   [NLVR2]: iter 22160 Ep: 8.21 loss 0.063 score 0.439 lr 3.27767e-06 
05/02/2021 19:23:46 - INFO - volta.train_utils -   [NLVR2]: iter 22200 Ep: 8.22 loss 0.068 score 0.440 lr 3.27356e-06 
05/02/2021 19:24:25 - INFO - volta.train_utils -   [NLVR2]: iter 22240 Ep: 8.24 loss 0.066 score 0.442 lr 3.26944e-06 
05/02/2021 19:25:13 - INFO - volta.train_utils -   [NLVR2]: iter 22280 Ep: 8.25 loss 0.070 score 0.433 lr 3.26533e-06 
05/02/2021 19:25:50 - INFO - volta.train_utils -   [NLVR2]: iter 22320 Ep: 8.27 loss 0.063 score 0.441 lr 3.26121e-06 
05/02/2021 19:26:37 - INFO - volta.train_utils -   [NLVR2]: iter 22360 Ep: 8.28 loss 0.063 score 0.443 lr 3.2571e-06 
05/02/2021 19:27:20 - INFO - volta.train_utils -   [NLVR2]: iter 22400 Ep: 8.30 loss 0.063 score 0.438 lr 3.25298e-06 
05/02/2021 19:28:06 - INFO - volta.train_utils -   [NLVR2]: iter 22440 Ep: 8.31 loss 0.069 score 0.432 lr 3.24887e-06 
05/02/2021 19:28:46 - INFO - volta.train_utils -   [NLVR2]: iter 22480 Ep: 8.33 loss 0.065 score 0.443 lr 3.24475e-06 
05/02/2021 19:29:27 - INFO - volta.train_utils -   [NLVR2]: iter 22520 Ep: 8.34 loss 0.070 score 0.432 lr 3.24064e-06 
05/02/2021 19:30:10 - INFO - volta.train_utils -   [NLVR2]: iter 22560 Ep: 8.36 loss 0.071 score 0.435 lr 3.23652e-06 
05/02/2021 19:30:49 - INFO - volta.train_utils -   [NLVR2]: iter 22600 Ep: 8.37 loss 0.066 score 0.443 lr 3.23241e-06 
05/02/2021 19:31:26 - INFO - volta.train_utils -   [NLVR2]: iter 22640 Ep: 8.39 loss 0.064 score 0.439 lr 3.22829e-06 
05/02/2021 19:32:11 - INFO - volta.train_utils -   [NLVR2]: iter 22680 Ep: 8.40 loss 0.068 score 0.432 lr 3.22418e-06 
05/02/2021 19:32:45 - INFO - volta.train_utils -   [NLVR2]: iter 22720 Ep: 8.41 loss 0.069 score 0.437 lr 3.22006e-06 
05/02/2021 19:33:25 - INFO - volta.train_utils -   [NLVR2]: iter 22760 Ep: 8.43 loss 0.067 score 0.438 lr 3.21595e-06 
05/02/2021 19:34:01 - INFO - volta.train_utils -   [NLVR2]: iter 22800 Ep: 8.44 loss 0.067 score 0.435 lr 3.21183e-06 
05/02/2021 19:34:44 - INFO - volta.train_utils -   [NLVR2]: iter 22840 Ep: 8.46 loss 0.068 score 0.439 lr 3.20772e-06 
05/02/2021 19:35:19 - INFO - volta.train_utils -   [NLVR2]: iter 22880 Ep: 8.47 loss 0.065 score 0.445 lr 3.2036e-06 
05/02/2021 19:36:00 - INFO - volta.train_utils -   [NLVR2]: iter 22920 Ep: 8.49 loss 0.064 score 0.440 lr 3.19949e-06 
05/02/2021 19:36:35 - INFO - volta.train_utils -   [NLVR2]: iter 22960 Ep: 8.50 loss 0.069 score 0.434 lr 3.19537e-06 
05/02/2021 19:37:19 - INFO - volta.train_utils -   [NLVR2]: iter 23000 Ep: 8.52 loss 0.072 score 0.431 lr 3.19126e-06 
05/02/2021 19:37:54 - INFO - volta.train_utils -   [NLVR2]: iter 23040 Ep: 8.53 loss 0.055 score 0.448 lr 3.18714e-06 
05/02/2021 19:38:35 - INFO - volta.train_utils -   [NLVR2]: iter 23080 Ep: 8.55 loss 0.063 score 0.442 lr 3.18302e-06 
05/02/2021 19:39:14 - INFO - volta.train_utils -   [NLVR2]: iter 23120 Ep: 8.56 loss 0.062 score 0.441 lr 3.17891e-06 
05/02/2021 19:40:00 - INFO - volta.train_utils -   [NLVR2]: iter 23160 Ep: 8.58 loss 0.062 score 0.442 lr 3.17479e-06 
05/02/2021 19:40:34 - INFO - volta.train_utils -   [NLVR2]: iter 23200 Ep: 8.59 loss 0.064 score 0.437 lr 3.17068e-06 
05/02/2021 19:41:12 - INFO - volta.train_utils -   [NLVR2]: iter 23240 Ep: 8.61 loss 0.071 score 0.442 lr 3.16656e-06 
05/02/2021 19:41:47 - INFO - volta.train_utils -   [NLVR2]: iter 23280 Ep: 8.62 loss 0.072 score 0.430 lr 3.16245e-06 
05/02/2021 19:42:32 - INFO - volta.train_utils -   [NLVR2]: iter 23320 Ep: 8.64 loss 0.072 score 0.438 lr 3.15833e-06 
05/02/2021 19:43:07 - INFO - volta.train_utils -   [NLVR2]: iter 23360 Ep: 8.65 loss 0.068 score 0.440 lr 3.15422e-06 
05/02/2021 19:43:47 - INFO - volta.train_utils -   [NLVR2]: iter 23400 Ep: 8.67 loss 0.060 score 0.443 lr 3.1501e-06 
05/02/2021 19:44:18 - INFO - volta.train_utils -   [NLVR2]: iter 23440 Ep: 8.68 loss 0.067 score 0.433 lr 3.14599e-06 
05/02/2021 19:44:57 - INFO - volta.train_utils -   [NLVR2]: iter 23480 Ep: 8.70 loss 0.068 score 0.435 lr 3.14187e-06 
05/02/2021 19:45:34 - INFO - volta.train_utils -   [NLVR2]: iter 23520 Ep: 8.71 loss 0.063 score 0.438 lr 3.13776e-06 
05/02/2021 19:46:16 - INFO - volta.train_utils -   [NLVR2]: iter 23560 Ep: 8.73 loss 0.068 score 0.436 lr 3.13364e-06 
05/02/2021 19:46:55 - INFO - volta.train_utils -   [NLVR2]: iter 23600 Ep: 8.74 loss 0.069 score 0.438 lr 3.12953e-06 
05/02/2021 19:47:38 - INFO - volta.train_utils -   [NLVR2]: iter 23640 Ep: 8.76 loss 0.072 score 0.436 lr 3.12541e-06 
05/02/2021 19:48:14 - INFO - volta.train_utils -   [NLVR2]: iter 23680 Ep: 8.77 loss 0.064 score 0.443 lr 3.1213e-06 
05/02/2021 19:48:58 - INFO - volta.train_utils -   [NLVR2]: iter 23720 Ep: 8.79 loss 0.068 score 0.436 lr 3.11718e-06 
05/02/2021 19:49:36 - INFO - volta.train_utils -   [NLVR2]: iter 23760 Ep: 8.80 loss 0.069 score 0.437 lr 3.11307e-06 
05/02/2021 19:50:27 - INFO - volta.train_utils -   [NLVR2]: iter 23800 Ep: 8.81 loss 0.071 score 0.439 lr 3.10895e-06 
05/02/2021 19:51:10 - INFO - volta.train_utils -   [NLVR2]: iter 23840 Ep: 8.83 loss 0.063 score 0.433 lr 3.10484e-06 
05/02/2021 19:51:56 - INFO - volta.train_utils -   [NLVR2]: iter 23880 Ep: 8.84 loss 0.070 score 0.436 lr 3.10072e-06 
05/02/2021 19:52:35 - INFO - volta.train_utils -   [NLVR2]: iter 23920 Ep: 8.86 loss 0.070 score 0.440 lr 3.0966e-06 
05/02/2021 19:53:23 - INFO - volta.train_utils -   [NLVR2]: iter 23960 Ep: 8.87 loss 0.069 score 0.434 lr 3.09249e-06 
05/02/2021 19:54:03 - INFO - volta.train_utils -   [NLVR2]: iter 24000 Ep: 8.89 loss 0.063 score 0.438 lr 3.08837e-06 
05/02/2021 19:54:53 - INFO - volta.train_utils -   [NLVR2]: iter 24040 Ep: 8.90 loss 0.071 score 0.438 lr 3.08426e-06 
05/02/2021 19:55:39 - INFO - volta.train_utils -   [NLVR2]: iter 24080 Ep: 8.92 loss 0.066 score 0.439 lr 3.08014e-06 
05/02/2021 19:56:28 - INFO - volta.train_utils -   [NLVR2]: iter 24120 Ep: 8.93 loss 0.070 score 0.429 lr 3.07603e-06 
05/02/2021 19:57:08 - INFO - volta.train_utils -   [NLVR2]: iter 24160 Ep: 8.95 loss 0.068 score 0.438 lr 3.07191e-06 
05/02/2021 19:58:01 - INFO - volta.train_utils -   [NLVR2]: iter 24200 Ep: 8.96 loss 0.072 score 0.430 lr 3.0678e-06 
05/02/2021 19:58:42 - INFO - volta.train_utils -   [NLVR2]: iter 24240 Ep: 8.98 loss 0.078 score 0.436 lr 3.06368e-06 
05/02/2021 19:59:30 - INFO - volta.train_utils -   [NLVR2]: iter 24280 Ep: 8.99 loss 0.066 score 0.441 lr 3.05957e-06 
05/02/2021 19:59:44 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  45%|     | 9/20 [9:29:44<11:28:51, 3757.38s/it]05/02/2021 20:15:15 - INFO - volta.train_utils -   Eval task TASK12 on iteration 24300 
05/02/2021 20:15:15 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.761 score 73.503 
05/02/2021 20:15:35 - INFO - volta.train_utils -   [NLVR2]: iter 24340 Ep: 9.01 loss 0.057 score 0.442 lr 3.05442e-06 
05/02/2021 20:16:16 - INFO - volta.train_utils -   [NLVR2]: iter 24380 Ep: 9.03 loss 0.070 score 0.446 lr 3.04928e-06 
05/02/2021 20:16:58 - INFO - volta.train_utils -   [NLVR2]: iter 24420 Ep: 9.04 loss 0.060 score 0.446 lr 3.04516e-06 
05/02/2021 20:17:38 - INFO - volta.train_utils -   [NLVR2]: iter 24460 Ep: 9.06 loss 0.059 score 0.452 lr 3.04105e-06 
05/02/2021 20:18:20 - INFO - volta.train_utils -   [NLVR2]: iter 24500 Ep: 9.07 loss 0.055 score 0.451 lr 3.03693e-06 
05/02/2021 20:18:59 - INFO - volta.train_utils -   [NLVR2]: iter 24540 Ep: 9.09 loss 0.057 score 0.445 lr 3.03282e-06 
05/02/2021 20:19:40 - INFO - volta.train_utils -   [NLVR2]: iter 24580 Ep: 9.10 loss 0.058 score 0.449 lr 3.0287e-06 
05/02/2021 20:20:25 - INFO - volta.train_utils -   [NLVR2]: iter 24620 Ep: 9.12 loss 0.050 score 0.454 lr 3.02459e-06 
05/02/2021 20:21:05 - INFO - volta.train_utils -   [NLVR2]: iter 24660 Ep: 9.13 loss 0.057 score 0.441 lr 3.02047e-06 
05/02/2021 20:21:49 - INFO - volta.train_utils -   [NLVR2]: iter 24700 Ep: 9.15 loss 0.064 score 0.441 lr 3.01636e-06 
05/02/2021 20:22:30 - INFO - volta.train_utils -   [NLVR2]: iter 24740 Ep: 9.16 loss 0.052 score 0.450 lr 3.01224e-06 
05/02/2021 20:23:12 - INFO - volta.train_utils -   [NLVR2]: iter 24780 Ep: 9.18 loss 0.060 score 0.452 lr 3.00813e-06 
05/02/2021 20:23:57 - INFO - volta.train_utils -   [NLVR2]: iter 24820 Ep: 9.19 loss 0.059 score 0.446 lr 3.00401e-06 
05/02/2021 20:24:37 - INFO - volta.train_utils -   [NLVR2]: iter 24860 Ep: 9.21 loss 0.055 score 0.449 lr 2.9999e-06 
05/02/2021 20:25:23 - INFO - volta.train_utils -   [NLVR2]: iter 24900 Ep: 9.22 loss 0.055 score 0.444 lr 2.99578e-06 
05/02/2021 20:26:00 - INFO - volta.train_utils -   [NLVR2]: iter 24940 Ep: 9.24 loss 0.063 score 0.443 lr 2.99167e-06 
05/02/2021 20:26:48 - INFO - volta.train_utils -   [NLVR2]: iter 24980 Ep: 9.25 loss 0.051 score 0.453 lr 2.98755e-06 
05/02/2021 20:27:28 - INFO - volta.train_utils -   [NLVR2]: iter 25020 Ep: 9.27 loss 0.056 score 0.444 lr 2.98344e-06 
05/02/2021 20:28:16 - INFO - volta.train_utils -   [NLVR2]: iter 25060 Ep: 9.28 loss 0.067 score 0.448 lr 2.97932e-06 
05/02/2021 20:28:56 - INFO - volta.train_utils -   [NLVR2]: iter 25100 Ep: 9.30 loss 0.058 score 0.448 lr 2.97521e-06 
05/02/2021 20:29:42 - INFO - volta.train_utils -   [NLVR2]: iter 25140 Ep: 9.31 loss 0.060 score 0.450 lr 2.97109e-06 
05/02/2021 20:30:23 - INFO - volta.train_utils -   [NLVR2]: iter 25180 Ep: 9.33 loss 0.073 score 0.442 lr 2.96698e-06 
05/02/2021 20:31:09 - INFO - volta.train_utils -   [NLVR2]: iter 25220 Ep: 9.34 loss 0.068 score 0.439 lr 2.96286e-06 
05/02/2021 20:31:45 - INFO - volta.train_utils -   [NLVR2]: iter 25260 Ep: 9.36 loss 0.060 score 0.446 lr 2.95874e-06 
05/02/2021 20:32:34 - INFO - volta.train_utils -   [NLVR2]: iter 25300 Ep: 9.37 loss 0.063 score 0.443 lr 2.95463e-06 
05/02/2021 20:33:15 - INFO - volta.train_utils -   [NLVR2]: iter 25340 Ep: 9.39 loss 0.065 score 0.446 lr 2.95051e-06 
05/02/2021 20:34:09 - INFO - volta.train_utils -   [NLVR2]: iter 25380 Ep: 9.40 loss 0.060 score 0.447 lr 2.9464e-06 
05/02/2021 20:34:41 - INFO - volta.train_utils -   [NLVR2]: iter 25420 Ep: 9.41 loss 0.065 score 0.436 lr 2.94228e-06 
05/02/2021 20:35:34 - INFO - volta.train_utils -   [NLVR2]: iter 25460 Ep: 9.43 loss 0.056 score 0.451 lr 2.93817e-06 
05/02/2021 20:36:15 - INFO - volta.train_utils -   [NLVR2]: iter 25500 Ep: 9.44 loss 0.069 score 0.441 lr 2.93405e-06 
05/02/2021 20:37:02 - INFO - volta.train_utils -   [NLVR2]: iter 25540 Ep: 9.46 loss 0.056 score 0.447 lr 2.92994e-06 
05/02/2021 20:37:43 - INFO - volta.train_utils -   [NLVR2]: iter 25580 Ep: 9.47 loss 0.052 score 0.451 lr 2.92582e-06 
05/02/2021 20:38:32 - INFO - volta.train_utils -   [NLVR2]: iter 25620 Ep: 9.49 loss 0.071 score 0.436 lr 2.92171e-06 
05/02/2021 20:39:13 - INFO - volta.train_utils -   [NLVR2]: iter 25660 Ep: 9.50 loss 0.056 score 0.448 lr 2.91759e-06 
05/02/2021 20:40:05 - INFO - volta.train_utils -   [NLVR2]: iter 25700 Ep: 9.52 loss 0.057 score 0.445 lr 2.91348e-06 
05/02/2021 20:40:47 - INFO - volta.train_utils -   [NLVR2]: iter 25740 Ep: 9.53 loss 0.061 score 0.447 lr 2.90936e-06 
05/02/2021 20:41:42 - INFO - volta.train_utils -   [NLVR2]: iter 25780 Ep: 9.55 loss 0.060 score 0.440 lr 2.90525e-06 
05/02/2021 20:42:26 - INFO - volta.train_utils -   [NLVR2]: iter 25820 Ep: 9.56 loss 0.060 score 0.443 lr 2.90113e-06 
05/02/2021 20:43:18 - INFO - volta.train_utils -   [NLVR2]: iter 25860 Ep: 9.58 loss 0.055 score 0.450 lr 2.89702e-06 
05/02/2021 20:44:04 - INFO - volta.train_utils -   [NLVR2]: iter 25900 Ep: 9.59 loss 0.060 score 0.439 lr 2.8929e-06 
05/02/2021 20:44:59 - INFO - volta.train_utils -   [NLVR2]: iter 25940 Ep: 9.61 loss 0.056 score 0.450 lr 2.88879e-06 
05/02/2021 20:45:46 - INFO - volta.train_utils -   [NLVR2]: iter 25980 Ep: 9.62 loss 0.050 score 0.441 lr 2.88467e-06 
05/02/2021 20:46:43 - INFO - volta.train_utils -   [NLVR2]: iter 26020 Ep: 9.64 loss 0.065 score 0.445 lr 2.88056e-06 
05/02/2021 20:47:27 - INFO - volta.train_utils -   [NLVR2]: iter 26060 Ep: 9.65 loss 0.057 score 0.455 lr 2.87644e-06 
05/02/2021 20:48:15 - INFO - volta.train_utils -   [NLVR2]: iter 26100 Ep: 9.67 loss 0.064 score 0.450 lr 2.87233e-06 
05/02/2021 20:48:57 - INFO - volta.train_utils -   [NLVR2]: iter 26140 Ep: 9.68 loss 0.059 score 0.443 lr 2.86821e-06 
05/02/2021 20:49:40 - INFO - volta.train_utils -   [NLVR2]: iter 26180 Ep: 9.70 loss 0.061 score 0.451 lr 2.86409e-06 
05/02/2021 20:50:22 - INFO - volta.train_utils -   [NLVR2]: iter 26220 Ep: 9.71 loss 0.060 score 0.446 lr 2.85998e-06 
05/02/2021 20:51:10 - INFO - volta.train_utils -   [NLVR2]: iter 26260 Ep: 9.73 loss 0.057 score 0.450 lr 2.85586e-06 
05/02/2021 20:51:49 - INFO - volta.train_utils -   [NLVR2]: iter 26300 Ep: 9.74 loss 0.061 score 0.439 lr 2.85175e-06 
05/02/2021 20:52:44 - INFO - volta.train_utils -   [NLVR2]: iter 26340 Ep: 9.76 loss 0.063 score 0.445 lr 2.84763e-06 
05/02/2021 20:53:19 - INFO - volta.train_utils -   [NLVR2]: iter 26380 Ep: 9.77 loss 0.062 score 0.445 lr 2.84352e-06 
05/02/2021 20:54:12 - INFO - volta.train_utils -   [NLVR2]: iter 26420 Ep: 9.79 loss 0.063 score 0.439 lr 2.8394e-06 
05/02/2021 20:54:53 - INFO - volta.train_utils -   [NLVR2]: iter 26460 Ep: 9.80 loss 0.065 score 0.440 lr 2.83529e-06 
05/02/2021 20:55:46 - INFO - volta.train_utils -   [NLVR2]: iter 26500 Ep: 9.81 loss 0.064 score 0.437 lr 2.83117e-06 
05/02/2021 20:56:32 - INFO - volta.train_utils -   [NLVR2]: iter 26540 Ep: 9.83 loss 0.057 score 0.447 lr 2.82706e-06 
05/02/2021 20:57:27 - INFO - volta.train_utils -   [NLVR2]: iter 26580 Ep: 9.84 loss 0.052 score 0.451 lr 2.82294e-06 
05/02/2021 20:58:09 - INFO - volta.train_utils -   [NLVR2]: iter 26620 Ep: 9.86 loss 0.061 score 0.443 lr 2.81883e-06 
05/02/2021 20:59:04 - INFO - volta.train_utils -   [NLVR2]: iter 26660 Ep: 9.87 loss 0.070 score 0.444 lr 2.81471e-06 
05/02/2021 20:59:50 - INFO - volta.train_utils -   [NLVR2]: iter 26700 Ep: 9.89 loss 0.058 score 0.444 lr 2.8106e-06 
05/02/2021 21:00:44 - INFO - volta.train_utils -   [NLVR2]: iter 26740 Ep: 9.90 loss 0.060 score 0.448 lr 2.80648e-06 
05/02/2021 21:01:25 - INFO - volta.train_utils -   [NLVR2]: iter 26780 Ep: 9.92 loss 0.063 score 0.444 lr 2.80237e-06 
05/02/2021 21:02:22 - INFO - volta.train_utils -   [NLVR2]: iter 26820 Ep: 9.93 loss 0.061 score 0.447 lr 2.79825e-06 
05/02/2021 21:03:05 - INFO - volta.train_utils -   [NLVR2]: iter 26860 Ep: 9.95 loss 0.062 score 0.438 lr 2.79414e-06 
05/02/2021 21:04:05 - INFO - volta.train_utils -   [NLVR2]: iter 26900 Ep: 9.96 loss 0.061 score 0.441 lr 2.79002e-06 
05/02/2021 21:04:53 - INFO - volta.train_utils -   [NLVR2]: iter 26940 Ep: 9.98 loss 0.065 score 0.440 lr 2.78591e-06 
05/02/2021 21:05:50 - INFO - volta.train_utils -   [NLVR2]: iter 26980 Ep: 9.99 loss 0.071 score 0.440 lr 2.78179e-06 
05/02/2021 21:06:02 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  50%|     | 10/20 [10:36:01<10:37:12, 3823.22s/it]05/02/2021 21:23:30 - INFO - volta.train_utils -   Eval task TASK12 on iteration 27000 
05/02/2021 21:23:30 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.782 score 74.506 
05/02/2021 21:23:30 - INFO - __main__ -   ** ** * Saving model * ** ** 
05/02/2021 21:24:05 - INFO - volta.train_utils -   [NLVR2]: iter 27040 Ep: 10.01 loss 0.057 score 0.450 lr 2.77665e-06 
05/02/2021 21:24:50 - INFO - volta.train_utils -   [NLVR2]: iter 27080 Ep: 10.03 loss 0.056 score 0.446 lr 2.7715e-06 
05/02/2021 21:25:44 - INFO - volta.train_utils -   [NLVR2]: iter 27120 Ep: 10.04 loss 0.057 score 0.454 lr 2.76739e-06 
05/02/2021 21:26:40 - INFO - volta.train_utils -   [NLVR2]: iter 27160 Ep: 10.06 loss 0.054 score 0.456 lr 2.76327e-06 
05/02/2021 21:27:34 - INFO - volta.train_utils -   [NLVR2]: iter 27200 Ep: 10.07 loss 0.055 score 0.453 lr 2.75916e-06 
05/02/2021 21:28:18 - INFO - volta.train_utils -   [NLVR2]: iter 27240 Ep: 10.09 loss 0.047 score 0.452 lr 2.75504e-06 
05/02/2021 21:29:11 - INFO - volta.train_utils -   [NLVR2]: iter 27280 Ep: 10.10 loss 0.050 score 0.457 lr 2.75093e-06 
05/02/2021 21:30:00 - INFO - volta.train_utils -   [NLVR2]: iter 27320 Ep: 10.12 loss 0.044 score 0.457 lr 2.74681e-06 
05/02/2021 21:30:57 - INFO - volta.train_utils -   [NLVR2]: iter 27360 Ep: 10.13 loss 0.056 score 0.456 lr 2.7427e-06 
05/02/2021 21:31:48 - INFO - volta.train_utils -   [NLVR2]: iter 27400 Ep: 10.15 loss 0.049 score 0.459 lr 2.73858e-06 
05/02/2021 21:32:52 - INFO - volta.train_utils -   [NLVR2]: iter 27440 Ep: 10.16 loss 0.049 score 0.457 lr 2.73447e-06 
05/02/2021 21:33:43 - INFO - volta.train_utils -   [NLVR2]: iter 27480 Ep: 10.18 loss 0.046 score 0.457 lr 2.73035e-06 
05/02/2021 21:34:40 - INFO - volta.train_utils -   [NLVR2]: iter 27520 Ep: 10.19 loss 0.052 score 0.454 lr 2.72623e-06 
05/02/2021 21:35:33 - INFO - volta.train_utils -   [NLVR2]: iter 27560 Ep: 10.21 loss 0.055 score 0.452 lr 2.72212e-06 
05/02/2021 21:36:27 - INFO - volta.train_utils -   [NLVR2]: iter 27600 Ep: 10.22 loss 0.051 score 0.453 lr 2.718e-06 
05/02/2021 21:37:19 - INFO - volta.train_utils -   [NLVR2]: iter 27640 Ep: 10.24 loss 0.045 score 0.459 lr 2.71389e-06 
05/02/2021 21:38:08 - INFO - volta.train_utils -   [NLVR2]: iter 27680 Ep: 10.25 loss 0.053 score 0.455 lr 2.70977e-06 
05/02/2021 21:39:02 - INFO - volta.train_utils -   [NLVR2]: iter 27720 Ep: 10.27 loss 0.056 score 0.444 lr 2.70566e-06 
05/02/2021 21:39:57 - INFO - volta.train_utils -   [NLVR2]: iter 27760 Ep: 10.28 loss 0.050 score 0.452 lr 2.70154e-06 
05/02/2021 21:41:00 - INFO - volta.train_utils -   [NLVR2]: iter 27800 Ep: 10.30 loss 0.057 score 0.455 lr 2.69743e-06 
05/02/2021 21:42:02 - INFO - volta.train_utils -   [NLVR2]: iter 27840 Ep: 10.31 loss 0.055 score 0.452 lr 2.69331e-06 
05/02/2021 21:43:04 - INFO - volta.train_utils -   [NLVR2]: iter 27880 Ep: 10.33 loss 0.054 score 0.454 lr 2.6892e-06 
05/02/2021 21:44:01 - INFO - volta.train_utils -   [NLVR2]: iter 27920 Ep: 10.34 loss 0.058 score 0.453 lr 2.68508e-06 
05/02/2021 21:44:57 - INFO - volta.train_utils -   [NLVR2]: iter 27960 Ep: 10.36 loss 0.049 score 0.455 lr 2.68097e-06 
05/02/2021 21:45:52 - INFO - volta.train_utils -   [NLVR2]: iter 28000 Ep: 10.37 loss 0.063 score 0.443 lr 2.67685e-06 
05/02/2021 21:46:52 - INFO - volta.train_utils -   [NLVR2]: iter 28040 Ep: 10.39 loss 0.054 score 0.452 lr 2.67274e-06 
05/02/2021 21:47:33 - INFO - volta.train_utils -   [NLVR2]: iter 28080 Ep: 10.40 loss 0.059 score 0.451 lr 2.66862e-06 
05/02/2021 21:48:32 - INFO - volta.train_utils -   [NLVR2]: iter 28120 Ep: 10.41 loss 0.057 score 0.441 lr 2.66451e-06 
05/02/2021 21:49:23 - INFO - volta.train_utils -   [NLVR2]: iter 28160 Ep: 10.43 loss 0.048 score 0.460 lr 2.66039e-06 
05/02/2021 21:50:24 - INFO - volta.train_utils -   [NLVR2]: iter 28200 Ep: 10.44 loss 0.063 score 0.448 lr 2.65628e-06 
05/02/2021 21:51:23 - INFO - volta.train_utils -   [NLVR2]: iter 28240 Ep: 10.46 loss 0.050 score 0.453 lr 2.65216e-06 
05/02/2021 21:52:40 - INFO - volta.train_utils -   [NLVR2]: iter 28280 Ep: 10.47 loss 0.051 score 0.455 lr 2.64805e-06 
05/02/2021 21:53:40 - INFO - volta.train_utils -   [NLVR2]: iter 28320 Ep: 10.49 loss 0.053 score 0.454 lr 2.64393e-06 
05/02/2021 21:54:39 - INFO - volta.train_utils -   [NLVR2]: iter 28360 Ep: 10.50 loss 0.047 score 0.460 lr 2.63981e-06 
05/02/2021 21:55:38 - INFO - volta.train_utils -   [NLVR2]: iter 28400 Ep: 10.52 loss 0.045 score 0.454 lr 2.6357e-06 
05/02/2021 21:56:36 - INFO - volta.train_utils -   [NLVR2]: iter 28440 Ep: 10.53 loss 0.062 score 0.446 lr 2.63158e-06 
05/02/2021 21:57:31 - INFO - volta.train_utils -   [NLVR2]: iter 28480 Ep: 10.55 loss 0.054 score 0.452 lr 2.62747e-06 
05/02/2021 21:58:33 - INFO - volta.train_utils -   [NLVR2]: iter 28520 Ep: 10.56 loss 0.053 score 0.449 lr 2.62335e-06 
05/02/2021 21:59:32 - INFO - volta.train_utils -   [NLVR2]: iter 28560 Ep: 10.58 loss 0.062 score 0.445 lr 2.61924e-06 
05/02/2021 22:00:31 - INFO - volta.train_utils -   [NLVR2]: iter 28600 Ep: 10.59 loss 0.056 score 0.449 lr 2.61512e-06 
05/02/2021 22:01:24 - INFO - volta.train_utils -   [NLVR2]: iter 28640 Ep: 10.61 loss 0.049 score 0.455 lr 2.61101e-06 
05/02/2021 22:02:22 - INFO - volta.train_utils -   [NLVR2]: iter 28680 Ep: 10.62 loss 0.057 score 0.449 lr 2.60689e-06 
05/02/2021 22:03:15 - INFO - volta.train_utils -   [NLVR2]: iter 28720 Ep: 10.64 loss 0.056 score 0.449 lr 2.60278e-06 
05/02/2021 22:04:12 - INFO - volta.train_utils -   [NLVR2]: iter 28760 Ep: 10.65 loss 0.055 score 0.446 lr 2.59866e-06 
05/02/2021 22:05:02 - INFO - volta.train_utils -   [NLVR2]: iter 28800 Ep: 10.67 loss 0.058 score 0.450 lr 2.59455e-06 
05/02/2021 22:06:10 - INFO - volta.train_utils -   [NLVR2]: iter 28840 Ep: 10.68 loss 0.066 score 0.445 lr 2.59043e-06 
05/02/2021 22:07:03 - INFO - volta.train_utils -   [NLVR2]: iter 28880 Ep: 10.70 loss 0.051 score 0.450 lr 2.58632e-06 
05/02/2021 22:08:06 - INFO - volta.train_utils -   [NLVR2]: iter 28920 Ep: 10.71 loss 0.053 score 0.456 lr 2.5822e-06 
05/02/2021 22:08:58 - INFO - volta.train_utils -   [NLVR2]: iter 28960 Ep: 10.73 loss 0.051 score 0.448 lr 2.57809e-06 
05/02/2021 22:09:51 - INFO - volta.train_utils -   [NLVR2]: iter 29000 Ep: 10.74 loss 0.059 score 0.451 lr 2.57397e-06 
05/02/2021 22:10:51 - INFO - volta.train_utils -   [NLVR2]: iter 29040 Ep: 10.76 loss 0.057 score 0.451 lr 2.56986e-06 
05/02/2021 22:11:44 - INFO - volta.train_utils -   [NLVR2]: iter 29080 Ep: 10.77 loss 0.065 score 0.443 lr 2.56574e-06 
05/02/2021 22:12:39 - INFO - volta.train_utils -   [NLVR2]: iter 29120 Ep: 10.79 loss 0.052 score 0.454 lr 2.56163e-06 
05/02/2021 22:13:26 - INFO - volta.train_utils -   [NLVR2]: iter 29160 Ep: 10.80 loss 0.063 score 0.449 lr 2.55751e-06 
05/02/2021 22:14:31 - INFO - volta.train_utils -   [NLVR2]: iter 29200 Ep: 10.81 loss 0.047 score 0.454 lr 2.5534e-06 
05/02/2021 22:15:26 - INFO - volta.train_utils -   [NLVR2]: iter 29240 Ep: 10.83 loss 0.052 score 0.454 lr 2.54928e-06 
05/02/2021 22:16:24 - INFO - volta.train_utils -   [NLVR2]: iter 29280 Ep: 10.84 loss 0.052 score 0.444 lr 2.54516e-06 
05/02/2021 22:17:32 - INFO - volta.train_utils -   [NLVR2]: iter 29320 Ep: 10.86 loss 0.048 score 0.451 lr 2.54105e-06 
05/02/2021 22:18:37 - INFO - volta.train_utils -   [NLVR2]: iter 29360 Ep: 10.87 loss 0.051 score 0.454 lr 2.53693e-06 
05/02/2021 22:19:49 - INFO - volta.train_utils -   [NLVR2]: iter 29400 Ep: 10.89 loss 0.046 score 0.460 lr 2.53282e-06 
05/02/2021 22:20:45 - INFO - volta.train_utils -   [NLVR2]: iter 29440 Ep: 10.90 loss 0.052 score 0.453 lr 2.5287e-06 
05/02/2021 22:21:42 - INFO - volta.train_utils -   [NLVR2]: iter 29480 Ep: 10.92 loss 0.051 score 0.453 lr 2.52459e-06 
05/02/2021 22:22:39 - INFO - volta.train_utils -   [NLVR2]: iter 29520 Ep: 10.93 loss 0.052 score 0.446 lr 2.52047e-06 
05/02/2021 22:23:39 - INFO - volta.train_utils -   [NLVR2]: iter 29560 Ep: 10.95 loss 0.056 score 0.454 lr 2.51636e-06 
05/02/2021 22:24:35 - INFO - volta.train_utils -   [NLVR2]: iter 29600 Ep: 10.96 loss 0.052 score 0.454 lr 2.51224e-06 
05/02/2021 22:25:41 - INFO - volta.train_utils -   [NLVR2]: iter 29640 Ep: 10.98 loss 0.061 score 0.445 lr 2.50813e-06 
05/02/2021 22:26:30 - INFO - volta.train_utils -   [NLVR2]: iter 29680 Ep: 10.99 loss 0.061 score 0.452 lr 2.50401e-06 
05/02/2021 22:26:45 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  55%|    | 11/20 [11:56:44<10:19:22, 4129.21s/it]05/02/2021 22:40:06 - INFO - volta.train_utils -   Eval task TASK12 on iteration 29700 
05/02/2021 22:40:06 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.858 score 74.033 
05/02/2021 22:40:35 - INFO - volta.train_utils -   [NLVR2]: iter 29740 Ep: 11.01 loss 0.047 score 0.461 lr 2.49887e-06 
05/02/2021 22:41:21 - INFO - volta.train_utils -   [NLVR2]: iter 29780 Ep: 11.03 loss 0.038 score 0.460 lr 2.49372e-06 
05/02/2021 22:42:19 - INFO - volta.train_utils -   [NLVR2]: iter 29820 Ep: 11.04 loss 0.041 score 0.465 lr 2.48961e-06 
05/02/2021 22:43:00 - INFO - volta.train_utils -   [NLVR2]: iter 29860 Ep: 11.06 loss 0.049 score 0.459 lr 2.48549e-06 
05/02/2021 22:43:57 - INFO - volta.train_utils -   [NLVR2]: iter 29900 Ep: 11.07 loss 0.043 score 0.459 lr 2.48138e-06 
05/02/2021 22:44:38 - INFO - volta.train_utils -   [NLVR2]: iter 29940 Ep: 11.09 loss 0.042 score 0.459 lr 2.47726e-06 
05/02/2021 22:45:25 - INFO - volta.train_utils -   [NLVR2]: iter 29980 Ep: 11.10 loss 0.047 score 0.458 lr 2.47315e-06 
05/02/2021 22:46:12 - INFO - volta.train_utils -   [NLVR2]: iter 30020 Ep: 11.12 loss 0.047 score 0.456 lr 2.46903e-06 
05/02/2021 22:47:00 - INFO - volta.train_utils -   [NLVR2]: iter 30060 Ep: 11.13 loss 0.046 score 0.458 lr 2.46492e-06 
05/02/2021 22:48:00 - INFO - volta.train_utils -   [NLVR2]: iter 30100 Ep: 11.15 loss 0.040 score 0.460 lr 2.4608e-06 
05/02/2021 22:48:46 - INFO - volta.train_utils -   [NLVR2]: iter 30140 Ep: 11.16 loss 0.050 score 0.459 lr 2.45669e-06 
05/02/2021 22:49:41 - INFO - volta.train_utils -   [NLVR2]: iter 30180 Ep: 11.18 loss 0.051 score 0.454 lr 2.45257e-06 
05/02/2021 22:50:24 - INFO - volta.train_utils -   [NLVR2]: iter 30220 Ep: 11.19 loss 0.047 score 0.457 lr 2.44846e-06 
05/02/2021 22:51:19 - INFO - volta.train_utils -   [NLVR2]: iter 30260 Ep: 11.21 loss 0.049 score 0.454 lr 2.44434e-06 
05/02/2021 22:52:01 - INFO - volta.train_utils -   [NLVR2]: iter 30300 Ep: 11.22 loss 0.050 score 0.457 lr 2.44023e-06 
05/02/2021 22:52:55 - INFO - volta.train_utils -   [NLVR2]: iter 30340 Ep: 11.24 loss 0.055 score 0.449 lr 2.43611e-06 
05/02/2021 22:53:35 - INFO - volta.train_utils -   [NLVR2]: iter 30380 Ep: 11.25 loss 0.046 score 0.456 lr 2.432e-06 
05/02/2021 22:54:29 - INFO - volta.train_utils -   [NLVR2]: iter 30420 Ep: 11.27 loss 0.048 score 0.456 lr 2.42788e-06 
05/02/2021 22:55:15 - INFO - volta.train_utils -   [NLVR2]: iter 30460 Ep: 11.28 loss 0.041 score 0.459 lr 2.42377e-06 
05/02/2021 22:56:08 - INFO - volta.train_utils -   [NLVR2]: iter 30500 Ep: 11.30 loss 0.043 score 0.454 lr 2.41965e-06 
05/02/2021 22:56:56 - INFO - volta.train_utils -   [NLVR2]: iter 30540 Ep: 11.31 loss 0.042 score 0.462 lr 2.41553e-06 
05/02/2021 22:57:59 - INFO - volta.train_utils -   [NLVR2]: iter 30580 Ep: 11.33 loss 0.044 score 0.458 lr 2.41142e-06 
05/02/2021 22:58:47 - INFO - volta.train_utils -   [NLVR2]: iter 30620 Ep: 11.34 loss 0.050 score 0.464 lr 2.4073e-06 
05/02/2021 22:59:45 - INFO - volta.train_utils -   [NLVR2]: iter 30660 Ep: 11.36 loss 0.045 score 0.464 lr 2.40319e-06 
05/02/2021 23:00:27 - INFO - volta.train_utils -   [NLVR2]: iter 30700 Ep: 11.37 loss 0.046 score 0.459 lr 2.39907e-06 
05/02/2021 23:01:26 - INFO - volta.train_utils -   [NLVR2]: iter 30740 Ep: 11.39 loss 0.056 score 0.451 lr 2.39496e-06 
05/02/2021 23:02:13 - INFO - volta.train_utils -   [NLVR2]: iter 30780 Ep: 11.40 loss 0.049 score 0.454 lr 2.39084e-06 
05/02/2021 23:03:07 - INFO - volta.train_utils -   [NLVR2]: iter 30820 Ep: 11.41 loss 0.048 score 0.454 lr 2.38673e-06 
05/02/2021 23:03:52 - INFO - volta.train_utils -   [NLVR2]: iter 30860 Ep: 11.43 loss 0.045 score 0.460 lr 2.38261e-06 
05/02/2021 23:04:52 - INFO - volta.train_utils -   [NLVR2]: iter 30900 Ep: 11.44 loss 0.045 score 0.460 lr 2.3785e-06 
05/02/2021 23:05:39 - INFO - volta.train_utils -   [NLVR2]: iter 30940 Ep: 11.46 loss 0.050 score 0.461 lr 2.37438e-06 
05/02/2021 23:06:35 - INFO - volta.train_utils -   [NLVR2]: iter 30980 Ep: 11.47 loss 0.045 score 0.455 lr 2.37027e-06 
05/02/2021 23:07:23 - INFO - volta.train_utils -   [NLVR2]: iter 31020 Ep: 11.49 loss 0.046 score 0.455 lr 2.36615e-06 
05/02/2021 23:08:28 - INFO - volta.train_utils -   [NLVR2]: iter 31060 Ep: 11.50 loss 0.055 score 0.455 lr 2.36204e-06 
05/02/2021 23:09:15 - INFO - volta.train_utils -   [NLVR2]: iter 31100 Ep: 11.52 loss 0.041 score 0.458 lr 2.35792e-06 
05/02/2021 23:10:20 - INFO - volta.train_utils -   [NLVR2]: iter 31140 Ep: 11.53 loss 0.042 score 0.466 lr 2.35381e-06 
05/02/2021 23:11:08 - INFO - volta.train_utils -   [NLVR2]: iter 31180 Ep: 11.55 loss 0.048 score 0.452 lr 2.34969e-06 
05/02/2021 23:12:04 - INFO - volta.train_utils -   [NLVR2]: iter 31220 Ep: 11.56 loss 0.061 score 0.452 lr 2.34558e-06 
05/02/2021 23:12:50 - INFO - volta.train_utils -   [NLVR2]: iter 31260 Ep: 11.58 loss 0.052 score 0.454 lr 2.34146e-06 
05/02/2021 23:13:44 - INFO - volta.train_utils -   [NLVR2]: iter 31300 Ep: 11.59 loss 0.055 score 0.450 lr 2.33735e-06 
05/02/2021 23:14:27 - INFO - volta.train_utils -   [NLVR2]: iter 31340 Ep: 11.61 loss 0.053 score 0.460 lr 2.33323e-06 
05/02/2021 23:15:21 - INFO - volta.train_utils -   [NLVR2]: iter 31380 Ep: 11.62 loss 0.040 score 0.462 lr 2.32912e-06 
05/02/2021 23:16:10 - INFO - volta.train_utils -   [NLVR2]: iter 31420 Ep: 11.64 loss 0.042 score 0.463 lr 2.325e-06 
05/02/2021 23:17:16 - INFO - volta.train_utils -   [NLVR2]: iter 31460 Ep: 11.65 loss 0.043 score 0.454 lr 2.32088e-06 
05/02/2021 23:18:00 - INFO - volta.train_utils -   [NLVR2]: iter 31500 Ep: 11.67 loss 0.046 score 0.463 lr 2.31677e-06 
05/02/2021 23:18:58 - INFO - volta.train_utils -   [NLVR2]: iter 31540 Ep: 11.68 loss 0.047 score 0.457 lr 2.31265e-06 
05/02/2021 23:19:49 - INFO - volta.train_utils -   [NLVR2]: iter 31580 Ep: 11.70 loss 0.048 score 0.458 lr 2.30854e-06 
05/02/2021 23:20:45 - INFO - volta.train_utils -   [NLVR2]: iter 31620 Ep: 11.71 loss 0.047 score 0.466 lr 2.30442e-06 
05/02/2021 23:21:38 - INFO - volta.train_utils -   [NLVR2]: iter 31660 Ep: 11.73 loss 0.056 score 0.451 lr 2.30031e-06 
05/02/2021 23:22:32 - INFO - volta.train_utils -   [NLVR2]: iter 31700 Ep: 11.74 loss 0.050 score 0.461 lr 2.29619e-06 
05/02/2021 23:23:22 - INFO - volta.train_utils -   [NLVR2]: iter 31740 Ep: 11.76 loss 0.050 score 0.456 lr 2.29208e-06 
05/02/2021 23:24:17 - INFO - volta.train_utils -   [NLVR2]: iter 31780 Ep: 11.77 loss 0.050 score 0.452 lr 2.28796e-06 
05/02/2021 23:25:02 - INFO - volta.train_utils -   [NLVR2]: iter 31820 Ep: 11.79 loss 0.049 score 0.459 lr 2.28385e-06 
05/02/2021 23:25:54 - INFO - volta.train_utils -   [NLVR2]: iter 31860 Ep: 11.80 loss 0.056 score 0.452 lr 2.27973e-06 
05/02/2021 23:26:41 - INFO - volta.train_utils -   [NLVR2]: iter 31900 Ep: 11.81 loss 0.054 score 0.461 lr 2.27562e-06 
05/02/2021 23:27:46 - INFO - volta.train_utils -   [NLVR2]: iter 31940 Ep: 11.83 loss 0.054 score 0.449 lr 2.2715e-06 
05/02/2021 23:28:34 - INFO - volta.train_utils -   [NLVR2]: iter 31980 Ep: 11.84 loss 0.047 score 0.461 lr 2.26739e-06 
05/02/2021 23:29:25 - INFO - volta.train_utils -   [NLVR2]: iter 32020 Ep: 11.86 loss 0.046 score 0.454 lr 2.26327e-06 
05/02/2021 23:30:11 - INFO - volta.train_utils -   [NLVR2]: iter 32060 Ep: 11.87 loss 0.048 score 0.457 lr 2.25916e-06 
05/02/2021 23:31:17 - INFO - volta.train_utils -   [NLVR2]: iter 32100 Ep: 11.89 loss 0.050 score 0.456 lr 2.25504e-06 
05/02/2021 23:32:00 - INFO - volta.train_utils -   [NLVR2]: iter 32140 Ep: 11.90 loss 0.051 score 0.457 lr 2.25093e-06 
05/02/2021 23:32:48 - INFO - volta.train_utils -   [NLVR2]: iter 32180 Ep: 11.92 loss 0.039 score 0.459 lr 2.24681e-06 
05/02/2021 23:33:34 - INFO - volta.train_utils -   [NLVR2]: iter 32220 Ep: 11.93 loss 0.049 score 0.457 lr 2.2427e-06 
05/02/2021 23:34:32 - INFO - volta.train_utils -   [NLVR2]: iter 32260 Ep: 11.95 loss 0.047 score 0.456 lr 2.23858e-06 
05/02/2021 23:35:13 - INFO - volta.train_utils -   [NLVR2]: iter 32300 Ep: 11.96 loss 0.060 score 0.445 lr 2.23447e-06 
05/02/2021 23:36:05 - INFO - volta.train_utils -   [NLVR2]: iter 32340 Ep: 11.98 loss 0.045 score 0.460 lr 2.23035e-06 
05/02/2021 23:36:49 - INFO - volta.train_utils -   [NLVR2]: iter 32380 Ep: 11.99 loss 0.048 score 0.454 lr 2.22623e-06 
05/02/2021 23:37:04 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  60%|    | 12/20 [13:07:04<9:14:13, 4156.63s/it] 05/02/2021 23:53:57 - INFO - volta.train_utils -   Eval task TASK12 on iteration 32400 
05/02/2021 23:53:57 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.929 score 73.475 
05/02/2021 23:54:21 - INFO - volta.train_utils -   [NLVR2]: iter 32440 Ep: 12.01 loss 0.040 score 0.466 lr 2.22109e-06 
05/02/2021 23:55:06 - INFO - volta.train_utils -   [NLVR2]: iter 32480 Ep: 12.03 loss 0.048 score 0.462 lr 2.21595e-06 
05/02/2021 23:56:00 - INFO - volta.train_utils -   [NLVR2]: iter 32520 Ep: 12.04 loss 0.036 score 0.466 lr 2.21183e-06 
05/02/2021 23:56:52 - INFO - volta.train_utils -   [NLVR2]: iter 32560 Ep: 12.06 loss 0.047 score 0.466 lr 2.20772e-06 
05/02/2021 23:57:48 - INFO - volta.train_utils -   [NLVR2]: iter 32600 Ep: 12.07 loss 0.042 score 0.464 lr 2.2036e-06 
05/02/2021 23:58:43 - INFO - volta.train_utils -   [NLVR2]: iter 32640 Ep: 12.09 loss 0.043 score 0.462 lr 2.19949e-06 
05/02/2021 23:59:38 - INFO - volta.train_utils -   [NLVR2]: iter 32680 Ep: 12.10 loss 0.042 score 0.463 lr 2.19537e-06 
05/03/2021 00:00:41 - INFO - volta.train_utils -   [NLVR2]: iter 32720 Ep: 12.12 loss 0.050 score 0.463 lr 2.19126e-06 
05/03/2021 00:01:38 - INFO - volta.train_utils -   [NLVR2]: iter 32760 Ep: 12.13 loss 0.042 score 0.465 lr 2.18714e-06 
05/03/2021 00:02:52 - INFO - volta.train_utils -   [NLVR2]: iter 32800 Ep: 12.15 loss 0.042 score 0.464 lr 2.18302e-06 
05/03/2021 00:03:58 - INFO - volta.train_utils -   [NLVR2]: iter 32840 Ep: 12.16 loss 0.044 score 0.466 lr 2.17891e-06 
05/03/2021 00:05:14 - INFO - volta.train_utils -   [NLVR2]: iter 32880 Ep: 12.18 loss 0.037 score 0.466 lr 2.17479e-06 
05/03/2021 00:06:06 - INFO - volta.train_utils -   [NLVR2]: iter 32920 Ep: 12.19 loss 0.046 score 0.460 lr 2.17068e-06 
05/03/2021 00:06:59 - INFO - volta.train_utils -   [NLVR2]: iter 32960 Ep: 12.21 loss 0.049 score 0.461 lr 2.16656e-06 
05/03/2021 00:07:53 - INFO - volta.train_utils -   [NLVR2]: iter 33000 Ep: 12.22 loss 0.043 score 0.463 lr 2.16245e-06 
05/03/2021 00:08:40 - INFO - volta.train_utils -   [NLVR2]: iter 33040 Ep: 12.24 loss 0.053 score 0.459 lr 2.15833e-06 
05/03/2021 00:09:38 - INFO - volta.train_utils -   [NLVR2]: iter 33080 Ep: 12.25 loss 0.047 score 0.458 lr 2.15422e-06 
05/03/2021 00:10:26 - INFO - volta.train_utils -   [NLVR2]: iter 33120 Ep: 12.27 loss 0.050 score 0.468 lr 2.1501e-06 
05/03/2021 00:11:28 - INFO - volta.train_utils -   [NLVR2]: iter 33160 Ep: 12.28 loss 0.050 score 0.453 lr 2.14599e-06 
05/03/2021 00:12:18 - INFO - volta.train_utils -   [NLVR2]: iter 33200 Ep: 12.30 loss 0.045 score 0.458 lr 2.14187e-06 
05/03/2021 00:13:12 - INFO - volta.train_utils -   [NLVR2]: iter 33240 Ep: 12.31 loss 0.049 score 0.460 lr 2.13776e-06 
05/03/2021 00:14:01 - INFO - volta.train_utils -   [NLVR2]: iter 33280 Ep: 12.33 loss 0.040 score 0.465 lr 2.13364e-06 
05/03/2021 00:15:04 - INFO - volta.train_utils -   [NLVR2]: iter 33320 Ep: 12.34 loss 0.048 score 0.462 lr 2.12953e-06 
05/03/2021 00:15:59 - INFO - volta.train_utils -   [NLVR2]: iter 33360 Ep: 12.36 loss 0.044 score 0.463 lr 2.12541e-06 
05/03/2021 00:16:57 - INFO - volta.train_utils -   [NLVR2]: iter 33400 Ep: 12.37 loss 0.041 score 0.465 lr 2.1213e-06 
05/03/2021 00:17:42 - INFO - volta.train_utils -   [NLVR2]: iter 33440 Ep: 12.39 loss 0.038 score 0.467 lr 2.11718e-06 
05/03/2021 00:18:28 - INFO - volta.train_utils -   [NLVR2]: iter 33480 Ep: 12.40 loss 0.048 score 0.456 lr 2.11307e-06 
05/03/2021 00:19:17 - INFO - volta.train_utils -   [NLVR2]: iter 33520 Ep: 12.41 loss 0.035 score 0.469 lr 2.10895e-06 
05/03/2021 00:20:06 - INFO - volta.train_utils -   [NLVR2]: iter 33560 Ep: 12.43 loss 0.031 score 0.472 lr 2.10484e-06 
05/03/2021 00:20:54 - INFO - volta.train_utils -   [NLVR2]: iter 33600 Ep: 12.44 loss 0.051 score 0.459 lr 2.10072e-06 
05/03/2021 00:21:49 - INFO - volta.train_utils -   [NLVR2]: iter 33640 Ep: 12.46 loss 0.043 score 0.463 lr 2.0966e-06 
05/03/2021 00:22:29 - INFO - volta.train_utils -   [NLVR2]: iter 33680 Ep: 12.47 loss 0.041 score 0.458 lr 2.09249e-06 
05/03/2021 00:23:26 - INFO - volta.train_utils -   [NLVR2]: iter 33720 Ep: 12.49 loss 0.034 score 0.468 lr 2.08837e-06 
05/03/2021 00:24:12 - INFO - volta.train_utils -   [NLVR2]: iter 33760 Ep: 12.50 loss 0.040 score 0.463 lr 2.08426e-06 
05/03/2021 00:25:07 - INFO - volta.train_utils -   [NLVR2]: iter 33800 Ep: 12.52 loss 0.033 score 0.468 lr 2.08014e-06 
05/03/2021 00:25:56 - INFO - volta.train_utils -   [NLVR2]: iter 33840 Ep: 12.53 loss 0.041 score 0.461 lr 2.07603e-06 
05/03/2021 00:26:55 - INFO - volta.train_utils -   [NLVR2]: iter 33880 Ep: 12.55 loss 0.041 score 0.462 lr 2.07191e-06 
05/03/2021 00:27:44 - INFO - volta.train_utils -   [NLVR2]: iter 33920 Ep: 12.56 loss 0.046 score 0.460 lr 2.0678e-06 
05/03/2021 00:28:45 - INFO - volta.train_utils -   [NLVR2]: iter 33960 Ep: 12.58 loss 0.038 score 0.455 lr 2.06368e-06 
05/03/2021 00:29:35 - INFO - volta.train_utils -   [NLVR2]: iter 34000 Ep: 12.59 loss 0.039 score 0.463 lr 2.05957e-06 
05/03/2021 00:30:27 - INFO - volta.train_utils -   [NLVR2]: iter 34040 Ep: 12.61 loss 0.040 score 0.464 lr 2.05545e-06 
05/03/2021 00:31:14 - INFO - volta.train_utils -   [NLVR2]: iter 34080 Ep: 12.62 loss 0.038 score 0.465 lr 2.05134e-06 
05/03/2021 00:32:08 - INFO - volta.train_utils -   [NLVR2]: iter 34120 Ep: 12.64 loss 0.036 score 0.466 lr 2.04722e-06 
05/03/2021 00:32:50 - INFO - volta.train_utils -   [NLVR2]: iter 34160 Ep: 12.65 loss 0.042 score 0.463 lr 2.04311e-06 
05/03/2021 00:33:59 - INFO - volta.train_utils -   [NLVR2]: iter 34200 Ep: 12.67 loss 0.047 score 0.464 lr 2.03899e-06 
05/03/2021 00:34:46 - INFO - volta.train_utils -   [NLVR2]: iter 34240 Ep: 12.68 loss 0.044 score 0.465 lr 2.03488e-06 
05/03/2021 00:35:51 - INFO - volta.train_utils -   [NLVR2]: iter 34280 Ep: 12.70 loss 0.037 score 0.469 lr 2.03076e-06 
05/03/2021 00:36:42 - INFO - volta.train_utils -   [NLVR2]: iter 34320 Ep: 12.71 loss 0.041 score 0.467 lr 2.02665e-06 
05/03/2021 00:37:39 - INFO - volta.train_utils -   [NLVR2]: iter 34360 Ep: 12.73 loss 0.043 score 0.461 lr 2.02253e-06 
05/03/2021 00:38:30 - INFO - volta.train_utils -   [NLVR2]: iter 34400 Ep: 12.74 loss 0.046 score 0.464 lr 2.01842e-06 
05/03/2021 00:39:31 - INFO - volta.train_utils -   [NLVR2]: iter 34440 Ep: 12.76 loss 0.053 score 0.459 lr 2.0143e-06 
05/03/2021 00:40:22 - INFO - volta.train_utils -   [NLVR2]: iter 34480 Ep: 12.77 loss 0.038 score 0.460 lr 2.01019e-06 
05/03/2021 00:41:27 - INFO - volta.train_utils -   [NLVR2]: iter 34520 Ep: 12.79 loss 0.037 score 0.462 lr 2.00607e-06 
05/03/2021 00:42:17 - INFO - volta.train_utils -   [NLVR2]: iter 34560 Ep: 12.80 loss 0.042 score 0.456 lr 2.00195e-06 
05/03/2021 00:43:20 - INFO - volta.train_utils -   [NLVR2]: iter 34600 Ep: 12.81 loss 0.046 score 0.462 lr 1.99784e-06 
05/03/2021 00:44:01 - INFO - volta.train_utils -   [NLVR2]: iter 34640 Ep: 12.83 loss 0.052 score 0.455 lr 1.99372e-06 
05/03/2021 00:45:00 - INFO - volta.train_utils -   [NLVR2]: iter 34680 Ep: 12.84 loss 0.049 score 0.459 lr 1.98961e-06 
05/03/2021 00:45:54 - INFO - volta.train_utils -   [NLVR2]: iter 34720 Ep: 12.86 loss 0.047 score 0.459 lr 1.98549e-06 
05/03/2021 00:46:54 - INFO - volta.train_utils -   [NLVR2]: iter 34760 Ep: 12.87 loss 0.052 score 0.461 lr 1.98138e-06 
05/03/2021 00:47:39 - INFO - volta.train_utils -   [NLVR2]: iter 34800 Ep: 12.89 loss 0.050 score 0.461 lr 1.97726e-06 
05/03/2021 00:48:40 - INFO - volta.train_utils -   [NLVR2]: iter 34840 Ep: 12.90 loss 0.048 score 0.462 lr 1.97315e-06 
05/03/2021 00:49:32 - INFO - volta.train_utils -   [NLVR2]: iter 34880 Ep: 12.92 loss 0.038 score 0.470 lr 1.96903e-06 
05/03/2021 00:50:43 - INFO - volta.train_utils -   [NLVR2]: iter 34920 Ep: 12.93 loss 0.044 score 0.459 lr 1.96492e-06 
05/03/2021 00:51:44 - INFO - volta.train_utils -   [NLVR2]: iter 34960 Ep: 12.95 loss 0.051 score 0.451 lr 1.9608e-06 
05/03/2021 00:53:11 - INFO - volta.train_utils -   [NLVR2]: iter 35000 Ep: 12.96 loss 0.044 score 0.464 lr 1.95669e-06 
05/03/2021 00:54:03 - INFO - volta.train_utils -   [NLVR2]: iter 35040 Ep: 12.98 loss 0.050 score 0.462 lr 1.95257e-06 
05/03/2021 00:55:00 - INFO - volta.train_utils -   [NLVR2]: iter 35080 Ep: 12.99 loss 0.041 score 0.460 lr 1.94846e-06 
05/03/2021 00:55:14 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  65%|   | 13/20 [14:25:13<8:23:32, 4316.13s/it]05/03/2021 01:13:15 - INFO - volta.train_utils -   Eval task TASK12 on iteration 35100 
05/03/2021 01:13:15 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.934 score 74.062 
05/03/2021 01:13:39 - INFO - volta.train_utils -   [NLVR2]: iter 35140 Ep: 13.01 loss 0.034 score 0.470 lr 1.94331e-06 
05/03/2021 01:14:39 - INFO - volta.train_utils -   [NLVR2]: iter 35180 Ep: 13.03 loss 0.042 score 0.468 lr 1.93817e-06 
05/03/2021 01:15:35 - INFO - volta.train_utils -   [NLVR2]: iter 35220 Ep: 13.04 loss 0.036 score 0.464 lr 1.93405e-06 
05/03/2021 01:16:36 - INFO - volta.train_utils -   [NLVR2]: iter 35260 Ep: 13.06 loss 0.039 score 0.466 lr 1.92994e-06 
05/03/2021 01:17:38 - INFO - volta.train_utils -   [NLVR2]: iter 35300 Ep: 13.07 loss 0.033 score 0.465 lr 1.92582e-06 
05/03/2021 01:18:37 - INFO - volta.train_utils -   [NLVR2]: iter 35340 Ep: 13.09 loss 0.029 score 0.475 lr 1.92171e-06 
05/03/2021 01:19:30 - INFO - volta.train_utils -   [NLVR2]: iter 35380 Ep: 13.10 loss 0.040 score 0.471 lr 1.91759e-06 
05/03/2021 01:20:24 - INFO - volta.train_utils -   [NLVR2]: iter 35420 Ep: 13.12 loss 0.035 score 0.469 lr 1.91348e-06 
05/03/2021 01:21:30 - INFO - volta.train_utils -   [NLVR2]: iter 35460 Ep: 13.13 loss 0.037 score 0.468 lr 1.90936e-06 
05/03/2021 01:22:26 - INFO - volta.train_utils -   [NLVR2]: iter 35500 Ep: 13.15 loss 0.039 score 0.473 lr 1.90525e-06 
05/03/2021 01:23:25 - INFO - volta.train_utils -   [NLVR2]: iter 35540 Ep: 13.16 loss 0.042 score 0.470 lr 1.90113e-06 
05/03/2021 01:24:22 - INFO - volta.train_utils -   [NLVR2]: iter 35580 Ep: 13.18 loss 0.038 score 0.466 lr 1.89702e-06 
05/03/2021 01:25:30 - INFO - volta.train_utils -   [NLVR2]: iter 35620 Ep: 13.19 loss 0.036 score 0.467 lr 1.8929e-06 
05/03/2021 01:26:24 - INFO - volta.train_utils -   [NLVR2]: iter 35660 Ep: 13.21 loss 0.043 score 0.463 lr 1.88879e-06 
05/03/2021 01:27:27 - INFO - volta.train_utils -   [NLVR2]: iter 35700 Ep: 13.22 loss 0.034 score 0.467 lr 1.88467e-06 
05/03/2021 01:28:21 - INFO - volta.train_utils -   [NLVR2]: iter 35740 Ep: 13.24 loss 0.039 score 0.465 lr 1.88056e-06 
05/03/2021 01:29:18 - INFO - volta.train_utils -   [NLVR2]: iter 35780 Ep: 13.25 loss 0.038 score 0.471 lr 1.87644e-06 
05/03/2021 01:30:07 - INFO - volta.train_utils -   [NLVR2]: iter 35820 Ep: 13.27 loss 0.039 score 0.463 lr 1.87233e-06 
05/03/2021 01:31:08 - INFO - volta.train_utils -   [NLVR2]: iter 35860 Ep: 13.28 loss 0.046 score 0.464 lr 1.86821e-06 
05/03/2021 01:32:02 - INFO - volta.train_utils -   [NLVR2]: iter 35900 Ep: 13.30 loss 0.039 score 0.469 lr 1.86409e-06 
05/03/2021 01:32:58 - INFO - volta.train_utils -   [NLVR2]: iter 35940 Ep: 13.31 loss 0.035 score 0.473 lr 1.85998e-06 
05/03/2021 01:33:46 - INFO - volta.train_utils -   [NLVR2]: iter 35980 Ep: 13.33 loss 0.035 score 0.468 lr 1.85586e-06 
05/03/2021 01:34:47 - INFO - volta.train_utils -   [NLVR2]: iter 36020 Ep: 13.34 loss 0.034 score 0.470 lr 1.85175e-06 
05/03/2021 01:35:40 - INFO - volta.train_utils -   [NLVR2]: iter 36060 Ep: 13.36 loss 0.035 score 0.463 lr 1.84763e-06 
05/03/2021 01:36:47 - INFO - volta.train_utils -   [NLVR2]: iter 36100 Ep: 13.37 loss 0.039 score 0.462 lr 1.84352e-06 
05/03/2021 01:37:36 - INFO - volta.train_utils -   [NLVR2]: iter 36140 Ep: 13.39 loss 0.035 score 0.469 lr 1.8394e-06 
05/03/2021 01:38:45 - INFO - volta.train_utils -   [NLVR2]: iter 36180 Ep: 13.40 loss 0.040 score 0.468 lr 1.83529e-06 
05/03/2021 01:39:30 - INFO - volta.train_utils -   [NLVR2]: iter 36220 Ep: 13.41 loss 0.036 score 0.468 lr 1.83117e-06 
05/03/2021 01:40:41 - INFO - volta.train_utils -   [NLVR2]: iter 36260 Ep: 13.43 loss 0.036 score 0.461 lr 1.82706e-06 
05/03/2021 01:41:39 - INFO - volta.train_utils -   [NLVR2]: iter 36300 Ep: 13.44 loss 0.044 score 0.467 lr 1.82294e-06 
05/03/2021 01:42:50 - INFO - volta.train_utils -   [NLVR2]: iter 36340 Ep: 13.46 loss 0.041 score 0.466 lr 1.81883e-06 
05/03/2021 01:43:40 - INFO - volta.train_utils -   [NLVR2]: iter 36380 Ep: 13.47 loss 0.034 score 0.468 lr 1.81471e-06 
05/03/2021 01:44:42 - INFO - volta.train_utils -   [NLVR2]: iter 36420 Ep: 13.49 loss 0.042 score 0.464 lr 1.8106e-06 
05/03/2021 01:45:23 - INFO - volta.train_utils -   [NLVR2]: iter 36460 Ep: 13.50 loss 0.039 score 0.470 lr 1.80648e-06 
05/03/2021 01:46:18 - INFO - volta.train_utils -   [NLVR2]: iter 36500 Ep: 13.52 loss 0.047 score 0.463 lr 1.80237e-06 
05/03/2021 01:47:01 - INFO - volta.train_utils -   [NLVR2]: iter 36540 Ep: 13.53 loss 0.037 score 0.468 lr 1.79825e-06 
05/03/2021 01:47:51 - INFO - volta.train_utils -   [NLVR2]: iter 36580 Ep: 13.55 loss 0.035 score 0.465 lr 1.79414e-06 
05/03/2021 01:48:34 - INFO - volta.train_utils -   [NLVR2]: iter 36620 Ep: 13.56 loss 0.035 score 0.470 lr 1.79002e-06 
05/03/2021 01:49:33 - INFO - volta.train_utils -   [NLVR2]: iter 36660 Ep: 13.58 loss 0.032 score 0.468 lr 1.78591e-06 
05/03/2021 01:50:14 - INFO - volta.train_utils -   [NLVR2]: iter 36700 Ep: 13.59 loss 0.031 score 0.467 lr 1.78179e-06 
05/03/2021 01:51:05 - INFO - volta.train_utils -   [NLVR2]: iter 36740 Ep: 13.61 loss 0.046 score 0.468 lr 1.77767e-06 
05/03/2021 01:51:53 - INFO - volta.train_utils -   [NLVR2]: iter 36780 Ep: 13.62 loss 0.044 score 0.464 lr 1.77356e-06 
05/03/2021 01:52:57 - INFO - volta.train_utils -   [NLVR2]: iter 36820 Ep: 13.64 loss 0.041 score 0.462 lr 1.76944e-06 
05/03/2021 01:53:46 - INFO - volta.train_utils -   [NLVR2]: iter 36860 Ep: 13.65 loss 0.047 score 0.459 lr 1.76533e-06 
05/03/2021 01:54:45 - INFO - volta.train_utils -   [NLVR2]: iter 36900 Ep: 13.67 loss 0.038 score 0.464 lr 1.76121e-06 
05/03/2021 01:55:38 - INFO - volta.train_utils -   [NLVR2]: iter 36940 Ep: 13.68 loss 0.044 score 0.466 lr 1.7571e-06 
05/03/2021 01:56:40 - INFO - volta.train_utils -   [NLVR2]: iter 36980 Ep: 13.70 loss 0.038 score 0.473 lr 1.75298e-06 
05/03/2021 01:57:33 - INFO - volta.train_utils -   [NLVR2]: iter 37020 Ep: 13.71 loss 0.037 score 0.468 lr 1.74887e-06 
05/03/2021 01:58:34 - INFO - volta.train_utils -   [NLVR2]: iter 37060 Ep: 13.73 loss 0.040 score 0.471 lr 1.74475e-06 
05/03/2021 01:59:20 - INFO - volta.train_utils -   [NLVR2]: iter 37100 Ep: 13.74 loss 0.039 score 0.470 lr 1.74064e-06 
05/03/2021 02:00:13 - INFO - volta.train_utils -   [NLVR2]: iter 37140 Ep: 13.76 loss 0.044 score 0.466 lr 1.73652e-06 
05/03/2021 02:00:53 - INFO - volta.train_utils -   [NLVR2]: iter 37180 Ep: 13.77 loss 0.034 score 0.470 lr 1.73241e-06 
05/03/2021 02:01:49 - INFO - volta.train_utils -   [NLVR2]: iter 37220 Ep: 13.79 loss 0.033 score 0.468 lr 1.72829e-06 
05/03/2021 02:02:31 - INFO - volta.train_utils -   [NLVR2]: iter 37260 Ep: 13.80 loss 0.040 score 0.459 lr 1.72418e-06 
05/03/2021 02:03:24 - INFO - volta.train_utils -   [NLVR2]: iter 37300 Ep: 13.81 loss 0.039 score 0.466 lr 1.72006e-06 
05/03/2021 02:04:14 - INFO - volta.train_utils -   [NLVR2]: iter 37340 Ep: 13.83 loss 0.044 score 0.464 lr 1.71595e-06 
05/03/2021 02:05:16 - INFO - volta.train_utils -   [NLVR2]: iter 37380 Ep: 13.84 loss 0.036 score 0.466 lr 1.71183e-06 
05/03/2021 02:06:06 - INFO - volta.train_utils -   [NLVR2]: iter 37420 Ep: 13.86 loss 0.036 score 0.468 lr 1.70772e-06 
05/03/2021 02:07:06 - INFO - volta.train_utils -   [NLVR2]: iter 37460 Ep: 13.87 loss 0.045 score 0.467 lr 1.7036e-06 
05/03/2021 02:07:59 - INFO - volta.train_utils -   [NLVR2]: iter 37500 Ep: 13.89 loss 0.036 score 0.464 lr 1.69949e-06 
05/03/2021 02:08:57 - INFO - volta.train_utils -   [NLVR2]: iter 37540 Ep: 13.90 loss 0.038 score 0.472 lr 1.69537e-06 
05/03/2021 02:09:45 - INFO - volta.train_utils -   [NLVR2]: iter 37580 Ep: 13.92 loss 0.036 score 0.465 lr 1.69126e-06 
05/03/2021 02:10:44 - INFO - volta.train_utils -   [NLVR2]: iter 37620 Ep: 13.93 loss 0.040 score 0.467 lr 1.68714e-06 
05/03/2021 02:11:32 - INFO - volta.train_utils -   [NLVR2]: iter 37660 Ep: 13.95 loss 0.038 score 0.465 lr 1.68302e-06 
05/03/2021 02:12:30 - INFO - volta.train_utils -   [NLVR2]: iter 37700 Ep: 13.96 loss 0.041 score 0.462 lr 1.67891e-06 
05/03/2021 02:13:12 - INFO - volta.train_utils -   [NLVR2]: iter 37740 Ep: 13.98 loss 0.044 score 0.460 lr 1.67479e-06 
05/03/2021 02:14:01 - INFO - volta.train_utils -   [NLVR2]: iter 37780 Ep: 13.99 loss 0.036 score 0.463 lr 1.67068e-06 
05/03/2021 02:14:18 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  70%|   | 14/20 [15:44:16<7:24:25, 4444.29s/it]05/03/2021 02:33:17 - INFO - volta.train_utils -   Eval task TASK12 on iteration 37800 
05/03/2021 02:33:17 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.012 score 74.277 
05/03/2021 02:33:40 - INFO - volta.train_utils -   [NLVR2]: iter 37840 Ep: 14.01 loss 0.040 score 0.469 lr 1.66553e-06 
05/03/2021 02:34:24 - INFO - volta.train_utils -   [NLVR2]: iter 37880 Ep: 14.03 loss 0.036 score 0.469 lr 1.66039e-06 
05/03/2021 02:35:15 - INFO - volta.train_utils -   [NLVR2]: iter 37920 Ep: 14.04 loss 0.037 score 0.467 lr 1.65628e-06 
05/03/2021 02:36:03 - INFO - volta.train_utils -   [NLVR2]: iter 37960 Ep: 14.06 loss 0.035 score 0.466 lr 1.65216e-06 
05/03/2021 02:37:01 - INFO - volta.train_utils -   [NLVR2]: iter 38000 Ep: 14.07 loss 0.032 score 0.471 lr 1.64805e-06 
05/03/2021 02:37:53 - INFO - volta.train_utils -   [NLVR2]: iter 38040 Ep: 14.09 loss 0.027 score 0.476 lr 1.64393e-06 
05/03/2021 02:38:56 - INFO - volta.train_utils -   [NLVR2]: iter 38080 Ep: 14.10 loss 0.038 score 0.468 lr 1.63981e-06 
05/03/2021 02:40:00 - INFO - volta.train_utils -   [NLVR2]: iter 38120 Ep: 14.12 loss 0.037 score 0.470 lr 1.6357e-06 
05/03/2021 02:41:12 - INFO - volta.train_utils -   [NLVR2]: iter 38160 Ep: 14.13 loss 0.027 score 0.475 lr 1.63158e-06 
05/03/2021 02:42:24 - INFO - volta.train_utils -   [NLVR2]: iter 38200 Ep: 14.15 loss 0.035 score 0.469 lr 1.62747e-06 
05/03/2021 02:43:15 - INFO - volta.train_utils -   [NLVR2]: iter 38240 Ep: 14.16 loss 0.029 score 0.469 lr 1.62335e-06 
05/03/2021 02:44:15 - INFO - volta.train_utils -   [NLVR2]: iter 38280 Ep: 14.18 loss 0.033 score 0.468 lr 1.61924e-06 
05/03/2021 02:45:08 - INFO - volta.train_utils -   [NLVR2]: iter 38320 Ep: 14.19 loss 0.030 score 0.471 lr 1.61512e-06 
05/03/2021 02:46:21 - INFO - volta.train_utils -   [NLVR2]: iter 38360 Ep: 14.21 loss 0.036 score 0.471 lr 1.61101e-06 
05/03/2021 02:47:17 - INFO - volta.train_utils -   [NLVR2]: iter 38400 Ep: 14.22 loss 0.032 score 0.471 lr 1.60689e-06 
05/03/2021 02:48:16 - INFO - volta.train_utils -   [NLVR2]: iter 38440 Ep: 14.24 loss 0.038 score 0.471 lr 1.60278e-06 
05/03/2021 02:49:07 - INFO - volta.train_utils -   [NLVR2]: iter 38480 Ep: 14.25 loss 0.040 score 0.467 lr 1.59866e-06 
05/03/2021 02:50:09 - INFO - volta.train_utils -   [NLVR2]: iter 38520 Ep: 14.27 loss 0.030 score 0.474 lr 1.59455e-06 
05/03/2021 02:50:57 - INFO - volta.train_utils -   [NLVR2]: iter 38560 Ep: 14.28 loss 0.034 score 0.468 lr 1.59043e-06 
05/03/2021 02:52:21 - INFO - volta.train_utils -   [NLVR2]: iter 38600 Ep: 14.30 loss 0.039 score 0.467 lr 1.58632e-06 
05/03/2021 02:53:25 - INFO - volta.train_utils -   [NLVR2]: iter 38640 Ep: 14.31 loss 0.034 score 0.470 lr 1.5822e-06 
05/03/2021 02:54:42 - INFO - volta.train_utils -   [NLVR2]: iter 38680 Ep: 14.33 loss 0.040 score 0.469 lr 1.57809e-06 
05/03/2021 02:55:36 - INFO - volta.train_utils -   [NLVR2]: iter 38720 Ep: 14.34 loss 0.031 score 0.475 lr 1.57397e-06 
05/03/2021 02:56:42 - INFO - volta.train_utils -   [NLVR2]: iter 38760 Ep: 14.36 loss 0.034 score 0.471 lr 1.56986e-06 
05/03/2021 02:57:32 - INFO - volta.train_utils -   [NLVR2]: iter 38800 Ep: 14.37 loss 0.033 score 0.469 lr 1.56574e-06 
05/03/2021 02:58:36 - INFO - volta.train_utils -   [NLVR2]: iter 38840 Ep: 14.39 loss 0.037 score 0.475 lr 1.56163e-06 
05/03/2021 02:59:25 - INFO - volta.train_utils -   [NLVR2]: iter 38880 Ep: 14.40 loss 0.042 score 0.464 lr 1.55751e-06 
05/03/2021 03:00:33 - INFO - volta.train_utils -   [NLVR2]: iter 38920 Ep: 14.41 loss 0.041 score 0.469 lr 1.5534e-06 
05/03/2021 03:01:38 - INFO - volta.train_utils -   [NLVR2]: iter 38960 Ep: 14.43 loss 0.038 score 0.467 lr 1.54928e-06 
05/03/2021 03:02:52 - INFO - volta.train_utils -   [NLVR2]: iter 39000 Ep: 14.44 loss 0.031 score 0.472 lr 1.54516e-06 
05/03/2021 03:03:51 - INFO - volta.train_utils -   [NLVR2]: iter 39040 Ep: 14.46 loss 0.029 score 0.467 lr 1.54105e-06 
05/03/2021 03:04:56 - INFO - volta.train_utils -   [NLVR2]: iter 39080 Ep: 14.47 loss 0.031 score 0.470 lr 1.53693e-06 
05/03/2021 03:05:46 - INFO - volta.train_utils -   [NLVR2]: iter 39120 Ep: 14.49 loss 0.041 score 0.467 lr 1.53282e-06 
05/03/2021 03:07:05 - INFO - volta.train_utils -   [NLVR2]: iter 39160 Ep: 14.50 loss 0.030 score 0.475 lr 1.5287e-06 
05/03/2021 03:08:05 - INFO - volta.train_utils -   [NLVR2]: iter 39200 Ep: 14.52 loss 0.035 score 0.472 lr 1.52459e-06 
05/03/2021 03:09:09 - INFO - volta.train_utils -   [NLVR2]: iter 39240 Ep: 14.53 loss 0.032 score 0.473 lr 1.52047e-06 
05/03/2021 03:10:09 - INFO - volta.train_utils -   [NLVR2]: iter 39280 Ep: 14.55 loss 0.032 score 0.471 lr 1.51636e-06 
05/03/2021 03:11:14 - INFO - volta.train_utils -   [NLVR2]: iter 39320 Ep: 14.56 loss 0.028 score 0.470 lr 1.51224e-06 
05/03/2021 03:12:13 - INFO - volta.train_utils -   [NLVR2]: iter 39360 Ep: 14.58 loss 0.034 score 0.472 lr 1.50813e-06 
05/03/2021 03:13:25 - INFO - volta.train_utils -   [NLVR2]: iter 39400 Ep: 14.59 loss 0.035 score 0.471 lr 1.50401e-06 
05/03/2021 03:14:19 - INFO - volta.train_utils -   [NLVR2]: iter 39440 Ep: 14.61 loss 0.035 score 0.468 lr 1.4999e-06 
05/03/2021 03:15:26 - INFO - volta.train_utils -   [NLVR2]: iter 39480 Ep: 14.62 loss 0.032 score 0.469 lr 1.49578e-06 
05/03/2021 03:16:17 - INFO - volta.train_utils -   [NLVR2]: iter 39520 Ep: 14.64 loss 0.033 score 0.477 lr 1.49167e-06 
05/03/2021 03:17:34 - INFO - volta.train_utils -   [NLVR2]: iter 39560 Ep: 14.65 loss 0.038 score 0.471 lr 1.48755e-06 
05/03/2021 03:18:36 - INFO - volta.train_utils -   [NLVR2]: iter 39600 Ep: 14.67 loss 0.038 score 0.468 lr 1.48344e-06 
05/03/2021 03:19:53 - INFO - volta.train_utils -   [NLVR2]: iter 39640 Ep: 14.68 loss 0.033 score 0.475 lr 1.47932e-06 
05/03/2021 03:20:56 - INFO - volta.train_utils -   [NLVR2]: iter 39680 Ep: 14.70 loss 0.034 score 0.468 lr 1.47521e-06 
05/03/2021 03:22:11 - INFO - volta.train_utils -   [NLVR2]: iter 39720 Ep: 14.71 loss 0.040 score 0.471 lr 1.47109e-06 
05/03/2021 03:23:25 - INFO - volta.train_utils -   [NLVR2]: iter 39760 Ep: 14.73 loss 0.039 score 0.466 lr 1.46698e-06 
05/03/2021 03:24:51 - INFO - volta.train_utils -   [NLVR2]: iter 39800 Ep: 14.74 loss 0.040 score 0.465 lr 1.46286e-06 
05/03/2021 03:25:54 - INFO - volta.train_utils -   [NLVR2]: iter 39840 Ep: 14.76 loss 0.037 score 0.465 lr 1.45874e-06 
05/03/2021 03:27:04 - INFO - volta.train_utils -   [NLVR2]: iter 39880 Ep: 14.77 loss 0.038 score 0.471 lr 1.45463e-06 
05/03/2021 03:27:57 - INFO - volta.train_utils -   [NLVR2]: iter 39920 Ep: 14.79 loss 0.033 score 0.471 lr 1.45051e-06 
05/03/2021 03:28:59 - INFO - volta.train_utils -   [NLVR2]: iter 39960 Ep: 14.80 loss 0.034 score 0.470 lr 1.4464e-06 
05/03/2021 03:29:45 - INFO - volta.train_utils -   [NLVR2]: iter 40000 Ep: 14.81 loss 0.036 score 0.468 lr 1.44228e-06 
05/03/2021 03:30:58 - INFO - volta.train_utils -   [NLVR2]: iter 40040 Ep: 14.83 loss 0.038 score 0.468 lr 1.43817e-06 
05/03/2021 03:31:57 - INFO - volta.train_utils -   [NLVR2]: iter 40080 Ep: 14.84 loss 0.043 score 0.466 lr 1.43405e-06 
05/03/2021 03:33:05 - INFO - volta.train_utils -   [NLVR2]: iter 40120 Ep: 14.86 loss 0.042 score 0.464 lr 1.42994e-06 
05/03/2021 03:34:04 - INFO - volta.train_utils -   [NLVR2]: iter 40160 Ep: 14.87 loss 0.038 score 0.470 lr 1.42582e-06 
05/03/2021 03:35:06 - INFO - volta.train_utils -   [NLVR2]: iter 40200 Ep: 14.89 loss 0.038 score 0.468 lr 1.42171e-06 
05/03/2021 03:35:53 - INFO - volta.train_utils -   [NLVR2]: iter 40240 Ep: 14.90 loss 0.034 score 0.472 lr 1.41759e-06 
05/03/2021 03:36:49 - INFO - volta.train_utils -   [NLVR2]: iter 40280 Ep: 14.92 loss 0.039 score 0.471 lr 1.41348e-06 
05/03/2021 03:37:32 - INFO - volta.train_utils -   [NLVR2]: iter 40320 Ep: 14.93 loss 0.030 score 0.474 lr 1.40936e-06 
05/03/2021 03:38:28 - INFO - volta.train_utils -   [NLVR2]: iter 40360 Ep: 14.95 loss 0.031 score 0.471 lr 1.40525e-06 
05/03/2021 03:39:07 - INFO - volta.train_utils -   [NLVR2]: iter 40400 Ep: 14.96 loss 0.041 score 0.467 lr 1.40113e-06 
05/03/2021 03:40:09 - INFO - volta.train_utils -   [NLVR2]: iter 40440 Ep: 14.98 loss 0.029 score 0.478 lr 1.39702e-06 
05/03/2021 03:40:52 - INFO - volta.train_utils -   [NLVR2]: iter 40480 Ep: 14.99 loss 0.037 score 0.470 lr 1.3929e-06 
05/03/2021 03:41:09 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  75%|  | 15/20 [17:11:09<6:29:34, 4674.83s/it]05/03/2021 03:59:51 - INFO - volta.train_utils -   Eval task TASK12 on iteration 40500 
05/03/2021 03:59:51 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.085 score 74.076 
05/03/2021 04:00:17 - INFO - volta.train_utils -   [NLVR2]: iter 40540 Ep: 15.01 loss 0.027 score 0.476 lr 1.38776e-06 
05/03/2021 04:01:14 - INFO - volta.train_utils -   [NLVR2]: iter 40580 Ep: 15.03 loss 0.030 score 0.472 lr 1.38261e-06 
05/03/2021 04:02:11 - INFO - volta.train_utils -   [NLVR2]: iter 40620 Ep: 15.04 loss 0.032 score 0.468 lr 1.3785e-06 
05/03/2021 04:03:07 - INFO - volta.train_utils -   [NLVR2]: iter 40660 Ep: 15.06 loss 0.031 score 0.469 lr 1.37438e-06 
05/03/2021 04:04:12 - INFO - volta.train_utils -   [NLVR2]: iter 40700 Ep: 15.07 loss 0.030 score 0.476 lr 1.37027e-06 
05/03/2021 04:05:02 - INFO - volta.train_utils -   [NLVR2]: iter 40740 Ep: 15.09 loss 0.028 score 0.479 lr 1.36615e-06 
05/03/2021 04:06:10 - INFO - volta.train_utils -   [NLVR2]: iter 40780 Ep: 15.10 loss 0.042 score 0.466 lr 1.36204e-06 
05/03/2021 04:07:06 - INFO - volta.train_utils -   [NLVR2]: iter 40820 Ep: 15.12 loss 0.040 score 0.470 lr 1.35792e-06 
05/03/2021 04:08:16 - INFO - volta.train_utils -   [NLVR2]: iter 40860 Ep: 15.13 loss 0.032 score 0.470 lr 1.35381e-06 
05/03/2021 04:09:09 - INFO - volta.train_utils -   [NLVR2]: iter 40900 Ep: 15.15 loss 0.030 score 0.477 lr 1.34969e-06 
05/03/2021 04:10:13 - INFO - volta.train_utils -   [NLVR2]: iter 40940 Ep: 15.16 loss 0.025 score 0.481 lr 1.34558e-06 
05/03/2021 04:10:58 - INFO - volta.train_utils -   [NLVR2]: iter 40980 Ep: 15.18 loss 0.027 score 0.478 lr 1.34146e-06 
05/03/2021 04:11:48 - INFO - volta.train_utils -   [NLVR2]: iter 41020 Ep: 15.19 loss 0.023 score 0.473 lr 1.33735e-06 
05/03/2021 04:12:33 - INFO - volta.train_utils -   [NLVR2]: iter 41060 Ep: 15.21 loss 0.030 score 0.470 lr 1.33323e-06 
05/03/2021 04:13:25 - INFO - volta.train_utils -   [NLVR2]: iter 41100 Ep: 15.22 loss 0.024 score 0.478 lr 1.32912e-06 
05/03/2021 04:14:11 - INFO - volta.train_utils -   [NLVR2]: iter 41140 Ep: 15.24 loss 0.027 score 0.475 lr 1.325e-06 
05/03/2021 04:15:10 - INFO - volta.train_utils -   [NLVR2]: iter 41180 Ep: 15.25 loss 0.035 score 0.472 lr 1.32088e-06 
05/03/2021 04:15:56 - INFO - volta.train_utils -   [NLVR2]: iter 41220 Ep: 15.27 loss 0.042 score 0.462 lr 1.31677e-06 
05/03/2021 04:17:02 - INFO - volta.train_utils -   [NLVR2]: iter 41260 Ep: 15.28 loss 0.031 score 0.482 lr 1.31265e-06 
05/03/2021 04:17:53 - INFO - volta.train_utils -   [NLVR2]: iter 41300 Ep: 15.30 loss 0.029 score 0.473 lr 1.30854e-06 
05/03/2021 04:19:00 - INFO - volta.train_utils -   [NLVR2]: iter 41340 Ep: 15.31 loss 0.031 score 0.468 lr 1.30442e-06 
05/03/2021 04:19:47 - INFO - volta.train_utils -   [NLVR2]: iter 41380 Ep: 15.33 loss 0.027 score 0.478 lr 1.30031e-06 
05/03/2021 04:20:43 - INFO - volta.train_utils -   [NLVR2]: iter 41420 Ep: 15.34 loss 0.035 score 0.474 lr 1.29619e-06 
05/03/2021 04:21:32 - INFO - volta.train_utils -   [NLVR2]: iter 41460 Ep: 15.36 loss 0.042 score 0.468 lr 1.29208e-06 
05/03/2021 04:22:26 - INFO - volta.train_utils -   [NLVR2]: iter 41500 Ep: 15.37 loss 0.038 score 0.470 lr 1.28796e-06 
05/03/2021 04:23:07 - INFO - volta.train_utils -   [NLVR2]: iter 41540 Ep: 15.39 loss 0.030 score 0.473 lr 1.28385e-06 
05/03/2021 04:24:04 - INFO - volta.train_utils -   [NLVR2]: iter 41580 Ep: 15.40 loss 0.035 score 0.472 lr 1.27973e-06 
05/03/2021 04:24:49 - INFO - volta.train_utils -   [NLVR2]: iter 41620 Ep: 15.41 loss 0.034 score 0.473 lr 1.27562e-06 
05/03/2021 04:25:47 - INFO - volta.train_utils -   [NLVR2]: iter 41660 Ep: 15.43 loss 0.023 score 0.484 lr 1.2715e-06 
05/03/2021 04:26:35 - INFO - volta.train_utils -   [NLVR2]: iter 41700 Ep: 15.44 loss 0.037 score 0.471 lr 1.26739e-06 
05/03/2021 04:27:29 - INFO - volta.train_utils -   [NLVR2]: iter 41740 Ep: 15.46 loss 0.037 score 0.473 lr 1.26327e-06 
05/03/2021 04:28:14 - INFO - volta.train_utils -   [NLVR2]: iter 41780 Ep: 15.47 loss 0.034 score 0.472 lr 1.25916e-06 
05/03/2021 04:29:06 - INFO - volta.train_utils -   [NLVR2]: iter 41820 Ep: 15.49 loss 0.036 score 0.471 lr 1.25504e-06 
05/03/2021 04:29:45 - INFO - volta.train_utils -   [NLVR2]: iter 41860 Ep: 15.50 loss 0.039 score 0.473 lr 1.25093e-06 
05/03/2021 04:30:38 - INFO - volta.train_utils -   [NLVR2]: iter 41900 Ep: 15.52 loss 0.027 score 0.471 lr 1.24681e-06 
05/03/2021 04:31:24 - INFO - volta.train_utils -   [NLVR2]: iter 41940 Ep: 15.53 loss 0.033 score 0.477 lr 1.2427e-06 
05/03/2021 04:32:20 - INFO - volta.train_utils -   [NLVR2]: iter 41980 Ep: 15.55 loss 0.032 score 0.476 lr 1.23858e-06 
05/03/2021 04:32:59 - INFO - volta.train_utils -   [NLVR2]: iter 42020 Ep: 15.56 loss 0.029 score 0.475 lr 1.23447e-06 
05/03/2021 04:33:54 - INFO - volta.train_utils -   [NLVR2]: iter 42060 Ep: 15.58 loss 0.030 score 0.475 lr 1.23035e-06 
05/03/2021 04:34:34 - INFO - volta.train_utils -   [NLVR2]: iter 42100 Ep: 15.59 loss 0.026 score 0.472 lr 1.22623e-06 
05/03/2021 04:35:35 - INFO - volta.train_utils -   [NLVR2]: iter 42140 Ep: 15.61 loss 0.038 score 0.465 lr 1.22212e-06 
05/03/2021 04:36:19 - INFO - volta.train_utils -   [NLVR2]: iter 42180 Ep: 15.62 loss 0.024 score 0.478 lr 1.218e-06 
05/03/2021 04:37:18 - INFO - volta.train_utils -   [NLVR2]: iter 42220 Ep: 15.64 loss 0.030 score 0.472 lr 1.21389e-06 
05/03/2021 04:38:04 - INFO - volta.train_utils -   [NLVR2]: iter 42260 Ep: 15.65 loss 0.032 score 0.476 lr 1.20977e-06 
05/03/2021 04:39:10 - INFO - volta.train_utils -   [NLVR2]: iter 42300 Ep: 15.67 loss 0.028 score 0.473 lr 1.20566e-06 
05/03/2021 04:39:50 - INFO - volta.train_utils -   [NLVR2]: iter 42340 Ep: 15.68 loss 0.041 score 0.470 lr 1.20154e-06 
05/03/2021 04:40:49 - INFO - volta.train_utils -   [NLVR2]: iter 42380 Ep: 15.70 loss 0.032 score 0.472 lr 1.19743e-06 
05/03/2021 04:41:31 - INFO - volta.train_utils -   [NLVR2]: iter 42420 Ep: 15.71 loss 0.031 score 0.474 lr 1.19331e-06 
05/03/2021 04:42:27 - INFO - volta.train_utils -   [NLVR2]: iter 42460 Ep: 15.73 loss 0.023 score 0.479 lr 1.1892e-06 
05/03/2021 04:43:13 - INFO - volta.train_utils -   [NLVR2]: iter 42500 Ep: 15.74 loss 0.030 score 0.473 lr 1.18508e-06 
05/03/2021 04:44:01 - INFO - volta.train_utils -   [NLVR2]: iter 42540 Ep: 15.76 loss 0.036 score 0.466 lr 1.18097e-06 
05/03/2021 04:44:49 - INFO - volta.train_utils -   [NLVR2]: iter 42580 Ep: 15.77 loss 0.034 score 0.466 lr 1.17685e-06 
05/03/2021 04:45:54 - INFO - volta.train_utils -   [NLVR2]: iter 42620 Ep: 15.79 loss 0.034 score 0.472 lr 1.17274e-06 
05/03/2021 04:46:41 - INFO - volta.train_utils -   [NLVR2]: iter 42660 Ep: 15.80 loss 0.031 score 0.473 lr 1.16862e-06 
05/03/2021 04:47:44 - INFO - volta.train_utils -   [NLVR2]: iter 42700 Ep: 15.81 loss 0.029 score 0.473 lr 1.16451e-06 
05/03/2021 04:48:33 - INFO - volta.train_utils -   [NLVR2]: iter 42740 Ep: 15.83 loss 0.039 score 0.470 lr 1.16039e-06 
05/03/2021 04:49:34 - INFO - volta.train_utils -   [NLVR2]: iter 42780 Ep: 15.84 loss 0.037 score 0.470 lr 1.15628e-06 
05/03/2021 04:50:29 - INFO - volta.train_utils -   [NLVR2]: iter 42820 Ep: 15.86 loss 0.031 score 0.472 lr 1.15216e-06 
05/03/2021 04:51:29 - INFO - volta.train_utils -   [NLVR2]: iter 42860 Ep: 15.87 loss 0.033 score 0.474 lr 1.14805e-06 
05/03/2021 04:52:32 - INFO - volta.train_utils -   [NLVR2]: iter 42900 Ep: 15.89 loss 0.033 score 0.468 lr 1.14393e-06 
05/03/2021 04:53:40 - INFO - volta.train_utils -   [NLVR2]: iter 42940 Ep: 15.90 loss 0.030 score 0.471 lr 1.13981e-06 
05/03/2021 04:54:31 - INFO - volta.train_utils -   [NLVR2]: iter 42980 Ep: 15.92 loss 0.038 score 0.473 lr 1.1357e-06 
05/03/2021 04:55:34 - INFO - volta.train_utils -   [NLVR2]: iter 43020 Ep: 15.93 loss 0.030 score 0.473 lr 1.13158e-06 
05/03/2021 04:56:25 - INFO - volta.train_utils -   [NLVR2]: iter 43060 Ep: 15.95 loss 0.026 score 0.475 lr 1.12747e-06 
05/03/2021 04:57:27 - INFO - volta.train_utils -   [NLVR2]: iter 43100 Ep: 15.96 loss 0.029 score 0.472 lr 1.12335e-06 
05/03/2021 04:58:13 - INFO - volta.train_utils -   [NLVR2]: iter 43140 Ep: 15.98 loss 0.031 score 0.472 lr 1.11924e-06 
05/03/2021 04:59:06 - INFO - volta.train_utils -   [NLVR2]: iter 43180 Ep: 15.99 loss 0.032 score 0.472 lr 1.11512e-06 
05/03/2021 04:59:20 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  80%|  | 16/20 [18:29:18<5:11:56, 4679.20s/it]05/03/2021 05:17:28 - INFO - volta.train_utils -   Eval task TASK12 on iteration 43200 
05/03/2021 05:17:28 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.112 score 74.105 
05/03/2021 05:17:53 - INFO - volta.train_utils -   [NLVR2]: iter 43240 Ep: 16.01 loss 0.037 score 0.474 lr 1.10998e-06 
05/03/2021 05:18:48 - INFO - volta.train_utils -   [NLVR2]: iter 43280 Ep: 16.03 loss 0.028 score 0.474 lr 1.10484e-06 
05/03/2021 05:19:56 - INFO - volta.train_utils -   [NLVR2]: iter 43320 Ep: 16.04 loss 0.029 score 0.476 lr 1.10072e-06 
05/03/2021 05:20:52 - INFO - volta.train_utils -   [NLVR2]: iter 43360 Ep: 16.06 loss 0.028 score 0.474 lr 1.0966e-06 
05/03/2021 05:21:47 - INFO - volta.train_utils -   [NLVR2]: iter 43400 Ep: 16.07 loss 0.038 score 0.469 lr 1.09249e-06 
05/03/2021 05:22:49 - INFO - volta.train_utils -   [NLVR2]: iter 43440 Ep: 16.09 loss 0.031 score 0.477 lr 1.08837e-06 
05/03/2021 05:23:43 - INFO - volta.train_utils -   [NLVR2]: iter 43480 Ep: 16.10 loss 0.030 score 0.473 lr 1.08426e-06 
05/03/2021 05:24:40 - INFO - volta.train_utils -   [NLVR2]: iter 43520 Ep: 16.12 loss 0.028 score 0.474 lr 1.08014e-06 
05/03/2021 05:25:32 - INFO - volta.train_utils -   [NLVR2]: iter 43560 Ep: 16.13 loss 0.030 score 0.478 lr 1.07603e-06 
05/03/2021 05:26:41 - INFO - volta.train_utils -   [NLVR2]: iter 43600 Ep: 16.15 loss 0.033 score 0.475 lr 1.07191e-06 
05/03/2021 05:27:33 - INFO - volta.train_utils -   [NLVR2]: iter 43640 Ep: 16.16 loss 0.033 score 0.479 lr 1.0678e-06 
05/03/2021 05:28:52 - INFO - volta.train_utils -   [NLVR2]: iter 43680 Ep: 16.18 loss 0.027 score 0.478 lr 1.06368e-06 
05/03/2021 05:29:49 - INFO - volta.train_utils -   [NLVR2]: iter 43720 Ep: 16.19 loss 0.037 score 0.471 lr 1.05957e-06 
05/03/2021 05:31:06 - INFO - volta.train_utils -   [NLVR2]: iter 43760 Ep: 16.21 loss 0.039 score 0.468 lr 1.05545e-06 
05/03/2021 05:32:00 - INFO - volta.train_utils -   [NLVR2]: iter 43800 Ep: 16.22 loss 0.028 score 0.474 lr 1.05134e-06 
05/03/2021 05:33:11 - INFO - volta.train_utils -   [NLVR2]: iter 43840 Ep: 16.24 loss 0.031 score 0.474 lr 1.04722e-06 
05/03/2021 05:34:02 - INFO - volta.train_utils -   [NLVR2]: iter 43880 Ep: 16.25 loss 0.038 score 0.467 lr 1.04311e-06 
05/03/2021 05:35:03 - INFO - volta.train_utils -   [NLVR2]: iter 43920 Ep: 16.27 loss 0.028 score 0.475 lr 1.03899e-06 
05/03/2021 05:35:44 - INFO - volta.train_utils -   [NLVR2]: iter 43960 Ep: 16.28 loss 0.029 score 0.475 lr 1.03488e-06 
05/03/2021 05:36:34 - INFO - volta.train_utils -   [NLVR2]: iter 44000 Ep: 16.30 loss 0.027 score 0.474 lr 1.03076e-06 
05/03/2021 05:37:24 - INFO - volta.train_utils -   [NLVR2]: iter 44040 Ep: 16.31 loss 0.032 score 0.478 lr 1.02665e-06 
05/03/2021 05:38:31 - INFO - volta.train_utils -   [NLVR2]: iter 44080 Ep: 16.33 loss 0.026 score 0.478 lr 1.02253e-06 
05/03/2021 05:39:22 - INFO - volta.train_utils -   [NLVR2]: iter 44120 Ep: 16.34 loss 0.030 score 0.475 lr 1.01842e-06 
05/03/2021 05:40:20 - INFO - volta.train_utils -   [NLVR2]: iter 44160 Ep: 16.36 loss 0.026 score 0.477 lr 1.0143e-06 
05/03/2021 05:41:19 - INFO - volta.train_utils -   [NLVR2]: iter 44200 Ep: 16.37 loss 0.031 score 0.477 lr 1.01019e-06 
05/03/2021 05:42:20 - INFO - volta.train_utils -   [NLVR2]: iter 44240 Ep: 16.39 loss 0.024 score 0.482 lr 1.00607e-06 
05/03/2021 05:43:11 - INFO - volta.train_utils -   [NLVR2]: iter 44280 Ep: 16.40 loss 0.027 score 0.476 lr 1.00195e-06 
05/03/2021 05:44:09 - INFO - volta.train_utils -   [NLVR2]: iter 44320 Ep: 16.41 loss 0.027 score 0.480 lr 9.9784e-07 
05/03/2021 05:44:48 - INFO - volta.train_utils -   [NLVR2]: iter 44360 Ep: 16.43 loss 0.034 score 0.477 lr 9.93724e-07 
05/03/2021 05:45:49 - INFO - volta.train_utils -   [NLVR2]: iter 44400 Ep: 16.44 loss 0.026 score 0.476 lr 9.89609e-07 
05/03/2021 05:46:47 - INFO - volta.train_utils -   [NLVR2]: iter 44440 Ep: 16.46 loss 0.022 score 0.476 lr 9.85494e-07 
05/03/2021 05:48:03 - INFO - volta.train_utils -   [NLVR2]: iter 44480 Ep: 16.47 loss 0.032 score 0.475 lr 9.81379e-07 
05/03/2021 05:48:50 - INFO - volta.train_utils -   [NLVR2]: iter 44520 Ep: 16.49 loss 0.029 score 0.476 lr 9.77263e-07 
05/03/2021 05:49:52 - INFO - volta.train_utils -   [NLVR2]: iter 44560 Ep: 16.50 loss 0.030 score 0.475 lr 9.73148e-07 
05/03/2021 05:50:33 - INFO - volta.train_utils -   [NLVR2]: iter 44600 Ep: 16.52 loss 0.033 score 0.476 lr 9.69033e-07 
05/03/2021 05:51:33 - INFO - volta.train_utils -   [NLVR2]: iter 44640 Ep: 16.53 loss 0.026 score 0.476 lr 9.64918e-07 
05/03/2021 05:52:20 - INFO - volta.train_utils -   [NLVR2]: iter 44680 Ep: 16.55 loss 0.025 score 0.480 lr 9.60802e-07 
05/03/2021 05:53:16 - INFO - volta.train_utils -   [NLVR2]: iter 44720 Ep: 16.56 loss 0.039 score 0.474 lr 9.56687e-07 
05/03/2021 05:53:56 - INFO - volta.train_utils -   [NLVR2]: iter 44760 Ep: 16.58 loss 0.027 score 0.475 lr 9.52572e-07 
05/03/2021 05:54:59 - INFO - volta.train_utils -   [NLVR2]: iter 44800 Ep: 16.59 loss 0.026 score 0.475 lr 9.48457e-07 
05/03/2021 05:55:49 - INFO - volta.train_utils -   [NLVR2]: iter 44840 Ep: 16.61 loss 0.026 score 0.477 lr 9.44342e-07 
05/03/2021 05:56:45 - INFO - volta.train_utils -   [NLVR2]: iter 44880 Ep: 16.62 loss 0.030 score 0.479 lr 9.40226e-07 
05/03/2021 05:57:27 - INFO - volta.train_utils -   [NLVR2]: iter 44920 Ep: 16.64 loss 0.027 score 0.478 lr 9.36111e-07 
05/03/2021 05:58:21 - INFO - volta.train_utils -   [NLVR2]: iter 44960 Ep: 16.65 loss 0.025 score 0.478 lr 9.31996e-07 
05/03/2021 05:59:15 - INFO - volta.train_utils -   [NLVR2]: iter 45000 Ep: 16.67 loss 0.032 score 0.472 lr 9.27881e-07 
05/03/2021 06:00:20 - INFO - volta.train_utils -   [NLVR2]: iter 45040 Ep: 16.68 loss 0.032 score 0.476 lr 9.23765e-07 
05/03/2021 06:01:18 - INFO - volta.train_utils -   [NLVR2]: iter 45080 Ep: 16.70 loss 0.036 score 0.470 lr 9.1965e-07 
05/03/2021 06:02:31 - INFO - volta.train_utils -   [NLVR2]: iter 45120 Ep: 16.71 loss 0.035 score 0.475 lr 9.15535e-07 
05/03/2021 06:03:25 - INFO - volta.train_utils -   [NLVR2]: iter 45160 Ep: 16.73 loss 0.024 score 0.480 lr 9.1142e-07 
05/03/2021 06:04:18 - INFO - volta.train_utils -   [NLVR2]: iter 45200 Ep: 16.74 loss 0.032 score 0.474 lr 9.07305e-07 
05/03/2021 06:05:16 - INFO - volta.train_utils -   [NLVR2]: iter 45240 Ep: 16.76 loss 0.025 score 0.474 lr 9.03189e-07 
05/03/2021 06:06:06 - INFO - volta.train_utils -   [NLVR2]: iter 45280 Ep: 16.77 loss 0.024 score 0.474 lr 8.99074e-07 
05/03/2021 06:07:07 - INFO - volta.train_utils -   [NLVR2]: iter 45320 Ep: 16.79 loss 0.034 score 0.470 lr 8.94959e-07 
05/03/2021 06:07:49 - INFO - volta.train_utils -   [NLVR2]: iter 45360 Ep: 16.80 loss 0.022 score 0.482 lr 8.90844e-07 
05/03/2021 06:08:40 - INFO - volta.train_utils -   [NLVR2]: iter 45400 Ep: 16.81 loss 0.027 score 0.477 lr 8.86728e-07 
05/03/2021 06:09:28 - INFO - volta.train_utils -   [NLVR2]: iter 45440 Ep: 16.83 loss 0.036 score 0.473 lr 8.82613e-07 
05/03/2021 06:10:15 - INFO - volta.train_utils -   [NLVR2]: iter 45480 Ep: 16.84 loss 0.027 score 0.477 lr 8.78498e-07 
05/03/2021 06:11:07 - INFO - volta.train_utils -   [NLVR2]: iter 45520 Ep: 16.86 loss 0.034 score 0.474 lr 8.74383e-07 
05/03/2021 06:12:09 - INFO - volta.train_utils -   [NLVR2]: iter 45560 Ep: 16.87 loss 0.029 score 0.479 lr 8.70267e-07 
05/03/2021 06:12:59 - INFO - volta.train_utils -   [NLVR2]: iter 45600 Ep: 16.89 loss 0.032 score 0.479 lr 8.66152e-07 
05/03/2021 06:14:06 - INFO - volta.train_utils -   [NLVR2]: iter 45640 Ep: 16.90 loss 0.034 score 0.472 lr 8.62037e-07 
05/03/2021 06:15:11 - INFO - volta.train_utils -   [NLVR2]: iter 45680 Ep: 16.92 loss 0.025 score 0.477 lr 8.57922e-07 
05/03/2021 06:16:14 - INFO - volta.train_utils -   [NLVR2]: iter 45720 Ep: 16.93 loss 0.027 score 0.476 lr 8.53807e-07 
05/03/2021 06:17:05 - INFO - volta.train_utils -   [NLVR2]: iter 45760 Ep: 16.95 loss 0.033 score 0.475 lr 8.49691e-07 
05/03/2021 06:18:02 - INFO - volta.train_utils -   [NLVR2]: iter 45800 Ep: 16.96 loss 0.026 score 0.475 lr 8.45576e-07 
05/03/2021 06:18:55 - INFO - volta.train_utils -   [NLVR2]: iter 45840 Ep: 16.98 loss 0.027 score 0.474 lr 8.41461e-07 
05/03/2021 06:19:34 - INFO - volta.train_utils -   [NLVR2]: iter 45880 Ep: 16.99 loss 0.033 score 0.471 lr 8.37346e-07 
05/03/2021 06:19:52 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  85%| | 17/20 [19:49:51<3:56:15, 4725.13s/it]05/03/2021 06:37:00 - INFO - volta.train_utils -   Eval task TASK12 on iteration 45900 
05/03/2021 06:37:00 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.153 score 73.990 
05/03/2021 06:37:21 - INFO - volta.train_utils -   [NLVR2]: iter 45940 Ep: 17.01 loss 0.026 score 0.474 lr 8.32202e-07 
05/03/2021 06:38:07 - INFO - volta.train_utils -   [NLVR2]: iter 45980 Ep: 17.03 loss 0.024 score 0.478 lr 8.27058e-07 
05/03/2021 06:38:56 - INFO - volta.train_utils -   [NLVR2]: iter 46020 Ep: 17.04 loss 0.020 score 0.480 lr 8.22942e-07 
05/03/2021 06:39:48 - INFO - volta.train_utils -   [NLVR2]: iter 46060 Ep: 17.06 loss 0.026 score 0.479 lr 8.18827e-07 
05/03/2021 06:40:51 - INFO - volta.train_utils -   [NLVR2]: iter 46100 Ep: 17.07 loss 0.025 score 0.482 lr 8.14712e-07 
05/03/2021 06:41:37 - INFO - volta.train_utils -   [NLVR2]: iter 46140 Ep: 17.09 loss 0.033 score 0.474 lr 8.10597e-07 
05/03/2021 06:42:30 - INFO - volta.train_utils -   [NLVR2]: iter 46180 Ep: 17.10 loss 0.023 score 0.478 lr 8.06481e-07 
05/03/2021 06:43:09 - INFO - volta.train_utils -   [NLVR2]: iter 46220 Ep: 17.12 loss 0.030 score 0.476 lr 8.02366e-07 
05/03/2021 06:44:07 - INFO - volta.train_utils -   [NLVR2]: iter 46260 Ep: 17.13 loss 0.020 score 0.481 lr 7.98251e-07 
05/03/2021 06:44:53 - INFO - volta.train_utils -   [NLVR2]: iter 46300 Ep: 17.15 loss 0.025 score 0.476 lr 7.94136e-07 
05/03/2021 06:45:48 - INFO - volta.train_utils -   [NLVR2]: iter 46340 Ep: 17.16 loss 0.018 score 0.479 lr 7.90021e-07 
05/03/2021 06:46:32 - INFO - volta.train_utils -   [NLVR2]: iter 46380 Ep: 17.18 loss 0.029 score 0.475 lr 7.85905e-07 
05/03/2021 06:47:34 - INFO - volta.train_utils -   [NLVR2]: iter 46420 Ep: 17.19 loss 0.031 score 0.479 lr 7.8179e-07 
05/03/2021 06:48:19 - INFO - volta.train_utils -   [NLVR2]: iter 46460 Ep: 17.21 loss 0.033 score 0.477 lr 7.77675e-07 
05/03/2021 06:49:16 - INFO - volta.train_utils -   [NLVR2]: iter 46500 Ep: 17.22 loss 0.022 score 0.476 lr 7.7356e-07 
05/03/2021 06:50:02 - INFO - volta.train_utils -   [NLVR2]: iter 46540 Ep: 17.24 loss 0.026 score 0.481 lr 7.69444e-07 
05/03/2021 06:51:02 - INFO - volta.train_utils -   [NLVR2]: iter 46580 Ep: 17.25 loss 0.029 score 0.479 lr 7.65329e-07 
05/03/2021 06:51:41 - INFO - volta.train_utils -   [NLVR2]: iter 46620 Ep: 17.27 loss 0.032 score 0.479 lr 7.61214e-07 
05/03/2021 06:52:33 - INFO - volta.train_utils -   [NLVR2]: iter 46660 Ep: 17.28 loss 0.018 score 0.480 lr 7.57099e-07 
05/03/2021 06:53:07 - INFO - volta.train_utils -   [NLVR2]: iter 46700 Ep: 17.30 loss 0.022 score 0.475 lr 7.52984e-07 
05/03/2021 06:54:10 - INFO - volta.train_utils -   [NLVR2]: iter 46740 Ep: 17.31 loss 0.025 score 0.478 lr 7.48868e-07 
05/03/2021 06:55:05 - INFO - volta.train_utils -   [NLVR2]: iter 46780 Ep: 17.33 loss 0.031 score 0.480 lr 7.44753e-07 
05/03/2021 06:56:07 - INFO - volta.train_utils -   [NLVR2]: iter 46820 Ep: 17.34 loss 0.030 score 0.473 lr 7.40638e-07 
05/03/2021 06:57:05 - INFO - volta.train_utils -   [NLVR2]: iter 46860 Ep: 17.36 loss 0.025 score 0.471 lr 7.36523e-07 
05/03/2021 06:58:00 - INFO - volta.train_utils -   [NLVR2]: iter 46900 Ep: 17.37 loss 0.032 score 0.475 lr 7.32407e-07 
05/03/2021 06:58:59 - INFO - volta.train_utils -   [NLVR2]: iter 46940 Ep: 17.39 loss 0.026 score 0.482 lr 7.28292e-07 
05/03/2021 06:59:52 - INFO - volta.train_utils -   [NLVR2]: iter 46980 Ep: 17.40 loss 0.036 score 0.478 lr 7.24177e-07 
05/03/2021 07:00:49 - INFO - volta.train_utils -   [NLVR2]: iter 47020 Ep: 17.41 loss 0.033 score 0.479 lr 7.20062e-07 
05/03/2021 07:01:45 - INFO - volta.train_utils -   [NLVR2]: iter 47060 Ep: 17.43 loss 0.028 score 0.479 lr 7.15947e-07 
05/03/2021 07:02:34 - INFO - volta.train_utils -   [NLVR2]: iter 47100 Ep: 17.44 loss 0.026 score 0.479 lr 7.11831e-07 
05/03/2021 07:03:20 - INFO - volta.train_utils -   [NLVR2]: iter 47140 Ep: 17.46 loss 0.032 score 0.471 lr 7.07716e-07 
05/03/2021 07:04:13 - INFO - volta.train_utils -   [NLVR2]: iter 47180 Ep: 17.47 loss 0.030 score 0.483 lr 7.03601e-07 
05/03/2021 07:05:03 - INFO - volta.train_utils -   [NLVR2]: iter 47220 Ep: 17.49 loss 0.024 score 0.478 lr 6.99486e-07 
05/03/2021 07:05:45 - INFO - volta.train_utils -   [NLVR2]: iter 47260 Ep: 17.50 loss 0.029 score 0.484 lr 6.9537e-07 
05/03/2021 07:06:39 - INFO - volta.train_utils -   [NLVR2]: iter 47300 Ep: 17.52 loss 0.029 score 0.479 lr 6.91255e-07 
05/03/2021 07:07:28 - INFO - volta.train_utils -   [NLVR2]: iter 47340 Ep: 17.53 loss 0.032 score 0.473 lr 6.8714e-07 
05/03/2021 07:08:38 - INFO - volta.train_utils -   [NLVR2]: iter 47380 Ep: 17.55 loss 0.034 score 0.479 lr 6.83025e-07 
05/03/2021 07:09:30 - INFO - volta.train_utils -   [NLVR2]: iter 47420 Ep: 17.56 loss 0.030 score 0.476 lr 6.78909e-07 
05/03/2021 07:10:32 - INFO - volta.train_utils -   [NLVR2]: iter 47460 Ep: 17.58 loss 0.025 score 0.481 lr 6.74794e-07 
05/03/2021 07:11:27 - INFO - volta.train_utils -   [NLVR2]: iter 47500 Ep: 17.59 loss 0.024 score 0.477 lr 6.70679e-07 
05/03/2021 07:12:24 - INFO - volta.train_utils -   [NLVR2]: iter 47540 Ep: 17.61 loss 0.033 score 0.471 lr 6.66564e-07 
05/03/2021 07:13:25 - INFO - volta.train_utils -   [NLVR2]: iter 47580 Ep: 17.62 loss 0.026 score 0.480 lr 6.62449e-07 
05/03/2021 07:14:17 - INFO - volta.train_utils -   [NLVR2]: iter 47620 Ep: 17.64 loss 0.026 score 0.481 lr 6.58333e-07 
05/03/2021 07:15:14 - INFO - volta.train_utils -   [NLVR2]: iter 47660 Ep: 17.65 loss 0.027 score 0.480 lr 6.54218e-07 
05/03/2021 07:16:04 - INFO - volta.train_utils -   [NLVR2]: iter 47700 Ep: 17.67 loss 0.024 score 0.480 lr 6.50103e-07 
05/03/2021 07:17:00 - INFO - volta.train_utils -   [NLVR2]: iter 47740 Ep: 17.68 loss 0.029 score 0.478 lr 6.45988e-07 
05/03/2021 07:17:58 - INFO - volta.train_utils -   [NLVR2]: iter 47780 Ep: 17.70 loss 0.028 score 0.478 lr 6.41872e-07 
05/03/2021 07:18:43 - INFO - volta.train_utils -   [NLVR2]: iter 47820 Ep: 17.71 loss 0.023 score 0.482 lr 6.37757e-07 
05/03/2021 07:19:38 - INFO - volta.train_utils -   [NLVR2]: iter 47860 Ep: 17.73 loss 0.029 score 0.479 lr 6.33642e-07 
05/03/2021 07:20:28 - INFO - volta.train_utils -   [NLVR2]: iter 47900 Ep: 17.74 loss 0.024 score 0.482 lr 6.29527e-07 
05/03/2021 07:21:28 - INFO - volta.train_utils -   [NLVR2]: iter 47940 Ep: 17.76 loss 0.030 score 0.479 lr 6.25412e-07 
05/03/2021 07:22:23 - INFO - volta.train_utils -   [NLVR2]: iter 47980 Ep: 17.77 loss 0.027 score 0.477 lr 6.21296e-07 
05/03/2021 07:23:21 - INFO - volta.train_utils -   [NLVR2]: iter 48020 Ep: 17.79 loss 0.038 score 0.473 lr 6.17181e-07 
05/03/2021 07:24:11 - INFO - volta.train_utils -   [NLVR2]: iter 48060 Ep: 17.80 loss 0.031 score 0.474 lr 6.13066e-07 
05/03/2021 07:25:03 - INFO - volta.train_utils -   [NLVR2]: iter 48100 Ep: 17.81 loss 0.031 score 0.475 lr 6.08951e-07 
05/03/2021 07:25:49 - INFO - volta.train_utils -   [NLVR2]: iter 48140 Ep: 17.83 loss 0.025 score 0.478 lr 6.04835e-07 
05/03/2021 07:26:48 - INFO - volta.train_utils -   [NLVR2]: iter 48180 Ep: 17.84 loss 0.022 score 0.480 lr 6.0072e-07 
05/03/2021 07:27:37 - INFO - volta.train_utils -   [NLVR2]: iter 48220 Ep: 17.86 loss 0.033 score 0.473 lr 5.96605e-07 
05/03/2021 07:28:26 - INFO - volta.train_utils -   [NLVR2]: iter 48260 Ep: 17.87 loss 0.028 score 0.476 lr 5.9249e-07 
05/03/2021 07:29:12 - INFO - volta.train_utils -   [NLVR2]: iter 48300 Ep: 17.89 loss 0.021 score 0.480 lr 5.88374e-07 
05/03/2021 07:30:01 - INFO - volta.train_utils -   [NLVR2]: iter 48340 Ep: 17.90 loss 0.024 score 0.480 lr 5.84259e-07 
05/03/2021 07:30:48 - INFO - volta.train_utils -   [NLVR2]: iter 48380 Ep: 17.92 loss 0.033 score 0.475 lr 5.80144e-07 
05/03/2021 07:31:42 - INFO - volta.train_utils -   [NLVR2]: iter 48420 Ep: 17.93 loss 0.028 score 0.476 lr 5.76029e-07 
05/03/2021 07:32:35 - INFO - volta.train_utils -   [NLVR2]: iter 48460 Ep: 17.95 loss 0.028 score 0.476 lr 5.71914e-07 
05/03/2021 07:33:26 - INFO - volta.train_utils -   [NLVR2]: iter 48500 Ep: 17.96 loss 0.023 score 0.482 lr 5.67798e-07 
05/03/2021 07:34:14 - INFO - volta.train_utils -   [NLVR2]: iter 48540 Ep: 17.98 loss 0.030 score 0.479 lr 5.63683e-07 
05/03/2021 07:35:01 - INFO - volta.train_utils -   [NLVR2]: iter 48580 Ep: 17.99 loss 0.029 score 0.476 lr 5.59568e-07 
05/03/2021 07:35:13 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  90%| | 18/20 [21:05:11<2:35:27, 4663.81s/it]05/03/2021 07:53:23 - INFO - volta.train_utils -   Eval task TASK12 on iteration 48600 
05/03/2021 07:53:23 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.201 score 73.890 
05/03/2021 07:53:46 - INFO - volta.train_utils -   [NLVR2]: iter 48640 Ep: 18.01 loss 0.031 score 0.476 lr 5.54424e-07 
05/03/2021 07:54:33 - INFO - volta.train_utils -   [NLVR2]: iter 48680 Ep: 18.03 loss 0.022 score 0.483 lr 5.4928e-07 
05/03/2021 07:55:31 - INFO - volta.train_utils -   [NLVR2]: iter 48720 Ep: 18.04 loss 0.025 score 0.480 lr 5.45165e-07 
05/03/2021 07:56:26 - INFO - volta.train_utils -   [NLVR2]: iter 48760 Ep: 18.06 loss 0.027 score 0.479 lr 5.41049e-07 
05/03/2021 07:57:25 - INFO - volta.train_utils -   [NLVR2]: iter 48800 Ep: 18.07 loss 0.027 score 0.483 lr 5.36934e-07 
05/03/2021 07:58:14 - INFO - volta.train_utils -   [NLVR2]: iter 48840 Ep: 18.09 loss 0.019 score 0.487 lr 5.32819e-07 
05/03/2021 07:59:05 - INFO - volta.train_utils -   [NLVR2]: iter 48880 Ep: 18.10 loss 0.023 score 0.482 lr 5.28704e-07 
05/03/2021 07:59:59 - INFO - volta.train_utils -   [NLVR2]: iter 48920 Ep: 18.12 loss 0.033 score 0.475 lr 5.24588e-07 
05/03/2021 08:00:52 - INFO - volta.train_utils -   [NLVR2]: iter 48960 Ep: 18.13 loss 0.025 score 0.481 lr 5.20473e-07 
05/03/2021 08:01:52 - INFO - volta.train_utils -   [NLVR2]: iter 49000 Ep: 18.15 loss 0.019 score 0.486 lr 5.16358e-07 
05/03/2021 08:02:47 - INFO - volta.train_utils -   [NLVR2]: iter 49040 Ep: 18.16 loss 0.030 score 0.478 lr 5.12243e-07 
05/03/2021 08:03:58 - INFO - volta.train_utils -   [NLVR2]: iter 49080 Ep: 18.18 loss 0.027 score 0.480 lr 5.08128e-07 
05/03/2021 08:04:51 - INFO - volta.train_utils -   [NLVR2]: iter 49120 Ep: 18.19 loss 0.032 score 0.478 lr 5.04012e-07 
05/03/2021 08:05:45 - INFO - volta.train_utils -   [NLVR2]: iter 49160 Ep: 18.21 loss 0.023 score 0.478 lr 4.99897e-07 
05/03/2021 08:06:42 - INFO - volta.train_utils -   [NLVR2]: iter 49200 Ep: 18.22 loss 0.034 score 0.471 lr 4.95782e-07 
05/03/2021 08:07:40 - INFO - volta.train_utils -   [NLVR2]: iter 49240 Ep: 18.24 loss 0.025 score 0.480 lr 4.91667e-07 
05/03/2021 08:08:39 - INFO - volta.train_utils -   [NLVR2]: iter 49280 Ep: 18.25 loss 0.021 score 0.480 lr 4.87551e-07 
05/03/2021 08:09:37 - INFO - volta.train_utils -   [NLVR2]: iter 49320 Ep: 18.27 loss 0.024 score 0.483 lr 4.83436e-07 
05/03/2021 08:10:27 - INFO - volta.train_utils -   [NLVR2]: iter 49360 Ep: 18.28 loss 0.020 score 0.482 lr 4.79321e-07 
05/03/2021 08:11:28 - INFO - volta.train_utils -   [NLVR2]: iter 49400 Ep: 18.30 loss 0.025 score 0.479 lr 4.75206e-07 
05/03/2021 08:12:20 - INFO - volta.train_utils -   [NLVR2]: iter 49440 Ep: 18.31 loss 0.035 score 0.475 lr 4.71091e-07 
05/03/2021 08:13:13 - INFO - volta.train_utils -   [NLVR2]: iter 49480 Ep: 18.33 loss 0.026 score 0.481 lr 4.66975e-07 
05/03/2021 08:14:00 - INFO - volta.train_utils -   [NLVR2]: iter 49520 Ep: 18.34 loss 0.022 score 0.481 lr 4.6286e-07 
05/03/2021 08:14:49 - INFO - volta.train_utils -   [NLVR2]: iter 49560 Ep: 18.36 loss 0.024 score 0.480 lr 4.58745e-07 
05/03/2021 08:15:39 - INFO - volta.train_utils -   [NLVR2]: iter 49600 Ep: 18.37 loss 0.036 score 0.475 lr 4.5463e-07 
05/03/2021 08:16:34 - INFO - volta.train_utils -   [NLVR2]: iter 49640 Ep: 18.39 loss 0.020 score 0.480 lr 4.50514e-07 
05/03/2021 08:17:43 - INFO - volta.train_utils -   [NLVR2]: iter 49680 Ep: 18.40 loss 0.024 score 0.480 lr 4.46399e-07 
05/03/2021 08:18:43 - INFO - volta.train_utils -   [NLVR2]: iter 49720 Ep: 18.41 loss 0.029 score 0.482 lr 4.42284e-07 
05/03/2021 08:19:40 - INFO - volta.train_utils -   [NLVR2]: iter 49760 Ep: 18.43 loss 0.029 score 0.478 lr 4.38169e-07 
05/03/2021 08:20:33 - INFO - volta.train_utils -   [NLVR2]: iter 49800 Ep: 18.44 loss 0.025 score 0.481 lr 4.34053e-07 
05/03/2021 08:21:29 - INFO - volta.train_utils -   [NLVR2]: iter 49840 Ep: 18.46 loss 0.027 score 0.480 lr 4.29938e-07 
05/03/2021 08:22:20 - INFO - volta.train_utils -   [NLVR2]: iter 49880 Ep: 18.47 loss 0.028 score 0.477 lr 4.25823e-07 
05/03/2021 08:23:09 - INFO - volta.train_utils -   [NLVR2]: iter 49920 Ep: 18.49 loss 0.022 score 0.480 lr 4.21708e-07 
05/03/2021 08:23:58 - INFO - volta.train_utils -   [NLVR2]: iter 49960 Ep: 18.50 loss 0.024 score 0.480 lr 4.17593e-07 
05/03/2021 08:24:55 - INFO - volta.train_utils -   [NLVR2]: iter 50000 Ep: 18.52 loss 0.025 score 0.480 lr 4.13477e-07 
05/03/2021 08:25:37 - INFO - volta.train_utils -   [NLVR2]: iter 50040 Ep: 18.53 loss 0.024 score 0.483 lr 4.09362e-07 
05/03/2021 08:26:30 - INFO - volta.train_utils -   [NLVR2]: iter 50080 Ep: 18.55 loss 0.030 score 0.478 lr 4.05247e-07 
05/03/2021 08:27:20 - INFO - volta.train_utils -   [NLVR2]: iter 50120 Ep: 18.56 loss 0.018 score 0.483 lr 4.01132e-07 
05/03/2021 08:28:12 - INFO - volta.train_utils -   [NLVR2]: iter 50160 Ep: 18.58 loss 0.026 score 0.473 lr 3.97016e-07 
05/03/2021 08:29:09 - INFO - volta.train_utils -   [NLVR2]: iter 50200 Ep: 18.59 loss 0.020 score 0.481 lr 3.92901e-07 
05/03/2021 08:30:05 - INFO - volta.train_utils -   [NLVR2]: iter 50240 Ep: 18.61 loss 0.023 score 0.479 lr 3.88786e-07 
05/03/2021 08:30:47 - INFO - volta.train_utils -   [NLVR2]: iter 50280 Ep: 18.62 loss 0.020 score 0.484 lr 3.84671e-07 
05/03/2021 08:31:45 - INFO - volta.train_utils -   [NLVR2]: iter 50320 Ep: 18.64 loss 0.021 score 0.480 lr 3.80556e-07 
05/03/2021 08:32:32 - INFO - volta.train_utils -   [NLVR2]: iter 50360 Ep: 18.65 loss 0.027 score 0.480 lr 3.7644e-07 
05/03/2021 08:33:27 - INFO - volta.train_utils -   [NLVR2]: iter 50400 Ep: 18.67 loss 0.025 score 0.477 lr 3.72325e-07 
05/03/2021 08:34:17 - INFO - volta.train_utils -   [NLVR2]: iter 50440 Ep: 18.68 loss 0.026 score 0.479 lr 3.6821e-07 
05/03/2021 08:35:20 - INFO - volta.train_utils -   [NLVR2]: iter 50480 Ep: 18.70 loss 0.024 score 0.478 lr 3.64095e-07 
05/03/2021 08:36:07 - INFO - volta.train_utils -   [NLVR2]: iter 50520 Ep: 18.71 loss 0.025 score 0.484 lr 3.59979e-07 
05/03/2021 08:37:05 - INFO - volta.train_utils -   [NLVR2]: iter 50560 Ep: 18.73 loss 0.025 score 0.480 lr 3.55864e-07 
05/03/2021 08:37:49 - INFO - volta.train_utils -   [NLVR2]: iter 50600 Ep: 18.74 loss 0.030 score 0.477 lr 3.51749e-07 
05/03/2021 08:38:48 - INFO - volta.train_utils -   [NLVR2]: iter 50640 Ep: 18.76 loss 0.027 score 0.479 lr 3.47634e-07 
05/03/2021 08:39:34 - INFO - volta.train_utils -   [NLVR2]: iter 50680 Ep: 18.77 loss 0.022 score 0.479 lr 3.43519e-07 
05/03/2021 08:40:32 - INFO - volta.train_utils -   [NLVR2]: iter 50720 Ep: 18.79 loss 0.027 score 0.479 lr 3.39403e-07 
05/03/2021 08:41:21 - INFO - volta.train_utils -   [NLVR2]: iter 50760 Ep: 18.80 loss 0.020 score 0.479 lr 3.35288e-07 
05/03/2021 08:42:24 - INFO - volta.train_utils -   [NLVR2]: iter 50800 Ep: 18.81 loss 0.031 score 0.477 lr 3.31173e-07 
05/03/2021 08:43:26 - INFO - volta.train_utils -   [NLVR2]: iter 50840 Ep: 18.83 loss 0.026 score 0.480 lr 3.27058e-07 
05/03/2021 08:44:26 - INFO - volta.train_utils -   [NLVR2]: iter 50880 Ep: 18.84 loss 0.032 score 0.475 lr 3.22942e-07 
05/03/2021 08:45:25 - INFO - volta.train_utils -   [NLVR2]: iter 50920 Ep: 18.86 loss 0.033 score 0.478 lr 3.18827e-07 
05/03/2021 08:46:28 - INFO - volta.train_utils -   [NLVR2]: iter 50960 Ep: 18.87 loss 0.025 score 0.482 lr 3.14712e-07 
05/03/2021 08:47:18 - INFO - volta.train_utils -   [NLVR2]: iter 51000 Ep: 18.89 loss 0.023 score 0.481 lr 3.10597e-07 
05/03/2021 08:48:16 - INFO - volta.train_utils -   [NLVR2]: iter 51040 Ep: 18.90 loss 0.025 score 0.481 lr 3.06481e-07 
05/03/2021 08:49:03 - INFO - volta.train_utils -   [NLVR2]: iter 51080 Ep: 18.92 loss 0.025 score 0.473 lr 3.02366e-07 
05/03/2021 08:50:00 - INFO - volta.train_utils -   [NLVR2]: iter 51120 Ep: 18.93 loss 0.025 score 0.479 lr 2.98251e-07 
05/03/2021 08:50:50 - INFO - volta.train_utils -   [NLVR2]: iter 51160 Ep: 18.95 loss 0.026 score 0.480 lr 2.94136e-07 
05/03/2021 08:51:52 - INFO - volta.train_utils -   [NLVR2]: iter 51200 Ep: 18.96 loss 0.025 score 0.482 lr 2.90021e-07 
05/03/2021 08:52:37 - INFO - volta.train_utils -   [NLVR2]: iter 51240 Ep: 18.98 loss 0.028 score 0.478 lr 2.85905e-07 
05/03/2021 08:53:32 - INFO - volta.train_utils -   [NLVR2]: iter 51280 Ep: 18.99 loss 0.021 score 0.484 lr 2.8179e-07 
05/03/2021 08:53:47 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  95%|| 19/20 [22:23:46<1:17:59, 4679.03s/it]05/03/2021 09:11:42 - INFO - volta.train_utils -   Eval task TASK12 on iteration 51300 
05/03/2021 09:11:42 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.219 score 73.732 
05/03/2021 09:12:07 - INFO - volta.train_utils -   [NLVR2]: iter 51340 Ep: 19.01 loss 0.021 score 0.481 lr 2.76646e-07 
05/03/2021 09:13:05 - INFO - volta.train_utils -   [NLVR2]: iter 51380 Ep: 19.03 loss 0.026 score 0.479 lr 2.71502e-07 
05/03/2021 09:14:06 - INFO - volta.train_utils -   [NLVR2]: iter 51420 Ep: 19.04 loss 0.018 score 0.484 lr 2.67387e-07 
05/03/2021 09:15:03 - INFO - volta.train_utils -   [NLVR2]: iter 51460 Ep: 19.06 loss 0.020 score 0.480 lr 2.63272e-07 
05/03/2021 09:16:05 - INFO - volta.train_utils -   [NLVR2]: iter 51500 Ep: 19.07 loss 0.024 score 0.480 lr 2.59156e-07 
05/03/2021 09:17:00 - INFO - volta.train_utils -   [NLVR2]: iter 51540 Ep: 19.09 loss 0.028 score 0.479 lr 2.55041e-07 
05/03/2021 09:18:06 - INFO - volta.train_utils -   [NLVR2]: iter 51580 Ep: 19.10 loss 0.030 score 0.476 lr 2.50926e-07 
05/03/2021 09:19:06 - INFO - volta.train_utils -   [NLVR2]: iter 51620 Ep: 19.12 loss 0.031 score 0.479 lr 2.46811e-07 
05/03/2021 09:20:04 - INFO - volta.train_utils -   [NLVR2]: iter 51660 Ep: 19.13 loss 0.025 score 0.478 lr 2.42695e-07 
05/03/2021 09:21:06 - INFO - volta.train_utils -   [NLVR2]: iter 51700 Ep: 19.15 loss 0.022 score 0.482 lr 2.3858e-07 
05/03/2021 09:22:15 - INFO - volta.train_utils -   [NLVR2]: iter 51740 Ep: 19.16 loss 0.026 score 0.480 lr 2.34465e-07 
05/03/2021 09:22:57 - INFO - volta.train_utils -   [NLVR2]: iter 51780 Ep: 19.18 loss 0.027 score 0.479 lr 2.3035e-07 
05/03/2021 09:23:57 - INFO - volta.train_utils -   [NLVR2]: iter 51820 Ep: 19.19 loss 0.025 score 0.482 lr 2.26235e-07 
05/03/2021 09:24:52 - INFO - volta.train_utils -   [NLVR2]: iter 51860 Ep: 19.21 loss 0.031 score 0.480 lr 2.22119e-07 
05/03/2021 09:25:45 - INFO - volta.train_utils -   [NLVR2]: iter 51900 Ep: 19.22 loss 0.029 score 0.479 lr 2.18004e-07 
05/03/2021 09:26:44 - INFO - volta.train_utils -   [NLVR2]: iter 51940 Ep: 19.24 loss 0.031 score 0.477 lr 2.13889e-07 
05/03/2021 09:27:54 - INFO - volta.train_utils -   [NLVR2]: iter 51980 Ep: 19.25 loss 0.029 score 0.479 lr 2.09774e-07 
05/03/2021 09:28:50 - INFO - volta.train_utils -   [NLVR2]: iter 52020 Ep: 19.27 loss 0.025 score 0.481 lr 2.05658e-07 
05/03/2021 09:29:57 - INFO - volta.train_utils -   [NLVR2]: iter 52060 Ep: 19.28 loss 0.021 score 0.487 lr 2.01543e-07 
05/03/2021 09:30:49 - INFO - volta.train_utils -   [NLVR2]: iter 52100 Ep: 19.30 loss 0.020 score 0.482 lr 1.97428e-07 
05/03/2021 09:31:51 - INFO - volta.train_utils -   [NLVR2]: iter 52140 Ep: 19.31 loss 0.025 score 0.481 lr 1.93313e-07 
05/03/2021 09:32:40 - INFO - volta.train_utils -   [NLVR2]: iter 52180 Ep: 19.33 loss 0.027 score 0.480 lr 1.89198e-07 
05/03/2021 09:33:37 - INFO - volta.train_utils -   [NLVR2]: iter 52220 Ep: 19.34 loss 0.033 score 0.479 lr 1.85082e-07 
05/03/2021 09:34:30 - INFO - volta.train_utils -   [NLVR2]: iter 52260 Ep: 19.36 loss 0.025 score 0.479 lr 1.80967e-07 
05/03/2021 09:35:26 - INFO - volta.train_utils -   [NLVR2]: iter 52300 Ep: 19.37 loss 0.026 score 0.479 lr 1.76852e-07 
05/03/2021 09:36:16 - INFO - volta.train_utils -   [NLVR2]: iter 52340 Ep: 19.39 loss 0.020 score 0.484 lr 1.72737e-07 
05/03/2021 09:37:16 - INFO - volta.train_utils -   [NLVR2]: iter 52380 Ep: 19.40 loss 0.025 score 0.478 lr 1.68621e-07 
05/03/2021 09:38:04 - INFO - volta.train_utils -   [NLVR2]: iter 52420 Ep: 19.41 loss 0.023 score 0.480 lr 1.64506e-07 
05/03/2021 09:38:59 - INFO - volta.train_utils -   [NLVR2]: iter 52460 Ep: 19.43 loss 0.022 score 0.483 lr 1.60391e-07 
05/03/2021 09:39:43 - INFO - volta.train_utils -   [NLVR2]: iter 52500 Ep: 19.44 loss 0.028 score 0.480 lr 1.56276e-07 
05/03/2021 09:40:37 - INFO - volta.train_utils -   [NLVR2]: iter 52540 Ep: 19.46 loss 0.025 score 0.477 lr 1.5216e-07 
05/03/2021 09:41:20 - INFO - volta.train_utils -   [NLVR2]: iter 52580 Ep: 19.47 loss 0.021 score 0.484 lr 1.48045e-07 
05/03/2021 09:42:15 - INFO - volta.train_utils -   [NLVR2]: iter 52620 Ep: 19.49 loss 0.027 score 0.480 lr 1.4393e-07 
05/03/2021 09:43:00 - INFO - volta.train_utils -   [NLVR2]: iter 52660 Ep: 19.50 loss 0.023 score 0.482 lr 1.39815e-07 
05/03/2021 09:43:55 - INFO - volta.train_utils -   [NLVR2]: iter 52700 Ep: 19.52 loss 0.024 score 0.485 lr 1.357e-07 
05/03/2021 09:44:39 - INFO - volta.train_utils -   [NLVR2]: iter 52740 Ep: 19.53 loss 0.021 score 0.480 lr 1.31584e-07 
05/03/2021 09:45:33 - INFO - volta.train_utils -   [NLVR2]: iter 52780 Ep: 19.55 loss 0.027 score 0.481 lr 1.27469e-07 
05/03/2021 09:46:26 - INFO - volta.train_utils -   [NLVR2]: iter 52820 Ep: 19.56 loss 0.026 score 0.485 lr 1.23354e-07 
05/03/2021 09:47:29 - INFO - volta.train_utils -   [NLVR2]: iter 52860 Ep: 19.58 loss 0.024 score 0.479 lr 1.19239e-07 
05/03/2021 09:48:13 - INFO - volta.train_utils -   [NLVR2]: iter 52900 Ep: 19.59 loss 0.020 score 0.485 lr 1.15123e-07 
05/03/2021 09:49:14 - INFO - volta.train_utils -   [NLVR2]: iter 52940 Ep: 19.61 loss 0.028 score 0.482 lr 1.11008e-07 
05/03/2021 09:49:59 - INFO - volta.train_utils -   [NLVR2]: iter 52980 Ep: 19.62 loss 0.028 score 0.480 lr 1.06893e-07 
05/03/2021 09:51:04 - INFO - volta.train_utils -   [NLVR2]: iter 53020 Ep: 19.64 loss 0.030 score 0.480 lr 1.02778e-07 
05/03/2021 09:51:57 - INFO - volta.train_utils -   [NLVR2]: iter 53060 Ep: 19.65 loss 0.021 score 0.479 lr 9.86626e-08 
05/03/2021 09:52:58 - INFO - volta.train_utils -   [NLVR2]: iter 53100 Ep: 19.67 loss 0.021 score 0.487 lr 9.45473e-08 
05/03/2021 09:53:49 - INFO - volta.train_utils -   [NLVR2]: iter 53140 Ep: 19.68 loss 0.028 score 0.477 lr 9.04321e-08 
05/03/2021 09:54:58 - INFO - volta.train_utils -   [NLVR2]: iter 53180 Ep: 19.70 loss 0.020 score 0.481 lr 8.63169e-08 
05/03/2021 09:55:50 - INFO - volta.train_utils -   [NLVR2]: iter 53220 Ep: 19.71 loss 0.023 score 0.479 lr 8.22016e-08 
05/03/2021 09:56:53 - INFO - volta.train_utils -   [NLVR2]: iter 53260 Ep: 19.73 loss 0.023 score 0.480 lr 7.80864e-08 
05/03/2021 09:57:53 - INFO - volta.train_utils -   [NLVR2]: iter 53300 Ep: 19.74 loss 0.022 score 0.480 lr 7.39712e-08 
05/03/2021 09:59:06 - INFO - volta.train_utils -   [NLVR2]: iter 53340 Ep: 19.76 loss 0.022 score 0.481 lr 6.9856e-08 
05/03/2021 10:00:06 - INFO - volta.train_utils -   [NLVR2]: iter 53380 Ep: 19.77 loss 0.026 score 0.478 lr 6.57407e-08 
05/03/2021 10:01:25 - INFO - volta.train_utils -   [NLVR2]: iter 53420 Ep: 19.79 loss 0.026 score 0.474 lr 6.16255e-08 
05/03/2021 10:02:20 - INFO - volta.train_utils -   [NLVR2]: iter 53460 Ep: 19.80 loss 0.024 score 0.485 lr 5.75103e-08 
05/03/2021 10:03:31 - INFO - volta.train_utils -   [NLVR2]: iter 53500 Ep: 19.81 loss 0.032 score 0.473 lr 5.33951e-08 
05/03/2021 10:04:28 - INFO - volta.train_utils -   [NLVR2]: iter 53540 Ep: 19.83 loss 0.030 score 0.475 lr 4.92798e-08 
05/03/2021 10:05:36 - INFO - volta.train_utils -   [NLVR2]: iter 53580 Ep: 19.84 loss 0.021 score 0.480 lr 4.51646e-08 
05/03/2021 10:06:28 - INFO - volta.train_utils -   [NLVR2]: iter 53620 Ep: 19.86 loss 0.032 score 0.480 lr 4.10494e-08 
05/03/2021 10:07:30 - INFO - volta.train_utils -   [NLVR2]: iter 53660 Ep: 19.87 loss 0.024 score 0.476 lr 3.69342e-08 
05/03/2021 10:08:25 - INFO - volta.train_utils -   [NLVR2]: iter 53700 Ep: 19.89 loss 0.037 score 0.480 lr 3.28189e-08 
05/03/2021 10:09:30 - INFO - volta.train_utils -   [NLVR2]: iter 53740 Ep: 19.90 loss 0.022 score 0.480 lr 2.87037e-08 
05/03/2021 10:10:43 - INFO - volta.train_utils -   [NLVR2]: iter 53780 Ep: 19.92 loss 0.031 score 0.474 lr 2.45885e-08 
05/03/2021 10:11:56 - INFO - volta.train_utils -   [NLVR2]: iter 53820 Ep: 19.93 loss 0.027 score 0.477 lr 2.04733e-08 
05/03/2021 10:13:09 - INFO - volta.train_utils -   [NLVR2]: iter 53860 Ep: 19.95 loss 0.018 score 0.486 lr 1.6358e-08 
05/03/2021 10:14:09 - INFO - volta.train_utils -   [NLVR2]: iter 53900 Ep: 19.96 loss 0.030 score 0.475 lr 1.22428e-08 
05/03/2021 10:15:12 - INFO - volta.train_utils -   [NLVR2]: iter 53940 Ep: 19.98 loss 0.017 score 0.481 lr 8.12757e-09 
05/03/2021 10:16:03 - INFO - volta.train_utils -   [NLVR2]: iter 53980 Ep: 19.99 loss 0.026 score 0.476 lr 4.01235e-09 
05/03/2021 10:16:20 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch: 100%|| 20/20 [23:46:20<00:00, 4761.42s/it]  
train.dtu.sh: line 24: /home/people/emabug: Is a directory
